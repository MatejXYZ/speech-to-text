/*
 * ATTENTION: The "eval" devtool has been used (maybe by default in mode: "development").
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
/******/ (() => { // webpackBootstrap
/******/ 	var __webpack_modules__ = ({

/***/ "./node_modules/bent/src/browser.js":
/*!******************************************!*\
  !*** ./node_modules/bent/src/browser.js ***!
  \******************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

  "use strict";
  eval("\n/* global fetch, btoa, Headers */\nconst core = __webpack_require__(/*! ./core */ \"./node_modules/bent/src/core.js\")\n\nclass StatusError extends Error {\n  constructor (res, ...params) {\n    super(...params)\n\n    if (Error.captureStackTrace) {\n      Error.captureStackTrace(this, StatusError)\n    }\n\n    this.name = 'StatusError'\n    this.message = res.statusMessage\n    this.statusCode = res.status\n    this.res = res\n    this.json = res.json.bind(res)\n    this.text = res.text.bind(res)\n    this.arrayBuffer = res.arrayBuffer.bind(res)\n    let buffer\n    const get = () => {\n      if (!buffer) buffer = this.arrayBuffer()\n      return buffer\n    }\n    Object.defineProperty(this, 'responseBody', { get })\n    // match Node.js headers object\n    this.headers = {}\n    for (const [key, value] of res.headers.entries()) {\n      this.headers[key.toLowerCase()] = value\n    }\n  }\n}\n\nconst mkrequest = (statusCodes, method, encoding, headers, baseurl) => async (_url, body, _headers = {}) => {\n  _url = baseurl + (_url || '')\n  let parsed = new URL(_url)\n\n  if (!headers) headers = {}\n  if (parsed.username) {\n    headers.Authorization = 'Basic ' + btoa(parsed.username + ':' + parsed.password)\n    parsed = new URL(parsed.protocol + '//' + parsed.host + parsed.pathname + parsed.search)\n  }\n  if (parsed.protocol !== 'https:' && parsed.protocol !== 'http:') {\n    throw new Error(`Unknown protocol, ${parsed.protocol}`)\n  }\n\n  if (body) {\n    if (body instanceof ArrayBuffer ||\n      ArrayBuffer.isView(body) ||\n      typeof body === 'string'\n    ) {\n      // noop\n    } else if (typeof body === 'object') {\n      body = JSON.stringify(body)\n      headers['Content-Type'] = 'application/json'\n    } else {\n      throw new Error('Unknown body type.')\n    }\n  }\n\n  _headers = new Headers({ ...(headers || {}), ..._headers })\n\n  const resp = await fetch(parsed, { method, headers: _headers, body })\n  resp.statusCode = resp.status\n\n  if (!statusCodes.has(resp.status)) {\n    throw new StatusError(resp)\n  }\n\n  if (encoding === 'json') return resp.json()\n  else if (encoding === 'buffer') return resp.arrayBuffer()\n  else if (encoding === 'string') return resp.text()\n  else return resp\n}\n\nmodule.exports = core(mkrequest)\n\n\n//# sourceURL=webpack://speech/./node_modules/bent/src/browser.js?");
  
  /***/ }),
  
  /***/ "./node_modules/bent/src/core.js":
  /*!***************************************!*\
    !*** ./node_modules/bent/src/core.js ***!
    \***************************************/
  /***/ ((module) => {
  
  "use strict";
  eval("\nconst encodings = new Set(['json', 'buffer', 'string'])\n\nmodule.exports = mkrequest => (...args) => {\n  const statusCodes = new Set()\n  let method\n  let encoding\n  let headers\n  let baseurl = ''\n\n  args.forEach(arg => {\n    if (typeof arg === 'string') {\n      if (arg.toUpperCase() === arg) {\n        if (method) {\n          const msg = `Can't set method to ${arg}, already set to ${method}.`\n          throw new Error(msg)\n        } else {\n          method = arg\n        }\n      } else if (arg.startsWith('http:') || arg.startsWith('https:')) {\n        baseurl = arg\n      } else {\n        if (encodings.has(arg)) {\n          encoding = arg\n        } else {\n          throw new Error(`Unknown encoding, ${arg}`)\n        }\n      }\n    } else if (typeof arg === 'number') {\n      statusCodes.add(arg)\n    } else if (typeof arg === 'object') {\n      if (Array.isArray(arg) || arg instanceof Set) {\n        arg.forEach(code => statusCodes.add(code))\n      } else {\n        if (headers) {\n          throw new Error('Cannot set headers twice.')\n        }\n        headers = arg\n      }\n    } else {\n      throw new Error(`Unknown type: ${typeof arg}`)\n    }\n  })\n\n  if (!method) method = 'GET'\n  if (statusCodes.size === 0) {\n    statusCodes.add(200)\n  }\n\n  return mkrequest(statusCodes, method, encoding, headers, baseurl)\n}\n\n\n//# sourceURL=webpack://speech/./node_modules/bent/src/core.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/CertChecks.js":
  /*!*************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/CertChecks.js ***!
    \*************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"CertCheckAgent\": () => (/* binding */ CertCheckAgent)\n/* harmony export */ });\n/* harmony import */ var tls__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tls */ \"?14d6\");\n/* harmony import */ var tls__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(tls__WEBPACK_IMPORTED_MODULE_0__);\n/* harmony import */ var _external_ocsp_ocsp__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../external/ocsp/ocsp */ \"?2454\");\n/* harmony import */ var _external_ocsp_ocsp__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(_external_ocsp_ocsp__WEBPACK_IMPORTED_MODULE_1__);\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../common/OCSPEvents */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/OCSPEvents.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Events.js\");\n/* harmony import */ var agent_base__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! agent-base */ \"?6483\");\n/* harmony import */ var agent_base__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(agent_base__WEBPACK_IMPORTED_MODULE_2__);\n/* harmony import */ var async_disk_cache__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! async-disk-cache */ \"?bed2\");\n/* harmony import */ var async_disk_cache__WEBPACK_IMPORTED_MODULE_3___default = /*#__PURE__*/__webpack_require__.n(async_disk_cache__WEBPACK_IMPORTED_MODULE_3__);\n/* harmony import */ var https_proxy_agent__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! https-proxy-agent */ \"?72ad\");\n/* harmony import */ var https_proxy_agent__WEBPACK_IMPORTED_MODULE_4___default = /*#__PURE__*/__webpack_require__.n(https_proxy_agent__WEBPACK_IMPORTED_MODULE_4__);\n/* harmony import */ var net__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! net */ \"?a1bf\");\n/* harmony import */ var net__WEBPACK_IMPORTED_MODULE_5___default = /*#__PURE__*/__webpack_require__.n(net__WEBPACK_IMPORTED_MODULE_5__);\n/* eslint-disable import/order */\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\n\n// eslint-disable-next-line @typescript-eslint/ban-ts-comment\n// @ts-ignore\n\n\n\n\nclass CertCheckAgent {\n    constructor(proxyInfo) {\n        if (!!proxyInfo) {\n            this.privProxyInfo = proxyInfo;\n        }\n        // Initialize this here to allow tests to set the env variable before the cache is constructed.\n        if (!CertCheckAgent.privDiskCache) {\n            // eslint-disable-next-line @typescript-eslint/no-unsafe-assignment, @typescript-eslint/no-unsafe-call\n            CertCheckAgent.privDiskCache = new (async_disk_cache__WEBPACK_IMPORTED_MODULE_3___default())(\"microsoft-cognitiveservices-speech-sdk-cache\", { supportBuffer: true, location: (typeof process !== \"undefined\" && !!process.env.SPEECH_OCSP_CACHE_ROOT) ? process.env.SPEECH_OCSP_CACHE_ROOT : undefined });\n        }\n    }\n    // Test hook to force the disk cache to be recreated.\n    static forceReinitDiskCache() {\n        CertCheckAgent.privDiskCache = undefined;\n        CertCheckAgent.privMemCache = {};\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    GetAgent(disableStapling) {\n        // eslint-disable-next-line @typescript-eslint/unbound-method\n        const agent = new (agent_base__WEBPACK_IMPORTED_MODULE_2___default().Agent)(this.CreateConnection);\n        if (this.privProxyInfo !== undefined &&\n            this.privProxyInfo.HostName !== undefined &&\n            this.privProxyInfo.Port > 0) {\n            const proxyName = \"privProxyInfo\";\n            // eslint-disable-next-line @typescript-eslint/no-unsafe-member-access\n            agent[proxyName] = this.privProxyInfo;\n        }\n        return agent;\n    }\n    static GetProxyAgent(proxyInfo) {\n        const httpProxyOptions = {\n            host: proxyInfo.HostName,\n            port: proxyInfo.Port,\n        };\n        if (!!proxyInfo.UserName) {\n            httpProxyOptions.headers = {\n                \"Proxy-Authentication\": \"Basic \" + new Buffer(`${proxyInfo.UserName}:${(proxyInfo.Password === undefined) ? \"\" : proxyInfo.Password}`).toString(\"base64\"),\n            };\n        }\n        else {\n            httpProxyOptions.headers = {};\n        }\n        httpProxyOptions.headers.requestOCSP = \"true\";\n        const httpProxyAgent = new (https_proxy_agent__WEBPACK_IMPORTED_MODULE_4___default())(httpProxyOptions);\n        return httpProxyAgent;\n    }\n    static OCSPCheck(socketPromise, proxyInfo) {\n        return __awaiter(this, void 0, void 0, function* () {\n            let ocspRequest;\n            let stapling;\n            let resolved = false;\n            const socket = yield socketPromise;\n            socket.cork();\n            const tlsSocket = socket;\n            return new Promise((resolve, reject) => {\n                socket.on(\"OCSPResponse\", (data) => {\n                    if (!!data) {\n                        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_6__.OCSPStapleReceivedEvent());\n                        stapling = data;\n                    }\n                });\n                socket.on(\"error\", (error) => {\n                    if (!resolved) {\n                        resolved = true;\n                        socket.destroy();\n                        reject(error);\n                    }\n                });\n                // eslint-disable-next-line @typescript-eslint/no-misused-promises, @typescript-eslint/explicit-function-return-type\n                tlsSocket.on(\"secure\", () => __awaiter(this, void 0, void 0, function* () {\n                    const peer = tlsSocket.getPeerCertificate(true);\n                    try {\n                        const issuer = yield this.GetIssuer(peer);\n                        // We always need a request to verify the response.\n                        ocspRequest = _external_ocsp_ocsp__WEBPACK_IMPORTED_MODULE_1__.request.generate(peer.raw, issuer.raw);\n                        // Do we have a result for this certificate in our memory cache?\n                        const sig = ocspRequest.id.toString(\"hex\");\n                        // Stapled response trumps cached response.\n                        if (!stapling) {\n                            const cacheEntry = yield CertCheckAgent.GetResponseFromCache(sig, ocspRequest, proxyInfo);\n                            stapling = cacheEntry;\n                        }\n                        yield this.VerifyOCSPResponse(stapling, ocspRequest, proxyInfo);\n                        socket.uncork();\n                        resolved = true;\n                        resolve(socket);\n                    }\n                    catch (e) {\n                        socket.destroy();\n                        resolved = true;\n                        reject(e);\n                    }\n                }));\n            });\n        });\n    }\n    static GetIssuer(peer) {\n        if (peer.issuerCertificate) {\n            return Promise.resolve(peer.issuerCertificate);\n        }\n        return new Promise((resolve, reject) => {\n            const ocspAgent = new _external_ocsp_ocsp__WEBPACK_IMPORTED_MODULE_1__.Agent({});\n            ocspAgent.fetchIssuer(peer, null, (error, value) => {\n                if (!!error) {\n                    reject(error);\n                    return;\n                }\n                resolve(value);\n            });\n        });\n    }\n    static GetResponseFromCache(signature, ocspRequest, proxyInfo) {\n        return __awaiter(this, void 0, void 0, function* () {\n            let cachedResponse = CertCheckAgent.privMemCache[signature];\n            if (!!cachedResponse) {\n                this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_6__.OCSPMemoryCacheHitEvent(signature));\n            }\n            // Do we have a result for this certificate on disk in %TMP%?\n            if (!cachedResponse) {\n                try {\n                    // eslint-disable-next-line @typescript-eslint/no-unsafe-member-access, @typescript-eslint/no-unsafe-call\n                    const diskCacheResponse = yield CertCheckAgent.privDiskCache.get(signature);\n                    if (!!diskCacheResponse.isCached) {\n                        CertCheckAgent.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_6__.OCSPDiskCacheHitEvent(signature));\n                        CertCheckAgent.StoreMemoryCacheEntry(signature, diskCacheResponse.value);\n                        cachedResponse = diskCacheResponse.value;\n                    }\n                }\n                catch (error) {\n                    cachedResponse = null;\n                }\n            }\n            if (!cachedResponse) {\n                return cachedResponse;\n            }\n            try {\n                const cachedOcspResponse = _external_ocsp_ocsp__WEBPACK_IMPORTED_MODULE_1__.utils.parseResponse(cachedResponse);\n                const responseValue = cachedOcspResponse.value;\n                const tbsData = responseValue.tbsResponseData;\n                if (tbsData.responses.length < 1) {\n                    this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_6__.OCSPCacheFetchErrorEvent(signature, \"Not enough data in cached response\"));\n                    return;\n                }\n                const cachedStartTime = tbsData.responses[0].thisUpdate;\n                const cachedNextTime = tbsData.responses[0].nextUpdate;\n                if (cachedNextTime < (Date.now() + this.testTimeOffset - 60000)) {\n                    // Cached entry has expired.\n                    this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_6__.OCSPCacheEntryExpiredEvent(signature, cachedNextTime));\n                    cachedResponse = null;\n                }\n                else {\n                    // If we're within one day of the next update, or 50% of the way through the validity period,\n                    // background an update to the cache.\n                    const minUpdate = Math.min(24 * 60 * 60 * 1000, (cachedNextTime - cachedStartTime) / 2);\n                    if ((cachedNextTime - (Date.now() + this.testTimeOffset)) < minUpdate) {\n                        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_6__.OCSPCacheEntryNeedsRefreshEvent(signature, cachedStartTime, cachedNextTime));\n                        this.UpdateCache(ocspRequest, proxyInfo).catch((error) => {\n                            // Well, not much we can do here.\n                            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_6__.OCSPCacheUpdateErrorEvent(signature, error.toString()));\n                        });\n                    }\n                    else {\n                        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_6__.OCSPCacheHitEvent(signature, cachedStartTime, cachedNextTime));\n                    }\n                }\n            }\n            catch (error) {\n                this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_6__.OCSPCacheFetchErrorEvent(signature, error));\n                cachedResponse = null;\n            }\n            if (!cachedResponse) {\n                this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_6__.OCSPCacheMissEvent(signature));\n            }\n            return cachedResponse;\n        });\n    }\n    static VerifyOCSPResponse(cacheValue, ocspRequest, proxyInfo) {\n        return __awaiter(this, void 0, void 0, function* () {\n            let ocspResponse = cacheValue;\n            // Do we have a valid response?\n            if (!ocspResponse) {\n                ocspResponse = yield CertCheckAgent.GetOCSPResponse(ocspRequest, proxyInfo);\n            }\n            return new Promise((resolve, reject) => {\n                _external_ocsp_ocsp__WEBPACK_IMPORTED_MODULE_1__.verify({ request: ocspRequest, response: ocspResponse }, (error) => {\n                    if (!!error) {\n                        CertCheckAgent.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_6__.OCSPVerificationFailedEvent(ocspRequest.id.toString(\"hex\"), error));\n                        // Bad Cached Value? One more try without the cache.\n                        if (!!cacheValue) {\n                            this.VerifyOCSPResponse(null, ocspRequest, proxyInfo).then(() => {\n                                resolve();\n                            }, (error) => {\n                                reject(error);\n                            });\n                        }\n                        else {\n                            reject(error);\n                        }\n                    }\n                    else {\n                        if (!cacheValue) {\n                            CertCheckAgent.StoreCacheEntry(ocspRequest.id.toString(\"hex\"), ocspResponse);\n                        }\n                        resolve();\n                    }\n                });\n            });\n        });\n    }\n    static UpdateCache(req, proxyInfo) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const signature = req.id.toString(\"hex\");\n            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_6__.OCSPCacheUpdateNeededEvent(signature));\n            const rawResponse = yield this.GetOCSPResponse(req, proxyInfo);\n            this.StoreCacheEntry(signature, rawResponse);\n            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_6__.OCSPCacheUpdateCompleteEvent(req.id.toString(\"hex\")));\n        });\n    }\n    static StoreCacheEntry(sig, rawResponse) {\n        this.StoreMemoryCacheEntry(sig, rawResponse);\n        this.StoreDiskCacheEntry(sig, rawResponse);\n    }\n    static StoreMemoryCacheEntry(sig, rawResponse) {\n        this.privMemCache[sig] = rawResponse;\n        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_6__.OCSPMemoryCacheStoreEvent(sig));\n    }\n    static StoreDiskCacheEntry(sig, rawResponse) {\n        // eslint-disable-next-line @typescript-eslint/no-unsafe-member-access, @typescript-eslint/no-unsafe-call\n        this.privDiskCache.set(sig, rawResponse).then(() => {\n            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_6__.OCSPDiskCacheStoreEvent(sig));\n        });\n    }\n    static GetOCSPResponse(req, proxyInfo) {\n        const ocspMethod = \"1.3.6.1.5.5.7.48.1\";\n        let options = {};\n        if (!!proxyInfo) {\n            const agent = CertCheckAgent.GetProxyAgent(proxyInfo);\n            options.agent = agent;\n        }\n        return new Promise((resolve, reject) => {\n            _external_ocsp_ocsp__WEBPACK_IMPORTED_MODULE_1__.utils.getAuthorityInfo(req.cert, ocspMethod, (error, uri) => {\n                if (error) {\n                    reject(error);\n                    return;\n                }\n                const url = new URL(uri);\n                options = Object.assign(Object.assign({}, options), { host: url.host, protocol: url.protocol, port: url.port, path: url.pathname, hostname: url.host });\n                _external_ocsp_ocsp__WEBPACK_IMPORTED_MODULE_1__.utils.getResponse(options, req.data, (error, raw) => {\n                    if (error) {\n                        reject(error);\n                        return;\n                    }\n                    const certID = req.certID;\n                    this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_6__.OCSPResponseRetrievedEvent(certID.toString(\"hex\")));\n                    resolve(raw);\n                });\n            });\n        });\n    }\n    static onEvent(event) {\n        _common_Exports__WEBPACK_IMPORTED_MODULE_7__.Events.instance.onEvent(event);\n    }\n    CreateConnection(request, options) {\n        const enableOCSP = (typeof process !== \"undefined\" && process.env.NODE_TLS_REJECT_UNAUTHORIZED !== \"0\" && process.env.SPEECH_CONDUCT_OCSP_CHECK !== \"0\") && options.secureEndpoint;\n        let socketPromise;\n        options = Object.assign(Object.assign({}, options), {\n            requestOCSP: !CertCheckAgent.forceDisableOCSPStapling,\n            servername: options.host\n        });\n        if (!!this.privProxyInfo) {\n            const httpProxyAgent = CertCheckAgent.GetProxyAgent(this.privProxyInfo);\n            const baseAgent = httpProxyAgent;\n            socketPromise = new Promise((resolve, reject) => {\n                baseAgent.callback(request, options, (error, socket) => {\n                    if (!!error) {\n                        reject(error);\n                    }\n                    else {\n                        resolve(socket);\n                    }\n                });\n            });\n        }\n        else {\n            if (!!options.secureEndpoint) {\n                socketPromise = Promise.resolve(tls__WEBPACK_IMPORTED_MODULE_0__.connect(options));\n            }\n            else {\n                socketPromise = Promise.resolve(net__WEBPACK_IMPORTED_MODULE_5__.connect(options));\n            }\n        }\n        if (!!enableOCSP) {\n            return CertCheckAgent.OCSPCheck(socketPromise, this.privProxyInfo);\n        }\n        else {\n            return socketPromise;\n        }\n    }\n}\n// Test hook to enable forcing expiration / refresh to happen.\nCertCheckAgent.testTimeOffset = 0;\n// Test hook to disable stapling for cache testing.\nCertCheckAgent.forceDisableOCSPStapling = false;\n// An in memory cache for recived responses.\nCertCheckAgent.privMemCache = {};\n\n//# sourceMappingURL=CertChecks.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/CertChecks.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/FileAudioSource.js":
  /*!******************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/FileAudioSource.js ***!
    \******************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"FileAudioSource\": () => (/* binding */ FileAudioSource)\n/* harmony export */ });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/EventSource.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/AudioSourceEvents.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ChunkedArrayBufferStream.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Events.js\");\n/* harmony import */ var _sdk_Audio_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../sdk/Audio/AudioStreamFormat */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioStreamFormat.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\nclass FileAudioSource {\n    constructor(file, filename, audioSourceId) {\n        this.privStreams = {};\n        this.privHeaderEnd = 44;\n        this.privId = audioSourceId ? audioSourceId : (0,_common_Exports__WEBPACK_IMPORTED_MODULE_0__.createNoDashGuid)();\n        this.privEvents = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.EventSource();\n        this.privSource = file;\n        if (typeof window !== \"undefined\" && typeof Blob !== \"undefined\" && this.privSource instanceof Blob) {\n            this.privFilename = file.name;\n        }\n        else {\n            this.privFilename = filename || \"unknown.wav\";\n        }\n        // Read the header.\n        this.privAudioFormatPromise = this.readHeader();\n    }\n    get format() {\n        return this.privAudioFormatPromise;\n    }\n    get blob() {\n        return Promise.resolve(this.privSource);\n    }\n    turnOn() {\n        if (this.privFilename.lastIndexOf(\".wav\") !== this.privFilename.length - 4) {\n            const errorMsg = this.privFilename + \" is not supported. Only WAVE files are allowed at the moment.\";\n            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.AudioSourceErrorEvent(errorMsg, \"\"));\n            return Promise.reject(errorMsg);\n        }\n        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.AudioSourceInitializingEvent(this.privId)); // no stream id\n        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.AudioSourceReadyEvent(this.privId));\n        return;\n    }\n    id() {\n        return this.privId;\n    }\n    attach(audioNodeId) {\n        return __awaiter(this, void 0, void 0, function* () {\n            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.AudioStreamNodeAttachingEvent(this.privId, audioNodeId));\n            const stream = yield this.upload(audioNodeId);\n            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.AudioStreamNodeAttachedEvent(this.privId, audioNodeId));\n            return Promise.resolve({\n                detach: () => __awaiter(this, void 0, void 0, function* () {\n                    stream.readEnded();\n                    delete this.privStreams[audioNodeId];\n                    this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.AudioStreamNodeDetachedEvent(this.privId, audioNodeId));\n                    yield this.turnOff();\n                }),\n                id: () => audioNodeId,\n                read: () => stream.read(),\n            });\n        });\n    }\n    detach(audioNodeId) {\n        if (audioNodeId && this.privStreams[audioNodeId]) {\n            this.privStreams[audioNodeId].close();\n            delete this.privStreams[audioNodeId];\n            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.AudioStreamNodeDetachedEvent(this.privId, audioNodeId));\n        }\n    }\n    turnOff() {\n        for (const streamId in this.privStreams) {\n            if (streamId) {\n                const stream = this.privStreams[streamId];\n                if (stream && !stream.isClosed) {\n                    stream.close();\n                }\n            }\n        }\n        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.AudioSourceOffEvent(this.privId)); // no stream now\n        return Promise.resolve();\n    }\n    get events() {\n        return this.privEvents;\n    }\n    get deviceInfo() {\n        return this.privAudioFormatPromise.then((result) => (Promise.resolve({\n            bitspersample: result.bitsPerSample,\n            channelcount: result.channels,\n            connectivity: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__.connectivity.Unknown,\n            manufacturer: \"Speech SDK\",\n            model: \"File\",\n            samplerate: result.samplesPerSec,\n            type: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__.type.File,\n        })));\n    }\n    readHeader() {\n        // Read the wave header.\n        const maxHeaderSize = 4296;\n        const header = this.privSource.slice(0, maxHeaderSize);\n        const headerResult = new _common_Exports__WEBPACK_IMPORTED_MODULE_4__.Deferred();\n        const processHeader = (header) => {\n            const view = new DataView(header);\n            const getWord = (index) => String.fromCharCode(view.getUint8(index), view.getUint8(index + 1), view.getUint8(index + 2), view.getUint8(index + 3));\n            // RIFF 4 bytes.\n            if (\"RIFF\" !== getWord(0)) {\n                headerResult.reject(\"Invalid WAV header in file, RIFF was not found\");\n                return;\n            }\n            // length, 4 bytes\n            // RIFF Type & fmt 8 bytes\n            if (\"WAVE\" !== getWord(8) || \"fmt \" !== getWord(12)) {\n                headerResult.reject(\"Invalid WAV header in file, WAVEfmt was not found\");\n                return;\n            }\n            const formatSize = view.getInt32(16, true);\n            const channelCount = view.getUint16(22, true);\n            const sampleRate = view.getUint32(24, true);\n            const bitsPerSample = view.getUint16(34, true);\n            // Confirm if header is 44 bytes long.\n            let pos = 36 + Math.max(formatSize - 16, 0);\n            for (; getWord(pos) !== \"data\"; pos += 2) {\n                if (pos > maxHeaderSize - 8) {\n                    headerResult.reject(\"Invalid WAV header in file, data block was not found\");\n                    return;\n                }\n            }\n            this.privHeaderEnd = pos + 8;\n            headerResult.resolve(_sdk_Audio_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_5__.AudioStreamFormat.getWaveFormatPCM(sampleRate, bitsPerSample, channelCount));\n        };\n        if (typeof window !== \"undefined\" && typeof Blob !== \"undefined\" && header instanceof Blob) {\n            const reader = new FileReader();\n            reader.onload = (event) => {\n                const header = event.target.result;\n                processHeader(header);\n            };\n            reader.readAsArrayBuffer(header);\n        }\n        else {\n            const h = header;\n            processHeader(h.buffer.slice(h.byteOffset, h.byteOffset + h.byteLength));\n        }\n        return headerResult.promise;\n    }\n    upload(audioNodeId) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const onerror = (error) => {\n                const errorMsg = `Error occurred while processing '${this.privFilename}'. ${error}`;\n                this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.AudioStreamNodeErrorEvent(this.privId, audioNodeId, errorMsg));\n                throw new Error(errorMsg);\n            };\n            try {\n                yield this.turnOn();\n                const format = yield this.privAudioFormatPromise;\n                const stream = new _common_Exports__WEBPACK_IMPORTED_MODULE_6__.ChunkedArrayBufferStream(format.avgBytesPerSec / 10, audioNodeId);\n                this.privStreams[audioNodeId] = stream;\n                const chunk = this.privSource.slice(this.privHeaderEnd);\n                const processFile = (buff) => {\n                    if (stream.isClosed) {\n                        return; // output stream was closed (somebody called TurnOff). We're done here.\n                    }\n                    stream.writeStreamChunk({\n                        buffer: buff,\n                        isEnd: false,\n                        timeReceived: Date.now(),\n                    });\n                    stream.close();\n                };\n                if (typeof window !== \"undefined\" && typeof Blob !== \"undefined\" && chunk instanceof Blob) {\n                    const reader = new FileReader();\n                    reader.onerror = (ev) => onerror(ev.toString());\n                    reader.onload = (event) => {\n                        const fileBuffer = event.target.result;\n                        processFile(fileBuffer);\n                    };\n                    reader.readAsArrayBuffer(chunk);\n                }\n                else {\n                    const c = chunk;\n                    processFile(c.buffer.slice(c.byteOffset, c.byteOffset + c.byteLength));\n                }\n                return stream;\n            }\n            catch (e) {\n                onerror(e);\n            }\n        });\n    }\n    onEvent(event) {\n        this.privEvents.onEvent(event);\n        _common_Exports__WEBPACK_IMPORTED_MODULE_7__.Events.instance.onEvent(event);\n    }\n}\n\n//# sourceMappingURL=FileAudioSource.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/FileAudioSource.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/MicAudioSource.js":
  /*!*****************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/MicAudioSource.js ***!
    \*****************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AudioWorkletSourceURLPropertyName\": () => (/* binding */ AudioWorkletSourceURLPropertyName),\n/* harmony export */   \"MicAudioSource\": () => (/* binding */ MicAudioSource)\n/* harmony export */ });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/EventSource.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/AudioSourceEvents.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ChunkedArrayBufferStream.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Events.js\");\n/* harmony import */ var _sdk_Audio_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../sdk/Audio/AudioStreamFormat */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioStreamFormat.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\nconst AudioWorkletSourceURLPropertyName = \"MICROPHONE-WorkletSourceUrl\";\nclass MicAudioSource {\n    constructor(privRecorder, deviceId, audioSourceId, mediaStream) {\n        this.privRecorder = privRecorder;\n        this.deviceId = deviceId;\n        this.privStreams = {};\n        this.privOutputChunkSize = MicAudioSource.AUDIOFORMAT.avgBytesPerSec / 10;\n        this.privId = audioSourceId ? audioSourceId : (0,_common_Exports__WEBPACK_IMPORTED_MODULE_0__.createNoDashGuid)();\n        this.privEvents = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.EventSource();\n        this.privMediaStream = mediaStream || null;\n        this.privIsClosing = false;\n    }\n    get format() {\n        return Promise.resolve(MicAudioSource.AUDIOFORMAT);\n    }\n    get blob() {\n        return Promise.reject(\"Not implemented for Mic input\");\n    }\n    turnOn() {\n        if (this.privInitializeDeferral) {\n            return this.privInitializeDeferral.promise;\n        }\n        this.privInitializeDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.Deferred();\n        try {\n            this.createAudioContext();\n        }\n        catch (error) {\n            if (error instanceof Error) {\n                const typedError = error;\n                this.privInitializeDeferral.reject(typedError.name + \": \" + typedError.message);\n            }\n            else {\n                this.privInitializeDeferral.reject(error);\n            }\n            return this.privInitializeDeferral.promise;\n        }\n        const nav = window.navigator;\n        let getUserMedia = (\n        // eslint-disable-next-line\n        nav.getUserMedia ||\n            nav.webkitGetUserMedia ||\n            nav.mozGetUserMedia ||\n            nav.msGetUserMedia);\n        if (!!nav.mediaDevices) {\n            getUserMedia = (constraints, successCallback, errorCallback) => {\n                nav.mediaDevices\n                    .getUserMedia(constraints)\n                    .then(successCallback)\n                    .catch(errorCallback);\n            };\n        }\n        if (!getUserMedia) {\n            const errorMsg = \"Browser does not support getUserMedia.\";\n            this.privInitializeDeferral.reject(errorMsg);\n            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_3__.AudioSourceErrorEvent(errorMsg, \"\")); // mic initialized error - no streamid at this point\n        }\n        else {\n            const next = () => {\n                this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_3__.AudioSourceInitializingEvent(this.privId)); // no stream id\n                if (this.privMediaStream && this.privMediaStream.active) {\n                    this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_3__.AudioSourceReadyEvent(this.privId));\n                    this.privInitializeDeferral.resolve();\n                }\n                else {\n                    getUserMedia({ audio: this.deviceId ? { deviceId: this.deviceId } : true, video: false }, (mediaStream) => {\n                        this.privMediaStream = mediaStream;\n                        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_3__.AudioSourceReadyEvent(this.privId));\n                        this.privInitializeDeferral.resolve();\n                    }, (error) => {\n                        const errorMsg = `Error occurred during microphone initialization: ${error}`;\n                        this.privInitializeDeferral.reject(errorMsg);\n                        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_3__.AudioSourceErrorEvent(this.privId, errorMsg));\n                    });\n                }\n            };\n            if (this.privContext.state === \"suspended\") {\n                // NOTE: On iOS, the Web Audio API requires sounds to be triggered from an explicit user action.\n                // https://github.com/WebAudio/web-audio-api/issues/790\n                this.privContext.resume()\n                    .then(next)\n                    .catch((reason) => {\n                    this.privInitializeDeferral.reject(`Failed to initialize audio context: ${reason}`);\n                });\n            }\n            else {\n                next();\n            }\n        }\n        return this.privInitializeDeferral.promise;\n    }\n    id() {\n        return this.privId;\n    }\n    attach(audioNodeId) {\n        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_3__.AudioStreamNodeAttachingEvent(this.privId, audioNodeId));\n        return this.listen(audioNodeId).then((stream) => {\n            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_3__.AudioStreamNodeAttachedEvent(this.privId, audioNodeId));\n            return {\n                detach: () => __awaiter(this, void 0, void 0, function* () {\n                    stream.readEnded();\n                    delete this.privStreams[audioNodeId];\n                    this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_3__.AudioStreamNodeDetachedEvent(this.privId, audioNodeId));\n                    return this.turnOff();\n                }),\n                id: () => audioNodeId,\n                read: () => stream.read(),\n            };\n        });\n    }\n    detach(audioNodeId) {\n        if (audioNodeId && this.privStreams[audioNodeId]) {\n            this.privStreams[audioNodeId].close();\n            delete this.privStreams[audioNodeId];\n            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_3__.AudioStreamNodeDetachedEvent(this.privId, audioNodeId));\n        }\n    }\n    turnOff() {\n        return __awaiter(this, void 0, void 0, function* () {\n            for (const streamId in this.privStreams) {\n                if (streamId) {\n                    const stream = this.privStreams[streamId];\n                    if (stream) {\n                        stream.close();\n                    }\n                }\n            }\n            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_3__.AudioSourceOffEvent(this.privId)); // no stream now\n            if (this.privInitializeDeferral) {\n                // Correctly handle when browser forces mic off before turnOn() completes\n                // eslint-disable-next-line @typescript-eslint/await-thenable\n                yield this.privInitializeDeferral;\n                this.privInitializeDeferral = null;\n            }\n            yield this.destroyAudioContext();\n            return;\n        });\n    }\n    get events() {\n        return this.privEvents;\n    }\n    get deviceInfo() {\n        return this.getMicrophoneLabel().then((label) => ({\n            bitspersample: MicAudioSource.AUDIOFORMAT.bitsPerSample,\n            channelcount: MicAudioSource.AUDIOFORMAT.channels,\n            connectivity: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.connectivity.Unknown,\n            manufacturer: \"Speech SDK\",\n            model: label,\n            samplerate: MicAudioSource.AUDIOFORMAT.samplesPerSec,\n            type: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.type.Microphones,\n        }));\n    }\n    setProperty(name, value) {\n        if (name === AudioWorkletSourceURLPropertyName) {\n            this.privRecorder.setWorkletUrl(value);\n        }\n        else {\n            throw new Error(\"Property '\" + name + \"' is not supported on Microphone.\");\n        }\n    }\n    getMicrophoneLabel() {\n        const defaultMicrophoneName = \"microphone\";\n        // If we did this already, return the value.\n        if (this.privMicrophoneLabel !== undefined) {\n            return Promise.resolve(this.privMicrophoneLabel);\n        }\n        // If the stream isn't currently running, we can't query devices because security.\n        if (this.privMediaStream === undefined || !this.privMediaStream.active) {\n            return Promise.resolve(defaultMicrophoneName);\n        }\n        // Setup a default\n        this.privMicrophoneLabel = defaultMicrophoneName;\n        // Get the id of the device running the audio track.\n        const microphoneDeviceId = this.privMediaStream.getTracks()[0].getSettings().deviceId;\n        // If the browser doesn't support getting the device ID, set a default and return.\n        if (undefined === microphoneDeviceId) {\n            return Promise.resolve(this.privMicrophoneLabel);\n        }\n        const deferred = new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.Deferred();\n        // Enumerate the media devices.\n        navigator.mediaDevices.enumerateDevices().then((devices) => {\n            for (const device of devices) {\n                if (device.deviceId === microphoneDeviceId) {\n                    // Found the device\n                    this.privMicrophoneLabel = device.label;\n                    break;\n                }\n            }\n            deferred.resolve(this.privMicrophoneLabel);\n        }, () => deferred.resolve(this.privMicrophoneLabel));\n        return deferred.promise;\n    }\n    listen(audioNodeId) {\n        return __awaiter(this, void 0, void 0, function* () {\n            yield this.turnOn();\n            const stream = new _common_Exports__WEBPACK_IMPORTED_MODULE_5__.ChunkedArrayBufferStream(this.privOutputChunkSize, audioNodeId);\n            this.privStreams[audioNodeId] = stream;\n            try {\n                this.privRecorder.record(this.privContext, this.privMediaStream, stream);\n            }\n            catch (error) {\n                this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_3__.AudioStreamNodeErrorEvent(this.privId, audioNodeId, error));\n                throw error;\n            }\n            const result = stream;\n            return result;\n        });\n    }\n    onEvent(event) {\n        this.privEvents.onEvent(event);\n        _common_Exports__WEBPACK_IMPORTED_MODULE_6__.Events.instance.onEvent(event);\n    }\n    createAudioContext() {\n        if (!!this.privContext) {\n            return;\n        }\n        this.privContext = _sdk_Audio_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_7__.AudioStreamFormatImpl.getAudioContext(MicAudioSource.AUDIOFORMAT.samplesPerSec);\n    }\n    destroyAudioContext() {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (!this.privContext) {\n                return;\n            }\n            this.privRecorder.releaseMediaResources(this.privContext);\n            // This pattern brought to you by a bug in the TypeScript compiler where it\n            // confuses the (\"close\" in this.privContext) with this.privContext always being null as the alternate.\n            // https://github.com/Microsoft/TypeScript/issues/11498\n            let hasClose = false;\n            if (\"close\" in this.privContext) {\n                hasClose = true;\n            }\n            if (hasClose) {\n                if (!this.privIsClosing) {\n                    // The audio context close may take enough time that the close is called twice\n                    this.privIsClosing = true;\n                    yield this.privContext.close();\n                    this.privContext = null;\n                    this.privIsClosing = false;\n                }\n            }\n            else if (null !== this.privContext && this.privContext.state === \"running\") {\n                // Suspend actually takes a callback, but analogous to the\n                // resume method, it'll be only fired if suspend is called\n                // in a direct response to a user action. The later is not always\n                // the case, as TurnOff is also called, when we receive an\n                // end-of-speech message from the service. So, doing a best effort\n                // fire-and-forget here.\n                yield this.privContext.suspend();\n            }\n        });\n    }\n}\nMicAudioSource.AUDIOFORMAT = _sdk_Audio_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_7__.AudioStreamFormat.getDefaultInputFormat();\n\n//# sourceMappingURL=MicAudioSource.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/MicAudioSource.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/PCMRecorder.js":
  /*!**************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/PCMRecorder.js ***!
    \**************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"PcmRecorder\": () => (/* binding */ PcmRecorder)\n/* harmony export */ });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/RiffPcmEncoder.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nclass PcmRecorder {\n    constructor(stopInputOnRelease) {\n        this.privStopInputOnRelease = stopInputOnRelease;\n    }\n    record(context, mediaStream, outputStream) {\n        const desiredSampleRate = 16000;\n        const waveStreamEncoder = new _common_Exports__WEBPACK_IMPORTED_MODULE_0__.RiffPcmEncoder(context.sampleRate, desiredSampleRate);\n        const micInput = context.createMediaStreamSource(mediaStream);\n        const attachScriptProcessor = () => {\n            // eslint-disable-next-line @typescript-eslint/explicit-function-return-type\n            const scriptNode = (() => {\n                let bufferSize = 0;\n                try {\n                    return context.createScriptProcessor(bufferSize, 1, 1);\n                }\n                catch (error) {\n                    // Webkit (<= version 31) requires a valid bufferSize.\n                    bufferSize = 2048;\n                    let audioSampleRate = context.sampleRate;\n                    while (bufferSize < 16384 && audioSampleRate >= (2 * desiredSampleRate)) {\n                        bufferSize <<= 1;\n                        audioSampleRate >>= 1;\n                    }\n                    return context.createScriptProcessor(bufferSize, 1, 1);\n                }\n            })();\n            scriptNode.onaudioprocess = (event) => {\n                const inputFrame = event.inputBuffer.getChannelData(0);\n                if (outputStream && !outputStream.isClosed) {\n                    const waveFrame = waveStreamEncoder.encode(inputFrame);\n                    if (!!waveFrame) {\n                        outputStream.writeStreamChunk({\n                            buffer: waveFrame,\n                            isEnd: false,\n                            timeReceived: Date.now(),\n                        });\n                    }\n                }\n            };\n            micInput.connect(scriptNode);\n            scriptNode.connect(context.destination);\n            this.privMediaResources = {\n                scriptProcessorNode: scriptNode,\n                source: micInput,\n                stream: mediaStream,\n            };\n        };\n        // https://webaudio.github.io/web-audio-api/#audioworklet\n        // Using AudioWorklet to improve audio quality and avoid audio glitches due to blocking the UI thread\n        if (!!context.audioWorklet) {\n            if (!this.privSpeechProcessorScript) {\n                const workletScript = `class SP extends AudioWorkletProcessor {\r\n                    constructor(options) {\r\n                      super(options);\r\n                    }\r\n                    process(inputs, outputs) {\r\n                      const input = inputs[0];\r\n                      const output = [];\r\n                      for (let channel = 0; channel < input.length; channel += 1) {\r\n                        output[channel] = input[channel];\r\n                      }\r\n                      this.port.postMessage(output[0]);\r\n                      return true;\r\n                    }\r\n                  }\r\n                  registerProcessor('speech-processor', SP);`;\n                const blob = new Blob([workletScript], { type: \"application/javascript; charset=utf-8\" });\n                this.privSpeechProcessorScript = URL.createObjectURL(blob);\n            }\n            context.audioWorklet\n                .addModule(this.privSpeechProcessorScript)\n                .then(() => {\n                const workletNode = new AudioWorkletNode(context, \"speech-processor\");\n                workletNode.port.onmessage = (ev) => {\n                    const inputFrame = ev.data;\n                    if (outputStream && !outputStream.isClosed) {\n                        const waveFrame = waveStreamEncoder.encode(inputFrame);\n                        if (!!waveFrame) {\n                            outputStream.writeStreamChunk({\n                                buffer: waveFrame,\n                                isEnd: false,\n                                timeReceived: Date.now(),\n                            });\n                        }\n                    }\n                };\n                micInput.connect(workletNode);\n                workletNode.connect(context.destination);\n                this.privMediaResources = {\n                    scriptProcessorNode: workletNode,\n                    source: micInput,\n                    stream: mediaStream,\n                };\n            })\n                .catch(() => {\n                attachScriptProcessor();\n            });\n        }\n        else {\n            try {\n                attachScriptProcessor();\n            }\n            catch (err) {\n                throw new Error(`Unable to start audio worklet node for PCMRecorder: ${err}`);\n            }\n        }\n    }\n    releaseMediaResources(context) {\n        if (this.privMediaResources) {\n            if (this.privMediaResources.scriptProcessorNode) {\n                this.privMediaResources.scriptProcessorNode.disconnect(context.destination);\n                this.privMediaResources.scriptProcessorNode = null;\n            }\n            if (this.privMediaResources.source) {\n                this.privMediaResources.source.disconnect();\n                if (this.privStopInputOnRelease) {\n                    this.privMediaResources.stream.getTracks().forEach((track) => track.stop());\n                }\n                this.privMediaResources.source = null;\n            }\n        }\n    }\n    setWorkletUrl(url) {\n        this.privSpeechProcessorScript = url;\n    }\n}\n\n//# sourceMappingURL=PCMRecorder.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/PCMRecorder.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ProxyInfo.js":
  /*!************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ProxyInfo.js ***!
    \************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ProxyInfo\": () => (/* binding */ ProxyInfo)\n/* harmony export */ });\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nclass ProxyInfo {\n    constructor(proxyHostName, proxyPort, proxyUserName, proxyPassword) {\n        this.privProxyHostName = proxyHostName;\n        this.privProxyPort = proxyPort;\n        this.privProxyUserName = proxyUserName;\n        this.privProxyPassword = proxyPassword;\n    }\n    static fromParameters(parameters) {\n        return new ProxyInfo(parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_ProxyHostName), parseInt(parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_ProxyPort), 10), parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_ProxyUserName), parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_ProxyPassword));\n    }\n    static fromRecognizerConfig(config) {\n        return this.fromParameters(config.parameters);\n    }\n    get HostName() {\n        return this.privProxyHostName;\n    }\n    get Port() {\n        return this.privProxyPort;\n    }\n    get UserName() {\n        return this.privProxyUserName;\n    }\n    get Password() {\n        return this.privProxyPassword;\n    }\n}\n\n//# sourceMappingURL=ProxyInfo.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ProxyInfo.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ReplayableAudioNode.js":
  /*!**********************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ReplayableAudioNode.js ***!
    \**********************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ReplayableAudioNode\": () => (/* binding */ ReplayableAudioNode)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nclass ReplayableAudioNode {\n    constructor(audioSource, bytesPerSecond) {\n        this.privBuffers = [];\n        this.privReplayOffset = 0;\n        this.privLastShrinkOffset = 0;\n        this.privBufferStartOffset = 0;\n        this.privBufferSerial = 0;\n        this.privBufferedBytes = 0;\n        this.privReplay = false;\n        this.privLastChunkAcquiredTime = 0;\n        this.privAudioNode = audioSource;\n        this.privBytesPerSecond = bytesPerSecond;\n    }\n    id() {\n        return this.privAudioNode.id();\n    }\n    // Reads and returns the next chunk of audio buffer.\n    // If replay of existing buffers are needed, read() will first seek and replay\n    // existing content, and upoin completion it will read new content from the underlying\n    // audio node, saving that content into the replayable buffers.\n    read() {\n        // if there is a replay request to honor.\n        if (!!this.privReplay && this.privBuffers.length !== 0) {\n            // Find the start point in the buffers.\n            // Offsets are in 100ns increments.\n            // So how many bytes do we need to seek to get the right offset?\n            const offsetToSeek = this.privReplayOffset - this.privBufferStartOffset;\n            let bytesToSeek = Math.round(offsetToSeek * this.privBytesPerSecond * 1e-7);\n            if (0 !== (bytesToSeek % 2)) {\n                bytesToSeek++;\n            }\n            let i = 0;\n            while (i < this.privBuffers.length && bytesToSeek >= this.privBuffers[i].chunk.buffer.byteLength) {\n                bytesToSeek -= this.privBuffers[i++].chunk.buffer.byteLength;\n            }\n            if (i < this.privBuffers.length) {\n                const retVal = this.privBuffers[i].chunk.buffer.slice(bytesToSeek);\n                this.privReplayOffset += (retVal.byteLength / this.privBytesPerSecond) * 1e+7;\n                // If we've reached the end of the buffers, stop replaying.\n                if (i === this.privBuffers.length - 1) {\n                    this.privReplay = false;\n                }\n                return Promise.resolve({\n                    buffer: retVal,\n                    isEnd: false,\n                    timeReceived: this.privBuffers[i].chunk.timeReceived,\n                });\n            }\n        }\n        return this.privAudioNode.read()\n            .then((result) => {\n            if (result && result.buffer) {\n                this.privBuffers.push(new BufferEntry(result, this.privBufferSerial++, this.privBufferedBytes));\n                this.privBufferedBytes += result.buffer.byteLength;\n            }\n            return result;\n        });\n    }\n    detach() {\n        this.privBuffers = undefined;\n        return this.privAudioNode.detach();\n    }\n    replay() {\n        if (this.privBuffers && 0 !== this.privBuffers.length) {\n            this.privReplay = true;\n            this.privReplayOffset = this.privLastShrinkOffset;\n        }\n    }\n    // Shrinks the existing audio buffers to start at the new offset, or at the\n    // beginning of the buffer closest to the requested offset.\n    // A replay request will start from the last shrink point.\n    shrinkBuffers(offset) {\n        if (this.privBuffers === undefined || this.privBuffers.length === 0) {\n            return;\n        }\n        this.privLastShrinkOffset = offset;\n        // Find the start point in the buffers.\n        // Offsets are in 100ns increments.\n        // So how many bytes do we need to seek to get the right offset?\n        const offsetToSeek = offset - this.privBufferStartOffset;\n        let bytesToSeek = Math.round(offsetToSeek * this.privBytesPerSecond * 1e-7);\n        let i = 0;\n        while (i < this.privBuffers.length && bytesToSeek >= this.privBuffers[i].chunk.buffer.byteLength) {\n            bytesToSeek -= this.privBuffers[i++].chunk.buffer.byteLength;\n        }\n        this.privBufferStartOffset = Math.round(offset - ((bytesToSeek / this.privBytesPerSecond) * 1e+7));\n        this.privBuffers = this.privBuffers.slice(i);\n    }\n    // Finds the time a buffer of audio was first seen by offset.\n    findTimeAtOffset(offset) {\n        if (offset < this.privBufferStartOffset || this.privBuffers === undefined) {\n            return 0;\n        }\n        for (const value of this.privBuffers) {\n            const startOffset = (value.byteOffset / this.privBytesPerSecond) * 1e7;\n            const endOffset = startOffset + ((value.chunk.buffer.byteLength / this.privBytesPerSecond) * 1e7);\n            if (offset >= startOffset && offset <= endOffset) {\n                return value.chunk.timeReceived;\n            }\n        }\n        return 0;\n    }\n}\n// Primary use of this class is to help debugging problems with the replay\n// code. If the memory cost of alloc / dealloc gets too much, drop it and just use\n// the ArrayBuffer directly.\nclass BufferEntry {\n    constructor(chunk, serial, byteOffset) {\n        this.chunk = chunk;\n        this.serial = serial;\n        this.byteOffset = byteOffset;\n    }\n}\n\n//# sourceMappingURL=ReplayableAudioNode.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ReplayableAudioNode.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/RestConfigBase.js":
  /*!*****************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/RestConfigBase.js ***!
    \*****************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"RestConfigBase\": () => (/* binding */ RestConfigBase)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nclass RestConfigBase {\n    static get requestOptions() {\n        return RestConfigBase.privDefaultRequestOptions;\n    }\n    static get configParams() {\n        return RestConfigBase.privDefaultParams;\n    }\n    static get restErrors() {\n        return RestConfigBase.privRestErrors;\n    }\n}\nRestConfigBase.privDefaultRequestOptions = {\n    headers: {\n        Accept: \"application/json\",\n    },\n    ignoreCache: false,\n    timeout: 10000,\n};\nRestConfigBase.privRestErrors = {\n    authInvalidSubscriptionKey: \"You must specify either an authentication token to use, or a Cognitive Speech subscription key.\",\n    authInvalidSubscriptionRegion: \"You must specify the Cognitive Speech region to use.\",\n    invalidArgs: \"Required input not found: {arg}.\",\n    invalidCreateJoinConversationResponse: \"Creating/Joining conversation failed with HTTP {status}.\",\n    invalidParticipantRequest: \"The requested participant was not found.\",\n    permissionDeniedConnect: \"Required credentials not found.\",\n    permissionDeniedConversation: \"Invalid operation: only the host can {command} the conversation.\",\n    permissionDeniedParticipant: \"Invalid operation: only the host can {command} a participant.\",\n    permissionDeniedSend: \"Invalid operation: the conversation is not in a connected state.\",\n    permissionDeniedStart: \"Invalid operation: there is already an active conversation.\",\n};\nRestConfigBase.privDefaultParams = {\n    apiVersion: \"api-version\",\n    authorization: \"Authorization\",\n    clientAppId: \"X-ClientAppId\",\n    contentTypeKey: \"Content-Type\",\n    correlationId: \"X-CorrelationId\",\n    languageCode: \"language\",\n    nickname: \"nickname\",\n    profanity: \"profanity\",\n    requestId: \"X-RequestId\",\n    roomId: \"roomid\",\n    sessionToken: \"token\",\n    subscriptionKey: \"Ocp-Apim-Subscription-Key\",\n    subscriptionRegion: \"Ocp-Apim-Subscription-Region\",\n    token: \"X-CapitoToken\",\n};\n\n//# sourceMappingURL=RestConfigBase.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/RestConfigBase.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/RestMessageAdapter.js":
  /*!*********************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/RestMessageAdapter.js ***!
    \*********************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"RestMessageAdapter\": () => (/* binding */ RestMessageAdapter),\n/* harmony export */   \"RestRequestType\": () => (/* binding */ RestRequestType)\n/* harmony export */ });\n/* harmony import */ var bent__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! bent */ \"./node_modules/bent/src/browser.js\");\n/* harmony import */ var bent__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(bent__WEBPACK_IMPORTED_MODULE_0__);\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\nvar RestRequestType;\n(function (RestRequestType) {\n    RestRequestType[\"Get\"] = \"GET\";\n    RestRequestType[\"Post\"] = \"POST\";\n    RestRequestType[\"Delete\"] = \"DELETE\";\n    RestRequestType[\"File\"] = \"file\";\n})(RestRequestType || (RestRequestType = {}));\n// accept rest operations via request method and return abstracted objects from server response\nclass RestMessageAdapter {\n    constructor(configParams) {\n        if (!configParams) {\n            throw new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.ArgumentNullError(\"configParams\");\n        }\n        this.privHeaders = configParams.headers;\n        this.privIgnoreCache = configParams.ignoreCache;\n    }\n    static extractHeaderValue(headerKey, headers) {\n        let headerValue = \"\";\n        try {\n            const arr = headers.trim().split(/[\\r\\n]+/);\n            const headerMap = {};\n            arr.forEach((line) => {\n                const parts = line.split(\": \");\n                const header = parts.shift().toLowerCase();\n                const value = parts.join(\": \");\n                headerMap[header] = value;\n            });\n            headerValue = headerMap[headerKey.toLowerCase()];\n        }\n        catch (e) {\n            // ignore the error\n        }\n        return headerValue;\n    }\n    set options(configParams) {\n        this.privHeaders = configParams.headers;\n        this.privIgnoreCache = configParams.ignoreCache;\n    }\n    setHeaders(key, value) {\n        this.privHeaders[key] = value;\n    }\n    request(method, uri, queryParams = {}, body = null, binaryBody = null) {\n        const responseReceivedDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.Deferred();\n        const requestCommand = method === RestRequestType.File ? \"POST\" : method;\n        const handleRestResponse = (data, j = {}) => {\n            const d = data;\n            return {\n                data: JSON.stringify(j),\n                headers: JSON.stringify(data.headers),\n                json: j,\n                ok: data.statusCode >= 200 && data.statusCode < 300,\n                status: data.statusCode,\n                statusText: j.error ? j.error.message : d.statusText ? d.statusText : d.statusMessage\n            };\n        };\n        const blobToArrayBuffer = (blob) => {\n            const reader = new FileReader();\n            reader.readAsArrayBuffer(blob);\n            return new Promise((resolve) => {\n                reader.onloadend = () => {\n                    resolve(reader.result);\n                };\n            });\n        };\n        const send = (postData) => {\n            const sendRequest = bent__WEBPACK_IMPORTED_MODULE_0___default()(uri, requestCommand, this.privHeaders, 200, 201, 202, 204, 400, 401, 402, 403, 404);\n            const params = this.queryParams(queryParams) === \"\" ? \"\" : `?${this.queryParams(queryParams)}`;\n            sendRequest(params, postData).then((data) => __awaiter(this, void 0, void 0, function* () {\n                if (method === RestRequestType.Delete || data.statusCode === 204) {\n                    // No JSON from Delete and reset (204) operations\n                    responseReceivedDeferral.resolve(handleRestResponse(data));\n                }\n                else {\n                    try {\n                        const j = yield data.json();\n                        responseReceivedDeferral.resolve(handleRestResponse(data, j));\n                    }\n                    catch (_a) {\n                        responseReceivedDeferral.resolve(handleRestResponse(data));\n                    }\n                }\n            })).catch((error) => {\n                responseReceivedDeferral.reject(error);\n            });\n        };\n        if (this.privIgnoreCache) {\n            this.privHeaders[\"Cache-Control\"] = \"no-cache\";\n        }\n        if (method === RestRequestType.File && binaryBody) {\n            const contentType = \"multipart/form-data\";\n            this.privHeaders[\"content-type\"] = contentType;\n            this.privHeaders[\"Content-Type\"] = contentType;\n            if (typeof (Blob) !== \"undefined\" && binaryBody instanceof Blob) {\n                blobToArrayBuffer(binaryBody).then((res) => {\n                    send(res);\n                }).catch((error) => {\n                    responseReceivedDeferral.reject(error);\n                });\n            }\n            else {\n                send(binaryBody);\n            }\n        }\n        else {\n            if (method === RestRequestType.Post && body) {\n                this.privHeaders[\"content-type\"] = \"application/json\";\n                this.privHeaders[\"Content-Type\"] = \"application/json\";\n            }\n            send(body);\n        }\n        return responseReceivedDeferral.promise;\n    }\n    withQuery(url, params = {}) {\n        const queryString = this.queryParams(params);\n        return queryString ? url + (url.indexOf(\"?\") === -1 ? \"?\" : \"&\") + queryString : url;\n    }\n    queryParams(params = {}) {\n        return Object.keys(params)\n            .map((k) => encodeURIComponent(k) + \"=\" + encodeURIComponent(params[k]))\n            .join(\"&\");\n    }\n}\n\n//# sourceMappingURL=RestMessageAdapter.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/RestMessageAdapter.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketConnection.js":
  /*!**********************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketConnection.js ***!
    \**********************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"WebsocketConnection\": () => (/* binding */ WebsocketConnection)\n/* harmony export */ });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js\");\n/* harmony import */ var _WebsocketMessageAdapter__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./WebsocketMessageAdapter */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketMessageAdapter.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\nclass WebsocketConnection {\n    constructor(uri, queryParameters, headers, messageFormatter, proxyInfo, enableCompression = false, connectionId) {\n        this.privIsDisposed = false;\n        if (!uri) {\n            throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__.ArgumentNullError(\"uri\");\n        }\n        if (!messageFormatter) {\n            throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__.ArgumentNullError(\"messageFormatter\");\n        }\n        this.privMessageFormatter = messageFormatter;\n        let queryParams = \"\";\n        let i = 0;\n        if (queryParameters) {\n            for (const paramName in queryParameters) {\n                if (paramName) {\n                    queryParams += ((i === 0) && (uri.indexOf(\"?\") === -1)) ? \"?\" : \"&\";\n                    const key = encodeURIComponent(paramName);\n                    queryParams += key;\n                    let val = queryParameters[paramName];\n                    if (val) {\n                        val = encodeURIComponent(val);\n                        queryParams += `=${val}`;\n                    }\n                    i++;\n                }\n            }\n        }\n        if (headers) {\n            for (const headerName in headers) {\n                if (headerName) {\n                    queryParams += ((i === 0) && (uri.indexOf(\"?\") === -1)) ? \"?\" : \"&\";\n                    const val = encodeURIComponent(headers[headerName]);\n                    queryParams += `${headerName}=${val}`;\n                    i++;\n                }\n            }\n        }\n        this.privUri = uri + queryParams;\n        this.privId = connectionId ? connectionId : (0,_common_Exports__WEBPACK_IMPORTED_MODULE_1__.createNoDashGuid)();\n        this.privConnectionMessageAdapter = new _WebsocketMessageAdapter__WEBPACK_IMPORTED_MODULE_2__.WebsocketMessageAdapter(this.privUri, this.id, this.privMessageFormatter, proxyInfo, headers, enableCompression);\n    }\n    dispose() {\n        return __awaiter(this, void 0, void 0, function* () {\n            this.privIsDisposed = true;\n            if (this.privConnectionMessageAdapter) {\n                yield this.privConnectionMessageAdapter.close();\n            }\n        });\n    }\n    isDisposed() {\n        return this.privIsDisposed;\n    }\n    get id() {\n        return this.privId;\n    }\n    get uri() {\n        return this.privUri;\n    }\n    state() {\n        return this.privConnectionMessageAdapter.state;\n    }\n    open() {\n        return this.privConnectionMessageAdapter.open();\n    }\n    send(message) {\n        return this.privConnectionMessageAdapter.send(message);\n    }\n    read() {\n        return this.privConnectionMessageAdapter.read();\n    }\n    get events() {\n        return this.privConnectionMessageAdapter.events;\n    }\n}\n\n//# sourceMappingURL=WebsocketConnection.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketConnection.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketMessageAdapter.js":
  /*!**************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketMessageAdapter.js ***!
    \**************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"WebsocketMessageAdapter\": () => (/* binding */ WebsocketMessageAdapter)\n/* harmony export */ });\n/* harmony import */ var ws__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ws */ \"?e42a\");\n/* harmony import */ var ws__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(ws__WEBPACK_IMPORTED_MODULE_0__);\n/* harmony import */ var _common_speech_HeaderNames__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../common.speech/HeaderNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/EventSource.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IConnection.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Queue.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Events.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/BackgroundError.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionOpenResponse.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionEvents.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/RawWebsocketMessage.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js\");\n/* harmony import */ var _CertChecks__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./CertChecks */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/CertChecks.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n// Node.JS specific web socket / browser support.\n\n\n\n\nclass WebsocketMessageAdapter {\n    constructor(uri, connectionId, messageFormatter, proxyInfo, headers, enableCompression) {\n        if (!uri) {\n            throw new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.ArgumentNullError(\"uri\");\n        }\n        if (!messageFormatter) {\n            throw new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.ArgumentNullError(\"messageFormatter\");\n        }\n        this.proxyInfo = proxyInfo;\n        this.privConnectionEvents = new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.EventSource();\n        this.privConnectionId = connectionId;\n        this.privMessageFormatter = messageFormatter;\n        this.privConnectionState = _common_Exports__WEBPACK_IMPORTED_MODULE_3__.ConnectionState.None;\n        this.privUri = uri;\n        this.privHeaders = headers;\n        this.privEnableCompression = enableCompression;\n        // Add the connection ID to the headers\n        this.privHeaders[_common_speech_HeaderNames__WEBPACK_IMPORTED_MODULE_4__.HeaderNames.ConnectionId] = this.privConnectionId;\n        this.privLastErrorReceived = \"\";\n    }\n    get state() {\n        return this.privConnectionState;\n    }\n    open() {\n        if (this.privConnectionState === _common_Exports__WEBPACK_IMPORTED_MODULE_3__.ConnectionState.Disconnected) {\n            return Promise.reject(`Cannot open a connection that is in ${this.privConnectionState} state`);\n        }\n        if (this.privConnectionEstablishDeferral) {\n            return this.privConnectionEstablishDeferral.promise;\n        }\n        this.privConnectionEstablishDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_5__.Deferred();\n        this.privCertificateValidatedDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_5__.Deferred();\n        this.privConnectionState = _common_Exports__WEBPACK_IMPORTED_MODULE_3__.ConnectionState.Connecting;\n        try {\n            if (typeof WebSocket !== \"undefined\" && !WebsocketMessageAdapter.forceNpmWebSocket) {\n                // Browser handles cert checks.\n                this.privCertificateValidatedDeferral.resolve();\n                this.privWebsocketClient = new WebSocket(this.privUri);\n            }\n            else {\n                const options = { headers: this.privHeaders, perMessageDeflate: this.privEnableCompression };\n                // The ocsp library will handle validation for us and fail the connection if needed.\n                this.privCertificateValidatedDeferral.resolve();\n                const checkAgent = new _CertChecks__WEBPACK_IMPORTED_MODULE_6__.CertCheckAgent(this.proxyInfo);\n                options.agent = checkAgent.GetAgent();\n                // Workaround for https://github.com/microsoft/cognitive-services-speech-sdk-js/issues/465\n                // Which is root caused by https://github.com/TooTallNate/node-agent-base/issues/61\n                const uri = new URL(this.privUri);\n                let protocol = uri.protocol;\n                if ((protocol === null || protocol === void 0 ? void 0 : protocol.toLocaleLowerCase()) === \"wss:\") {\n                    protocol = \"https:\";\n                }\n                else if ((protocol === null || protocol === void 0 ? void 0 : protocol.toLocaleLowerCase()) === \"ws:\") {\n                    protocol = \"http:\";\n                }\n                // eslint-disable-next-line @typescript-eslint/no-unsafe-member-access\n                options.agent.protocol = protocol;\n                this.privWebsocketClient = new (ws__WEBPACK_IMPORTED_MODULE_0___default())(this.privUri, options);\n            }\n            this.privWebsocketClient.binaryType = \"arraybuffer\";\n            this.privReceivingMessageQueue = new _common_Exports__WEBPACK_IMPORTED_MODULE_7__.Queue();\n            this.privDisconnectDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_5__.Deferred();\n            this.privSendMessageQueue = new _common_Exports__WEBPACK_IMPORTED_MODULE_7__.Queue();\n            this.processSendQueue().catch((reason) => {\n                _common_Exports__WEBPACK_IMPORTED_MODULE_8__.Events.instance.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_9__.BackgroundEvent(reason));\n            });\n        }\n        catch (error) {\n            this.privConnectionEstablishDeferral.resolve(new _common_Exports__WEBPACK_IMPORTED_MODULE_10__.ConnectionOpenResponse(500, error));\n            return this.privConnectionEstablishDeferral.promise;\n        }\n        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_11__.ConnectionStartEvent(this.privConnectionId, this.privUri));\n        this.privWebsocketClient.onopen = () => {\n            this.privCertificateValidatedDeferral.promise.then(() => {\n                this.privConnectionState = _common_Exports__WEBPACK_IMPORTED_MODULE_3__.ConnectionState.Connected;\n                this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_11__.ConnectionEstablishedEvent(this.privConnectionId));\n                this.privConnectionEstablishDeferral.resolve(new _common_Exports__WEBPACK_IMPORTED_MODULE_10__.ConnectionOpenResponse(200, \"\"));\n            }, (error) => {\n                this.privConnectionEstablishDeferral.reject(error);\n            });\n        };\n        this.privWebsocketClient.onerror = (e) => {\n            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_11__.ConnectionErrorEvent(this.privConnectionId, e.message, e.type));\n            this.privLastErrorReceived = e.message;\n        };\n        this.privWebsocketClient.onclose = (e) => {\n            if (this.privConnectionState === _common_Exports__WEBPACK_IMPORTED_MODULE_3__.ConnectionState.Connecting) {\n                this.privConnectionState = _common_Exports__WEBPACK_IMPORTED_MODULE_3__.ConnectionState.Disconnected;\n                // this.onEvent(new ConnectionEstablishErrorEvent(this.connectionId, e.code, e.reason));\n                this.privConnectionEstablishDeferral.resolve(new _common_Exports__WEBPACK_IMPORTED_MODULE_10__.ConnectionOpenResponse(e.code, e.reason + \" \" + this.privLastErrorReceived));\n            }\n            else {\n                this.privConnectionState = _common_Exports__WEBPACK_IMPORTED_MODULE_3__.ConnectionState.Disconnected;\n                this.privWebsocketClient = null;\n                this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_11__.ConnectionClosedEvent(this.privConnectionId, e.code, e.reason));\n            }\n            this.onClose(e.code, e.reason).catch((reason) => {\n                _common_Exports__WEBPACK_IMPORTED_MODULE_8__.Events.instance.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_9__.BackgroundEvent(reason));\n            });\n        };\n        this.privWebsocketClient.onmessage = (e) => {\n            const networkReceivedTime = new Date().toISOString();\n            if (this.privConnectionState === _common_Exports__WEBPACK_IMPORTED_MODULE_3__.ConnectionState.Connected) {\n                const deferred = new _common_Exports__WEBPACK_IMPORTED_MODULE_5__.Deferred();\n                // let id = ++this.idCounter;\n                this.privReceivingMessageQueue.enqueueFromPromise(deferred.promise);\n                if (e.data instanceof ArrayBuffer) {\n                    const rawMessage = new _common_Exports__WEBPACK_IMPORTED_MODULE_12__.RawWebsocketMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_13__.MessageType.Binary, e.data);\n                    this.privMessageFormatter\n                        .toConnectionMessage(rawMessage)\n                        .then((connectionMessage) => {\n                        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_11__.ConnectionMessageReceivedEvent(this.privConnectionId, networkReceivedTime, connectionMessage));\n                        deferred.resolve(connectionMessage);\n                    }, (error) => {\n                        // TODO: Events for these ?\n                        deferred.reject(`Invalid binary message format. Error: ${error}`);\n                    });\n                }\n                else {\n                    const rawMessage = new _common_Exports__WEBPACK_IMPORTED_MODULE_12__.RawWebsocketMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_13__.MessageType.Text, e.data);\n                    this.privMessageFormatter\n                        .toConnectionMessage(rawMessage)\n                        .then((connectionMessage) => {\n                        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_11__.ConnectionMessageReceivedEvent(this.privConnectionId, networkReceivedTime, connectionMessage));\n                        deferred.resolve(connectionMessage);\n                    }, (error) => {\n                        // TODO: Events for these ?\n                        deferred.reject(`Invalid text message format. Error: ${error}`);\n                    });\n                }\n            }\n        };\n        return this.privConnectionEstablishDeferral.promise;\n    }\n    send(message) {\n        if (this.privConnectionState !== _common_Exports__WEBPACK_IMPORTED_MODULE_3__.ConnectionState.Connected) {\n            return Promise.reject(`Cannot send on connection that is in ${_common_Exports__WEBPACK_IMPORTED_MODULE_3__.ConnectionState[this.privConnectionState]} state`);\n        }\n        const messageSendStatusDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_5__.Deferred();\n        const messageSendDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_5__.Deferred();\n        this.privSendMessageQueue.enqueueFromPromise(messageSendDeferral.promise);\n        this.privMessageFormatter\n            .fromConnectionMessage(message)\n            .then((rawMessage) => {\n            messageSendDeferral.resolve({\n                Message: message,\n                RawWebsocketMessage: rawMessage,\n                sendStatusDeferral: messageSendStatusDeferral,\n            });\n        }, (error) => {\n            messageSendDeferral.reject(`Error formatting the message. ${error}`);\n        });\n        return messageSendStatusDeferral.promise;\n    }\n    read() {\n        if (this.privConnectionState !== _common_Exports__WEBPACK_IMPORTED_MODULE_3__.ConnectionState.Connected) {\n            return Promise.reject(`Cannot read on connection that is in ${this.privConnectionState} state`);\n        }\n        return this.privReceivingMessageQueue.dequeue();\n    }\n    close(reason) {\n        if (this.privWebsocketClient) {\n            if (this.privConnectionState !== _common_Exports__WEBPACK_IMPORTED_MODULE_3__.ConnectionState.Disconnected) {\n                this.privWebsocketClient.close(1000, reason ? reason : \"Normal closure by client\");\n            }\n        }\n        else {\n            return Promise.resolve();\n        }\n        return this.privDisconnectDeferral.promise;\n    }\n    get events() {\n        return this.privConnectionEvents;\n    }\n    sendRawMessage(sendItem) {\n        try {\n            // indicates we are draining the queue and it came with no message;\n            if (!sendItem) {\n                return Promise.resolve();\n            }\n            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_11__.ConnectionMessageSentEvent(this.privConnectionId, new Date().toISOString(), sendItem.Message));\n            // add a check for the ws readystate in order to stop the red console error 'WebSocket is already in CLOSING or CLOSED state' appearing\n            if (this.isWebsocketOpen) {\n                // eslint-disable-next-line @typescript-eslint/no-unsafe-argument\n                this.privWebsocketClient.send(sendItem.RawWebsocketMessage.payload);\n            }\n            else {\n                return Promise.reject(\"websocket send error: Websocket not ready \" + this.privConnectionId + \" \" + sendItem.Message.id + \" \" + new Error().stack);\n            }\n            return Promise.resolve();\n        }\n        catch (e) {\n            return Promise.reject(`websocket send error: ${e}`);\n        }\n    }\n    onClose(code, reason) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const closeReason = `Connection closed. ${code}: ${reason}`;\n            this.privConnectionState = _common_Exports__WEBPACK_IMPORTED_MODULE_3__.ConnectionState.Disconnected;\n            this.privDisconnectDeferral.resolve();\n            yield this.privReceivingMessageQueue.drainAndDispose(() => {\n                // TODO: Events for these ?\n                // Logger.instance.onEvent(new LoggingEvent(LogType.Warning, null, `Failed to process received message. Reason: ${closeReason}, Message: ${JSON.stringify(pendingReceiveItem)}`));\n            }, closeReason);\n            yield this.privSendMessageQueue.drainAndDispose((pendingSendItem) => {\n                pendingSendItem.sendStatusDeferral.reject(closeReason);\n            }, closeReason);\n        });\n    }\n    processSendQueue() {\n        return __awaiter(this, void 0, void 0, function* () {\n            while (true) {\n                const itemToSend = this.privSendMessageQueue.dequeue();\n                const sendItem = yield itemToSend;\n                // indicates we are draining the queue and it came with no message;\n                if (!sendItem) {\n                    return;\n                }\n                try {\n                    yield this.sendRawMessage(sendItem);\n                    sendItem.sendStatusDeferral.resolve();\n                }\n                catch (sendError) {\n                    sendItem.sendStatusDeferral.reject(sendError);\n                }\n            }\n        });\n    }\n    onEvent(event) {\n        this.privConnectionEvents.onEvent(event);\n        _common_Exports__WEBPACK_IMPORTED_MODULE_8__.Events.instance.onEvent(event);\n    }\n    get isWebsocketOpen() {\n        return this.privWebsocketClient && this.privWebsocketClient.readyState === this.privWebsocketClient.OPEN;\n    }\n}\nWebsocketMessageAdapter.forceNpmWebSocket = false;\n\n//# sourceMappingURL=WebsocketMessageAdapter.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketMessageAdapter.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/AddedLmIntent.js":
  /*!***************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/AddedLmIntent.js ***!
    \***************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AddedLmIntent\": () => (/* binding */ AddedLmIntent)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * @class AddedLmIntent\n */\n// eslint-disable-next-line max-classes-per-file\nclass AddedLmIntent {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param modelImpl - The model.\n     * @param intentName - The intent name.\n     */\n    constructor(modelImpl, intentName) {\n        this.modelImpl = modelImpl;\n        this.intentName = intentName;\n    }\n}\n\n//# sourceMappingURL=AddedLmIntent.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/AddedLmIntent.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/AgentConfig.js":
  /*!*************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/AgentConfig.js ***!
    \*************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AgentConfig\": () => (/* binding */ AgentConfig)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Represents the JSON used in the agent.config message sent to the speech service.\n */\nclass AgentConfig {\n    toJsonString() {\n        return JSON.stringify(this.iPrivConfig);\n    }\n    get() {\n        return this.iPrivConfig;\n    }\n    /**\n     * Setter for the agent.config object.\n     * @param value a JSON serializable object.\n     */\n    set(value) {\n        this.iPrivConfig = value;\n    }\n}\n\n//# sourceMappingURL=AgentConfig.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/AgentConfig.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/CognitiveSubscriptionKeyAuthentication.js":
  /*!****************************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/CognitiveSubscriptionKeyAuthentication.js ***!
    \****************************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"CognitiveSubscriptionKeyAuthentication\": () => (/* binding */ CognitiveSubscriptionKeyAuthentication)\n/* harmony export */ });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js\");\n/* harmony import */ var _HeaderNames__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./HeaderNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js\");\n/* harmony import */ var _IAuthentication__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./IAuthentication */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IAuthentication.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\n/**\n * @class\n */\nclass CognitiveSubscriptionKeyAuthentication {\n    /**\n     * Creates and initializes an instance of the CognitiveSubscriptionKeyAuthentication class.\n     * @constructor\n     * @param {string} subscriptionKey - The subscription key\n     */\n    constructor(subscriptionKey) {\n        if (!subscriptionKey) {\n            throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__.ArgumentNullError(\"subscriptionKey\");\n        }\n        this.privAuthInfo = new _IAuthentication__WEBPACK_IMPORTED_MODULE_1__.AuthInfo(_HeaderNames__WEBPACK_IMPORTED_MODULE_2__.HeaderNames.AuthKey, subscriptionKey);\n    }\n    /**\n     * Fetches the subscription key.\n     * @member\n     * @function\n     * @public\n     * @param {string} authFetchEventId - The id to fetch.\n     */\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    fetch(authFetchEventId) {\n        return Promise.resolve(this.privAuthInfo);\n    }\n    /**\n     * Fetches the subscription key.\n     * @member\n     * @function\n     * @public\n     * @param {string} authFetchEventId - The id to fetch.\n     */\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    fetchOnExpiry(authFetchEventId) {\n        return Promise.resolve(this.privAuthInfo);\n    }\n}\n\n//# sourceMappingURL=CognitiveSubscriptionKeyAuthentication.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/CognitiveSubscriptionKeyAuthentication.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/CognitiveTokenAuthentication.js":
  /*!******************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/CognitiveTokenAuthentication.js ***!
    \******************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"CognitiveTokenAuthentication\": () => (/* binding */ CognitiveTokenAuthentication)\n/* harmony export */ });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js\");\n/* harmony import */ var _IAuthentication__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./IAuthentication */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IAuthentication.js\");\n/* harmony import */ var _HeaderNames__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./HeaderNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\nclass CognitiveTokenAuthentication {\n    constructor(fetchCallback, fetchOnExpiryCallback) {\n        if (!fetchCallback) {\n            throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__.ArgumentNullError(\"fetchCallback\");\n        }\n        if (!fetchOnExpiryCallback) {\n            throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__.ArgumentNullError(\"fetchOnExpiryCallback\");\n        }\n        this.privFetchCallback = fetchCallback;\n        this.privFetchOnExpiryCallback = fetchOnExpiryCallback;\n    }\n    fetch(authFetchEventId) {\n        return this.privFetchCallback(authFetchEventId).then((token) => new _IAuthentication__WEBPACK_IMPORTED_MODULE_1__.AuthInfo(_HeaderNames__WEBPACK_IMPORTED_MODULE_2__.HeaderNames.Authorization, token === undefined ? undefined : CognitiveTokenAuthentication.privTokenPrefix + token));\n    }\n    fetchOnExpiry(authFetchEventId) {\n        return this.privFetchOnExpiryCallback(authFetchEventId).then((token) => new _IAuthentication__WEBPACK_IMPORTED_MODULE_1__.AuthInfo(_HeaderNames__WEBPACK_IMPORTED_MODULE_2__.HeaderNames.Authorization, token === undefined ? undefined : CognitiveTokenAuthentication.privTokenPrefix + token));\n    }\n}\nCognitiveTokenAuthentication.privTokenPrefix = \"bearer \";\n\n//# sourceMappingURL=CognitiveTokenAuthentication.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/CognitiveTokenAuthentication.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js":
  /*!***********************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js ***!
    \***********************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConnectionFactoryBase\": () => (/* binding */ ConnectionFactoryBase)\n/* harmony export */ });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _QueryParameterNames__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./QueryParameterNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/QueryParameterNames.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\nclass ConnectionFactoryBase {\n    static getHostSuffix(region) {\n        if (!!region) {\n            if (region.toLowerCase().startsWith(\"china\")) {\n                return \".azure.cn\";\n            }\n            if (region.toLowerCase().startsWith(\"usgov\")) {\n                return \".azure.us\";\n            }\n        }\n        return \".microsoft.com\";\n    }\n    setCommonUrlParams(config, queryParams, endpoint) {\n        const propertyIdToParameterMap = new Map([\n            [_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.Speech_SegmentationSilenceTimeoutMs, _QueryParameterNames__WEBPACK_IMPORTED_MODULE_1__.QueryParameterNames.SegmentationSilenceTimeoutMs],\n            [_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_EnableAudioLogging, _QueryParameterNames__WEBPACK_IMPORTED_MODULE_1__.QueryParameterNames.EnableAudioLogging],\n            [_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_EndSilenceTimeoutMs, _QueryParameterNames__WEBPACK_IMPORTED_MODULE_1__.QueryParameterNames.EndSilenceTimeoutMs],\n            [_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_InitialSilenceTimeoutMs, _QueryParameterNames__WEBPACK_IMPORTED_MODULE_1__.QueryParameterNames.InitialSilenceTimeoutMs],\n            [_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceResponse_PostProcessingOption, _QueryParameterNames__WEBPACK_IMPORTED_MODULE_1__.QueryParameterNames.Postprocessing],\n            [_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceResponse_ProfanityOption, _QueryParameterNames__WEBPACK_IMPORTED_MODULE_1__.QueryParameterNames.Profanity],\n            [_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceResponse_RequestWordLevelTimestamps, _QueryParameterNames__WEBPACK_IMPORTED_MODULE_1__.QueryParameterNames.EnableWordLevelTimestamps],\n            [_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceResponse_StablePartialResultThreshold, _QueryParameterNames__WEBPACK_IMPORTED_MODULE_1__.QueryParameterNames.StableIntermediateThreshold],\n        ]);\n        propertyIdToParameterMap.forEach((parameterName, propertyId) => {\n            this.setUrlParameter(propertyId, parameterName, config, queryParams, endpoint);\n        });\n        const serviceProperties = JSON.parse(config.parameters.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_2__.ServicePropertiesPropertyName, \"{}\"));\n        Object.keys(serviceProperties).forEach((value) => {\n            queryParams[value] = serviceProperties[value];\n        });\n    }\n    setUrlParameter(propId, parameterName, config, queryParams, endpoint) {\n        const value = config.parameters.getProperty(propId, undefined);\n        // FIXME: The .search() check will incorrectly match parameter name anywhere in the string\n        //        including e.g. the path portion, or even as a substring of other query parameters\n        if (value && (!endpoint || endpoint.search(parameterName) === -1)) {\n            queryParams[parameterName] = value.toLocaleLowerCase();\n        }\n    }\n}\n\n//# sourceMappingURL=ConnectionFactoryBase.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConversationServiceRecognizer.js":
  /*!*******************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConversationServiceRecognizer.js ***!
    \*******************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConversationServiceRecognizer\": () => (/* binding */ ConversationServiceRecognizer)\n/* harmony export */ });\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/OutputFormat.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionResult.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceRecognizerBase.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SimpleSpeechPhrase.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/EnumTranslation.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/Enums.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/DetailedSpeechPhrase.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechHypothesis.js\");\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\nclass ConversationServiceRecognizer extends _Exports__WEBPACK_IMPORTED_MODULE_0__.ServiceRecognizerBase {\n    constructor(authentication, connectionFactory, audioSource, recognizerConfig, recognizer) {\n        super(authentication, connectionFactory, audioSource, recognizerConfig, recognizer);\n        this.handleSpeechPhraseMessage = (textBody) => __awaiter(this, void 0, void 0, function* () { return this.handleSpeechPhrase(textBody); });\n        this.handleSpeechHypothesisMessage = (textBody) => this.handleSpeechHypothesis(textBody);\n    }\n    processTypeSpecificMessages(connectionMessage) {\n        void connectionMessage;\n        return;\n    }\n    handleRecognizedCallback(result, offset, sessionId) {\n        void result;\n        void offset;\n        void sessionId;\n        return;\n    }\n    handleRecognizingCallback(result, duration, sessionId) {\n        void result;\n        void duration;\n        void sessionId;\n        return;\n    }\n    processSpeechMessages(connectionMessage) {\n        return __awaiter(this, void 0, void 0, function* () {\n            let processed = false;\n            switch (connectionMessage.path.toLowerCase()) {\n                case \"speech.hypothesis\":\n                case \"speech.fragment\":\n                    if (!!this.handleSpeechHypothesisMessage) {\n                        this.handleSpeechHypothesisMessage(connectionMessage.textBody);\n                    }\n                    processed = true;\n                    break;\n                case \"speech.phrase\":\n                    if (!!this.handleSpeechPhraseMessage) {\n                        yield this.handleSpeechPhraseMessage(connectionMessage.textBody);\n                    }\n                    processed = true;\n                    break;\n                default:\n                    break;\n            }\n            return processed;\n        });\n    }\n    cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {\n        // Implementing to allow inheritance\n        void sessionId;\n        void requestId;\n        void cancellationReason;\n        void errorCode;\n        void error;\n    }\n    handleSpeechPhrase(textBody) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const simple = _Exports__WEBPACK_IMPORTED_MODULE_1__.SimpleSpeechPhrase.fromJSON(textBody);\n            const resultReason = _Exports__WEBPACK_IMPORTED_MODULE_2__.EnumTranslation.implTranslateRecognitionResult(simple.RecognitionStatus);\n            let result;\n            const resultProps = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyCollection();\n            resultProps.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.SpeechServiceResponse_JsonResult, textBody);\n            const simpleOffset = simple.Offset + this.privRequestSession.currentTurnAudioOffset;\n            let offset = simpleOffset;\n            this.privRequestSession.onPhraseRecognized(this.privRequestSession.currentTurnAudioOffset + simple.Offset + simple.Duration);\n            if (_sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.Canceled === resultReason) {\n                const cancelReason = _Exports__WEBPACK_IMPORTED_MODULE_2__.EnumTranslation.implTranslateCancelResult(simple.RecognitionStatus);\n                const cancellationErrorCode = _Exports__WEBPACK_IMPORTED_MODULE_2__.EnumTranslation.implTranslateCancelErrorCode(simple.RecognitionStatus);\n                yield this.cancelRecognitionLocal(cancelReason, cancellationErrorCode, _Exports__WEBPACK_IMPORTED_MODULE_2__.EnumTranslation.implTranslateErrorDetails(cancellationErrorCode));\n            }\n            else {\n                if (!(this.privRequestSession.isSpeechEnded && resultReason === _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.NoMatch && simple.RecognitionStatus !== _Exports__WEBPACK_IMPORTED_MODULE_6__.RecognitionStatus.InitialSilenceTimeout)) {\n                    if (this.privRecognizerConfig.parameters.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_7__.OutputFormatPropertyName) === _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__.OutputFormat[_sdk_Exports__WEBPACK_IMPORTED_MODULE_8__.OutputFormat.Simple]) {\n                        result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.SpeechRecognitionResult(this.privRequestSession.requestId, resultReason, simple.DisplayText, simple.Duration, simpleOffset, simple.Language, simple.LanguageDetectionConfidence, simple.SpeakerId, undefined, textBody, resultProps);\n                    }\n                    else {\n                        const detailed = _Exports__WEBPACK_IMPORTED_MODULE_10__.DetailedSpeechPhrase.fromJSON(textBody);\n                        const totalOffset = detailed.Offset + this.privRequestSession.currentTurnAudioOffset;\n                        const offsetCorrectedJson = detailed.getJsonWithCorrectedOffsets(totalOffset);\n                        result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.SpeechRecognitionResult(this.privRequestSession.requestId, resultReason, detailed.Text, detailed.Duration, totalOffset, detailed.Language, detailed.LanguageDetectionConfidence, detailed.SpeakerId, undefined, offsetCorrectedJson, resultProps);\n                        offset = result.offset;\n                    }\n                    this.handleRecognizedCallback(result, offset, this.privRequestSession.sessionId);\n                }\n            }\n        });\n    }\n    handleSpeechHypothesis(textBody) {\n        const hypothesis = _Exports__WEBPACK_IMPORTED_MODULE_11__.SpeechHypothesis.fromJSON(textBody);\n        const offset = hypothesis.Offset + this.privRequestSession.currentTurnAudioOffset;\n        const resultProps = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyCollection();\n        resultProps.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.SpeechServiceResponse_JsonResult, textBody);\n        const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.SpeechRecognitionResult(this.privRequestSession.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.RecognizingSpeech, hypothesis.Text, hypothesis.Duration, offset, hypothesis.Language, hypothesis.LanguageDetectionConfidence, hypothesis.SpeakerId, undefined, textBody, resultProps);\n        this.privRequestSession.onHypothesis(offset);\n        this.handleRecognizingCallback(result, hypothesis.Duration, this.privRequestSession.sessionId);\n    }\n}\n\n//# sourceMappingURL=ConversationServiceRecognizer.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConversationServiceRecognizer.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceAdapter.js":
  /*!**********************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceAdapter.js ***!
    \**********************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"DialogServiceAdapter\": () => (/* binding */ DialogServiceAdapter)\n/* harmony export */ });\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_20__ = __webpack_require__(/*! ../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ReplayableAudioNode.js\");\n/* harmony import */ var _common_DialogEvents__WEBPACK_IMPORTED_MODULE_28__ = __webpack_require__(/*! ../common/DialogEvents */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/DialogEvents.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/EventSource.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_24__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionEvents.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_25__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Events.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_26__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/BackgroundError.js\");\n/* harmony import */ var _sdk_Audio_AudioOutputFormat__WEBPACK_IMPORTED_MODULE_31__ = __webpack_require__(/*! ../sdk/Audio/AudioOutputFormat */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputFormat.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationReason.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionResult.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionEventArgs.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_19__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionCanceledEventArgs.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_21__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SessionEventArgs.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_23__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionEventArgs.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_27__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/DialogServiceConfig.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_32__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ActivityReceivedEventArgs.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_33__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TurnStatusReceivedEventArgs.js\");\n/* harmony import */ var _DialogServiceTurnStateManager__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./DialogServiceTurnStateManager */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceTurnStateManager.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceRecognizerBase.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SimpleSpeechPhrase.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/Enums.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechHypothesis.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechKeyword.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_18__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_22__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechDetected.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_29__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/EnumTranslation.js\");\n/* harmony import */ var _ServiceMessages_ActivityResponsePayload__WEBPACK_IMPORTED_MODULE_30__ = __webpack_require__(/*! ./ServiceMessages/ActivityResponsePayload */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/ActivityResponsePayload.js\");\n/* harmony import */ var _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./SpeechConnectionMessage.Internal */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionMessage.Internal.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\n\n\n\n\n\n\nclass DialogServiceAdapter extends _Exports__WEBPACK_IMPORTED_MODULE_0__.ServiceRecognizerBase {\n    constructor(authentication, connectionFactory, audioSource, recognizerConfig, dialogServiceConnector) {\n        super(authentication, connectionFactory, audioSource, recognizerConfig, dialogServiceConnector);\n        this.privEvents = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.EventSource();\n        this.privDialogServiceConnector = dialogServiceConnector;\n        this.receiveMessageOverride = () => this.receiveDialogMessageOverride();\n        this.privTurnStateManager = new _DialogServiceTurnStateManager__WEBPACK_IMPORTED_MODULE_2__.DialogServiceTurnStateManager();\n        this.recognizeOverride =\n            (recoMode, successCallback, errorCallback) => this.listenOnce(recoMode, successCallback, errorCallback);\n        this.postConnectImplOverride = (connection) => this.dialogConnectImpl(connection);\n        this.configConnectionOverride = (connection) => this.configConnection(connection);\n        this.disconnectOverride = () => this.privDisconnect();\n        this.privDialogAudioSource = audioSource;\n        this.agentConfigSent = false;\n        this.privLastResult = null;\n        this.connectionEvents.attach((connectionEvent) => {\n            if (connectionEvent.name === \"ConnectionClosedEvent\") {\n                this.terminateMessageLoop = true;\n            }\n        });\n    }\n    sendMessage(message) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const interactionGuid = (0,_common_Exports__WEBPACK_IMPORTED_MODULE_3__.createGuid)();\n            const requestId = (0,_common_Exports__WEBPACK_IMPORTED_MODULE_3__.createNoDashGuid)();\n            const agentMessage = {\n                context: {\n                    interactionId: interactionGuid\n                },\n                // eslint-disable-next-line @typescript-eslint/no-unsafe-assignment\n                messagePayload: JSON.parse(message),\n                version: 0.5\n            };\n            const agentMessageJson = JSON.stringify(agentMessage);\n            const connection = yield this.fetchConnection();\n            yield connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_4__.SpeechConnectionMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_5__.MessageType.Text, \"agent\", requestId, \"application/json\", agentMessageJson));\n        });\n    }\n    privDisconnect() {\n        return __awaiter(this, void 0, void 0, function* () {\n            yield this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.CancellationReason.Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_7__.CancellationErrorCode.NoError, \"Disconnecting\");\n            this.terminateMessageLoop = true;\n            this.agentConfigSent = false;\n            return;\n        });\n    }\n    processTypeSpecificMessages(connectionMessage) {\n        const resultProps = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__.PropertyCollection();\n        if (connectionMessage.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_5__.MessageType.Text) {\n            resultProps.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.PropertyId.SpeechServiceResponse_JsonResult, connectionMessage.textBody);\n        }\n        let result;\n        let processed;\n        switch (connectionMessage.path.toLowerCase()) {\n            case \"speech.phrase\":\n                const speechPhrase = _Exports__WEBPACK_IMPORTED_MODULE_10__.SimpleSpeechPhrase.fromJSON(connectionMessage.textBody);\n                this.privRequestSession.onPhraseRecognized(this.privRequestSession.currentTurnAudioOffset + speechPhrase.Offset + speechPhrase.Duration);\n                if (speechPhrase.RecognitionStatus !== _Exports__WEBPACK_IMPORTED_MODULE_11__.RecognitionStatus.TooManyRequests && speechPhrase.RecognitionStatus !== _Exports__WEBPACK_IMPORTED_MODULE_11__.RecognitionStatus.Error) {\n                    const args = this.fireEventForResult(speechPhrase, resultProps);\n                    this.privLastResult = args.result;\n                    if (!!this.privDialogServiceConnector.recognized) {\n                        try {\n                            this.privDialogServiceConnector.recognized(this.privDialogServiceConnector, args);\n                            /* eslint-disable no-empty */\n                        }\n                        catch (error) {\n                            // Not going to let errors in the event handler\n                            // trip things up.\n                        }\n                    }\n                }\n                processed = true;\n                break;\n            case \"speech.hypothesis\":\n                const hypothesis = _Exports__WEBPACK_IMPORTED_MODULE_12__.SpeechHypothesis.fromJSON(connectionMessage.textBody);\n                const offset = hypothesis.Offset + this.privRequestSession.currentTurnAudioOffset;\n                result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_13__.SpeechRecognitionResult(this.privRequestSession.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_14__.ResultReason.RecognizingSpeech, hypothesis.Text, hypothesis.Duration, offset, hypothesis.Language, hypothesis.LanguageDetectionConfidence, undefined, undefined, connectionMessage.textBody, resultProps);\n                this.privRequestSession.onHypothesis(offset);\n                const ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_15__.SpeechRecognitionEventArgs(result, hypothesis.Duration, this.privRequestSession.sessionId);\n                if (!!this.privDialogServiceConnector.recognizing) {\n                    try {\n                        this.privDialogServiceConnector.recognizing(this.privDialogServiceConnector, ev);\n                        /* eslint-disable no-empty */\n                    }\n                    catch (error) {\n                        // Not going to let errors in the event handler\n                        // trip things up.\n                    }\n                }\n                processed = true;\n                break;\n            case \"speech.keyword\":\n                const keyword = _Exports__WEBPACK_IMPORTED_MODULE_16__.SpeechKeyword.fromJSON(connectionMessage.textBody);\n                result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_13__.SpeechRecognitionResult(this.privRequestSession.requestId, keyword.Status === \"Accepted\" ? _sdk_Exports__WEBPACK_IMPORTED_MODULE_14__.ResultReason.RecognizedKeyword : _sdk_Exports__WEBPACK_IMPORTED_MODULE_14__.ResultReason.NoMatch, keyword.Text, keyword.Duration, keyword.Offset, undefined, undefined, undefined, undefined, connectionMessage.textBody, resultProps);\n                if (keyword.Status !== \"Accepted\") {\n                    this.privLastResult = result;\n                }\n                const event = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_15__.SpeechRecognitionEventArgs(result, result.duration, result.resultId);\n                if (!!this.privDialogServiceConnector.recognized) {\n                    try {\n                        this.privDialogServiceConnector.recognized(this.privDialogServiceConnector, event);\n                        /* eslint-disable no-empty */\n                    }\n                    catch (error) {\n                        // Not going to let errors in the event handler\n                        // trip things up.\n                    }\n                }\n                processed = true;\n                break;\n            case \"audio\":\n                {\n                    const audioRequestId = connectionMessage.requestId.toUpperCase();\n                    const turn = this.privTurnStateManager.GetTurn(audioRequestId);\n                    try {\n                        // Empty binary message signals end of stream.\n                        if (!connectionMessage.binaryBody) {\n                            turn.endAudioStream();\n                        }\n                        else {\n                            turn.audioStream.write(connectionMessage.binaryBody);\n                        }\n                    }\n                    catch (error) {\n                        // Not going to let errors in the event handler\n                        // trip things up.\n                    }\n                }\n                processed = true;\n                break;\n            case \"response\":\n                {\n                    this.handleResponseMessage(connectionMessage);\n                }\n                processed = true;\n                break;\n            default:\n                break;\n        }\n        const defferal = new _common_Exports__WEBPACK_IMPORTED_MODULE_17__.Deferred();\n        defferal.resolve(processed);\n        return defferal.promise;\n    }\n    // Cancels recognition.\n    cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {\n        return __awaiter(this, void 0, void 0, function* () {\n            this.terminateMessageLoop = true;\n            if (!!this.privRequestSession.isRecognizing) {\n                yield this.privRequestSession.onStopRecognizing();\n            }\n            if (!!this.privDialogServiceConnector.canceled) {\n                const properties = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__.PropertyCollection();\n                properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_18__.CancellationErrorCodePropertyName, _sdk_Exports__WEBPACK_IMPORTED_MODULE_7__.CancellationErrorCode[errorCode]);\n                const cancelEvent = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_19__.SpeechRecognitionCanceledEventArgs(cancellationReason, error, errorCode, undefined, sessionId);\n                try {\n                    this.privDialogServiceConnector.canceled(this.privDialogServiceConnector, cancelEvent);\n                    /* eslint-disable no-empty */\n                }\n                catch (_a) { }\n                if (!!this.privSuccessCallback) {\n                    const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_13__.SpeechRecognitionResult(undefined, // ResultId\n                    _sdk_Exports__WEBPACK_IMPORTED_MODULE_14__.ResultReason.Canceled, undefined, // Text\n                    undefined, // Duration\n                    undefined, // Offset\n                    undefined, // Language\n                    undefined, // Language Detection Confidence\n                    undefined, // Speaker Id\n                    error, undefined, // Json\n                    properties);\n                    try {\n                        this.privSuccessCallback(result);\n                        this.privSuccessCallback = undefined;\n                        /* eslint-disable no-empty */\n                    }\n                    catch (_b) { }\n                }\n            }\n        });\n    }\n    listenOnce(recoMode, successCallback, errorCallback) {\n        return __awaiter(this, void 0, void 0, function* () {\n            this.privRecognizerConfig.recognitionMode = recoMode;\n            this.privSuccessCallback = successCallback;\n            this.privErrorCallback = errorCallback;\n            this.privRequestSession.startNewRecognition();\n            this.privRequestSession.listenForServiceTelemetry(this.privDialogAudioSource.events);\n            this.privRecognizerConfig.parameters.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.PropertyId.Speech_SessionId, this.privRequestSession.sessionId);\n            // Start the connection to the service. The promise this will create is stored and will be used by configureConnection().\n            const conPromise = this.connectImpl();\n            const preAudioPromise = this.sendPreAudioMessages();\n            const node = yield this.privDialogAudioSource.attach(this.privRequestSession.audioNodeId);\n            const format = yield this.privDialogAudioSource.format;\n            const deviceInfo = yield this.privDialogAudioSource.deviceInfo;\n            const audioNode = new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_20__.ReplayableAudioNode(node, format.avgBytesPerSec);\n            yield this.privRequestSession.onAudioSourceAttachCompleted(audioNode, false);\n            this.privRecognizerConfig.SpeechServiceConfig.Context.audio = { source: deviceInfo };\n            try {\n                yield conPromise;\n                yield preAudioPromise;\n            }\n            catch (error) {\n                yield this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.CancellationReason.Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_7__.CancellationErrorCode.ConnectionFailure, error);\n                return Promise.resolve();\n            }\n            const sessionStartEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_21__.SessionEventArgs(this.privRequestSession.sessionId);\n            if (!!this.privRecognizer.sessionStarted) {\n                this.privRecognizer.sessionStarted(this.privRecognizer, sessionStartEventArgs);\n            }\n            const audioSendPromise = this.sendAudio(audioNode);\n            // /* eslint-disable no-empty */\n            audioSendPromise.then(() => { }, (error) => __awaiter(this, void 0, void 0, function* () {\n                yield this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.CancellationReason.Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_7__.CancellationErrorCode.RuntimeError, error);\n            }));\n        });\n    }\n    // Establishes a websocket connection to the end point.\n    dialogConnectImpl(connection) {\n        this.privConnectionLoop = this.startMessageLoop();\n        return connection;\n    }\n    receiveDialogMessageOverride() {\n        // we won't rely on the cascading promises of the connection since we want to continually be available to receive messages\n        const communicationCustodian = new _common_Exports__WEBPACK_IMPORTED_MODULE_17__.Deferred();\n        const loop = () => __awaiter(this, void 0, void 0, function* () {\n            try {\n                const isDisposed = this.isDisposed();\n                const terminateMessageLoop = (!this.isDisposed() && this.terminateMessageLoop);\n                if (isDisposed || terminateMessageLoop) {\n                    // We're done.\n                    communicationCustodian.resolve(undefined);\n                    return;\n                }\n                const connection = yield this.fetchConnection();\n                const message = yield connection.read();\n                if (!message) {\n                    return loop();\n                }\n                const connectionMessage = _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_4__.SpeechConnectionMessage.fromConnectionMessage(message);\n                switch (connectionMessage.path.toLowerCase()) {\n                    case \"turn.start\":\n                        {\n                            const turnRequestId = connectionMessage.requestId.toUpperCase();\n                            const audioSessionReqId = this.privRequestSession.requestId.toUpperCase();\n                            // turn started by the service\n                            if (turnRequestId !== audioSessionReqId) {\n                                this.privTurnStateManager.StartTurn(turnRequestId);\n                            }\n                            else {\n                                this.privRequestSession.onServiceTurnStartResponse();\n                            }\n                        }\n                        break;\n                    case \"speech.startdetected\":\n                        const speechStartDetected = _Exports__WEBPACK_IMPORTED_MODULE_22__.SpeechDetected.fromJSON(connectionMessage.textBody);\n                        const speechStartEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_23__.RecognitionEventArgs(speechStartDetected.Offset, this.privRequestSession.sessionId);\n                        if (!!this.privRecognizer.speechStartDetected) {\n                            this.privRecognizer.speechStartDetected(this.privRecognizer, speechStartEventArgs);\n                        }\n                        break;\n                    case \"speech.enddetected\":\n                        let json;\n                        if (connectionMessage.textBody.length > 0) {\n                            json = connectionMessage.textBody;\n                        }\n                        else {\n                            // If the request was empty, the JSON returned is empty.\n                            json = \"{ Offset: 0 }\";\n                        }\n                        const speechStopDetected = _Exports__WEBPACK_IMPORTED_MODULE_22__.SpeechDetected.fromJSON(json);\n                        this.privRequestSession.onServiceRecognized(speechStopDetected.Offset + this.privRequestSession.currentTurnAudioOffset);\n                        const speechStopEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_23__.RecognitionEventArgs(speechStopDetected.Offset + this.privRequestSession.currentTurnAudioOffset, this.privRequestSession.sessionId);\n                        if (!!this.privRecognizer.speechEndDetected) {\n                            this.privRecognizer.speechEndDetected(this.privRecognizer, speechStopEventArgs);\n                        }\n                        break;\n                    case \"turn.end\":\n                        {\n                            const turnEndRequestId = connectionMessage.requestId.toUpperCase();\n                            const audioSessionReqId = this.privRequestSession.requestId.toUpperCase();\n                            // turn started by the service\n                            if (turnEndRequestId !== audioSessionReqId) {\n                                this.privTurnStateManager.CompleteTurn(turnEndRequestId);\n                            }\n                            else {\n                                // Audio session turn\n                                const sessionStopEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_21__.SessionEventArgs(this.privRequestSession.sessionId);\n                                yield this.privRequestSession.onServiceTurnEndResponse(false);\n                                if (!this.privRecognizerConfig.isContinuousRecognition || this.privRequestSession.isSpeechEnded || !this.privRequestSession.isRecognizing) {\n                                    if (!!this.privRecognizer.sessionStopped) {\n                                        this.privRecognizer.sessionStopped(this.privRecognizer, sessionStopEventArgs);\n                                    }\n                                }\n                                // report result to promise.\n                                if (!!this.privSuccessCallback && this.privLastResult) {\n                                    try {\n                                        this.privSuccessCallback(this.privLastResult);\n                                        this.privLastResult = null;\n                                    }\n                                    catch (e) {\n                                        if (!!this.privErrorCallback) {\n                                            this.privErrorCallback(e);\n                                        }\n                                    }\n                                    // Only invoke the call back once.\n                                    // and if it's successful don't invoke the\n                                    // error after that.\n                                    this.privSuccessCallback = undefined;\n                                    this.privErrorCallback = undefined;\n                                }\n                            }\n                        }\n                        break;\n                    default:\n                        try {\n                            const processed = yield this.processTypeSpecificMessages(connectionMessage);\n                            if (!processed) {\n                                if (!!this.serviceEvents) {\n                                    this.serviceEvents.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_24__.ServiceEvent(connectionMessage.path.toLowerCase(), connectionMessage.textBody));\n                                }\n                            }\n                        }\n                        catch (e) {\n                            //\n                        }\n                }\n                const ret = loop();\n                return ret;\n            }\n            catch (error) {\n                this.terminateMessageLoop = true;\n                communicationCustodian.resolve();\n            }\n        });\n        loop().catch((reason) => {\n            _common_Exports__WEBPACK_IMPORTED_MODULE_25__.Events.instance.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_26__.BackgroundEvent(reason));\n        });\n        return communicationCustodian.promise;\n    }\n    startMessageLoop() {\n        return __awaiter(this, void 0, void 0, function* () {\n            this.terminateMessageLoop = false;\n            try {\n                yield this.receiveDialogMessageOverride();\n            }\n            catch (error) {\n                yield this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.CancellationReason.Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_7__.CancellationErrorCode.RuntimeError, error);\n            }\n            return Promise.resolve();\n        });\n    }\n    // Takes an established websocket connection to the endpoint and sends speech configuration information.\n    configConnection(connection) {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (this.terminateMessageLoop) {\n                this.terminateMessageLoop = false;\n                return Promise.reject(\"Connection to service terminated.\");\n            }\n            yield this.sendSpeechServiceConfig(connection, this.privRequestSession, this.privRecognizerConfig.SpeechServiceConfig.serialize());\n            yield this.sendAgentConfig(connection);\n            return connection;\n        });\n    }\n    sendPreAudioMessages() {\n        return __awaiter(this, void 0, void 0, function* () {\n            const connection = yield this.fetchConnection();\n            this.addKeywordContextData();\n            yield this.sendSpeechContext(connection, true);\n            yield this.sendAgentContext(connection);\n            yield this.sendWaveHeader(connection);\n        });\n    }\n    sendAgentConfig(connection) {\n        if (this.agentConfig && !this.agentConfigSent) {\n            if (this.privRecognizerConfig\n                .parameters\n                .getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.PropertyId.Conversation_DialogType) === _sdk_Exports__WEBPACK_IMPORTED_MODULE_27__.DialogServiceConfig.DialogTypes.CustomCommands) {\n                const config = this.agentConfig.get();\n                config.botInfo.commandsCulture = this.privRecognizerConfig.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.PropertyId.SpeechServiceConnection_RecoLanguage, \"en-us\");\n                this.agentConfig.set(config);\n            }\n            this.onEvent(new _common_DialogEvents__WEBPACK_IMPORTED_MODULE_28__.SendingAgentContextMessageEvent(this.agentConfig));\n            const agentConfigJson = this.agentConfig.toJsonString();\n            // guard against sending this multiple times on one connection\n            this.agentConfigSent = true;\n            return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_4__.SpeechConnectionMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_5__.MessageType.Text, \"agent.config\", this.privRequestSession.requestId, \"application/json\", agentConfigJson));\n        }\n        return;\n    }\n    sendAgentContext(connection) {\n        const guid = (0,_common_Exports__WEBPACK_IMPORTED_MODULE_3__.createGuid)();\n        const speechActivityTemplate = this.privDialogServiceConnector.properties.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.PropertyId.Conversation_Speech_Activity_Template);\n        const agentContext = {\n            channelData: \"\",\n            context: {\n                interactionId: guid\n            },\n            messagePayload: typeof speechActivityTemplate === undefined ? undefined : speechActivityTemplate,\n            version: 0.5\n        };\n        const agentContextJson = JSON.stringify(agentContext);\n        return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_4__.SpeechConnectionMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_5__.MessageType.Text, \"speech.agent.context\", this.privRequestSession.requestId, \"application/json\", agentContextJson));\n    }\n    fireEventForResult(serviceResult, properties) {\n        const resultReason = _Exports__WEBPACK_IMPORTED_MODULE_29__.EnumTranslation.implTranslateRecognitionResult(serviceResult.RecognitionStatus);\n        const offset = serviceResult.Offset + this.privRequestSession.currentTurnAudioOffset;\n        const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_13__.SpeechRecognitionResult(this.privRequestSession.requestId, resultReason, serviceResult.DisplayText, serviceResult.Duration, offset, serviceResult.Language, serviceResult.LanguageDetectionConfidence, undefined, undefined, JSON.stringify(serviceResult), properties);\n        const ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_15__.SpeechRecognitionEventArgs(result, offset, this.privRequestSession.sessionId);\n        return ev;\n    }\n    handleResponseMessage(responseMessage) {\n        // \"response\" messages can contain either \"message\" (activity) or \"MessageStatus\" data. Fire the appropriate\n        // event according to the message type that's specified.\n        const responsePayload = JSON.parse(responseMessage.textBody);\n        switch (responsePayload.messageType.toLowerCase()) {\n            case \"message\":\n                const responseRequestId = responseMessage.requestId.toUpperCase();\n                const activityPayload = _ServiceMessages_ActivityResponsePayload__WEBPACK_IMPORTED_MODULE_30__.ActivityPayloadResponse.fromJSON(responseMessage.textBody);\n                const turn = this.privTurnStateManager.GetTurn(responseRequestId);\n                // update the conversation Id\n                if (activityPayload.conversationId) {\n                    const updateAgentConfig = this.agentConfig.get();\n                    updateAgentConfig.botInfo.conversationId = activityPayload.conversationId;\n                    this.agentConfig.set(updateAgentConfig);\n                }\n                const pullAudioOutputStream = turn.processActivityPayload(activityPayload, _sdk_Audio_AudioOutputFormat__WEBPACK_IMPORTED_MODULE_31__.AudioOutputFormatImpl.fromSpeechSynthesisOutputFormatString(this.privDialogServiceConnector.properties.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.PropertyId.SpeechServiceConnection_SynthOutputFormat, undefined)));\n                const activity = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_32__.ActivityReceivedEventArgs(activityPayload.messagePayload, pullAudioOutputStream);\n                if (!!this.privDialogServiceConnector.activityReceived) {\n                    try {\n                        this.privDialogServiceConnector.activityReceived(this.privDialogServiceConnector, activity);\n                        /* eslint-disable-next-line no-empty */\n                    }\n                    catch (error) {\n                        // Not going to let errors in the event handler\n                        // trip things up.\n                    }\n                }\n                break;\n            case \"messagestatus\":\n                if (!!this.privDialogServiceConnector.turnStatusReceived) {\n                    try {\n                        this.privDialogServiceConnector.turnStatusReceived(this.privDialogServiceConnector, new _sdk_Exports__WEBPACK_IMPORTED_MODULE_33__.TurnStatusReceivedEventArgs(responseMessage.textBody));\n                        /* eslint-disable-next-line no-empty */\n                    }\n                    catch (error) {\n                        // Not going to let errors in the event handler\n                        // trip things up.\n                    }\n                }\n                break;\n            default:\n                _common_Exports__WEBPACK_IMPORTED_MODULE_25__.Events.instance.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_26__.BackgroundEvent(`Unexpected response of type ${responsePayload.messageType}. Ignoring.`));\n                break;\n        }\n    }\n    onEvent(event) {\n        this.privEvents.onEvent(event);\n        _common_Exports__WEBPACK_IMPORTED_MODULE_25__.Events.instance.onEvent(event);\n    }\n    addKeywordContextData() {\n        const keywordPropertyValue = this.privRecognizerConfig.parameters.getProperty(\"SPEECH-KeywordsToDetect\");\n        if (keywordPropertyValue === undefined) {\n            return;\n        }\n        const keywordOffsetPropertyValue = this.privRecognizerConfig.parameters\n            .getProperty(\"SPEECH-KeywordsToDetect-Offsets\");\n        const keywordDurationPropertyValue = this.privRecognizerConfig.parameters\n            .getProperty(\"SPEECH-KeywordsToDetect-Durations\");\n        const keywords = keywordPropertyValue.split(\";\");\n        const keywordOffsets = keywordOffsetPropertyValue === undefined ? [] : keywordOffsetPropertyValue.split(\";\");\n        const keywordDurations = keywordDurationPropertyValue === undefined ? [] : keywordDurationPropertyValue.split(\";\");\n        const keywordDefinitionArray = [];\n        for (let i = 0; i < keywords.length; i++) {\n            const definition = {};\n            definition.text = keywords[i];\n            if (i < keywordOffsets.length) {\n                definition.offset = Number(keywordOffsets[i]);\n            }\n            if (i < keywordDurations.length) {\n                definition.duration = Number(keywordDurations[i]);\n            }\n            keywordDefinitionArray.push(definition);\n        }\n        this.speechContext.setSection(\"invocationSource\", \"VoiceActivationWithKeyword\");\n        this.speechContext.setSection(\"keywordDetection\", [{\n                clientDetectedKeywords: keywordDefinitionArray,\n                onReject: { action: \"EndOfTurn\" },\n                type: \"startTrigger\"\n            }]);\n    }\n}\n\n//# sourceMappingURL=DialogServiceAdapter.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceAdapter.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceTurnState.js":
  /*!************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceTurnState.js ***!
    \************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"DialogServiceTurnState\": () => (/* binding */ DialogServiceTurnState)\n/* harmony export */ });\n/* harmony import */ var _sdk_Audio_AudioOutputFormat__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../sdk/Audio/AudioOutputFormat */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputFormat.js\");\n/* harmony import */ var _sdk_Audio_AudioOutputStream__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Audio/AudioOutputStream */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputStream.js\");\n/* harmony import */ var _ServiceMessages_ActivityResponsePayload__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./ServiceMessages/ActivityResponsePayload */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/ActivityResponsePayload.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\nclass DialogServiceTurnState {\n    constructor(manager, requestId) {\n        this.privRequestId = requestId;\n        this.privIsCompleted = false;\n        this.privAudioStream = null;\n        this.privTurnManager = manager;\n        this.resetTurnEndTimeout();\n    }\n    get audioStream() {\n        // Called when is needed to stream.\n        this.resetTurnEndTimeout();\n        return this.privAudioStream;\n    }\n    processActivityPayload(payload, audioFormat) {\n        if (payload.messageDataStreamType === _ServiceMessages_ActivityResponsePayload__WEBPACK_IMPORTED_MODULE_0__.MessageDataStreamType.TextToSpeechAudio) {\n            this.privAudioStream = _sdk_Audio_AudioOutputStream__WEBPACK_IMPORTED_MODULE_1__.AudioOutputStream.createPullStream();\n            this.privAudioStream.format = (audioFormat !== undefined) ? audioFormat : _sdk_Audio_AudioOutputFormat__WEBPACK_IMPORTED_MODULE_2__.AudioOutputFormatImpl.getDefaultOutputFormat();\n        }\n        return this.privAudioStream;\n    }\n    endAudioStream() {\n        if (this.privAudioStream !== null && !this.privAudioStream.isClosed) {\n            this.privAudioStream.close();\n        }\n    }\n    complete() {\n        if (this.privTimeoutToken !== undefined) {\n            // eslint-disable-next-line @typescript-eslint/no-unsafe-argument\n            clearTimeout(this.privTimeoutToken);\n        }\n        this.endAudioStream();\n    }\n    resetTurnEndTimeout() {\n        if (this.privTimeoutToken !== undefined) {\n            // eslint-disable-next-line @typescript-eslint/no-unsafe-argument\n            clearTimeout(this.privTimeoutToken);\n        }\n        this.privTimeoutToken = setTimeout(() => {\n            this.privTurnManager.CompleteTurn(this.privRequestId);\n            return;\n        }, 2000);\n    }\n}\n\n//# sourceMappingURL=DialogServiceTurnState.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceTurnState.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceTurnStateManager.js":
  /*!*******************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceTurnStateManager.js ***!
    \*******************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"DialogServiceTurnStateManager\": () => (/* binding */ DialogServiceTurnStateManager)\n/* harmony export */ });\n/* harmony import */ var _common_Error__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Error */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js\");\n/* harmony import */ var _DialogServiceTurnState__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./DialogServiceTurnState */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceTurnState.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\nclass DialogServiceTurnStateManager {\n    constructor() {\n        this.privTurnMap = new Map();\n        return;\n    }\n    StartTurn(id) {\n        if (this.privTurnMap.has(id)) {\n            throw new _common_Error__WEBPACK_IMPORTED_MODULE_0__.InvalidOperationError(\"Service error: There is already a turn with id:\" + id);\n        }\n        const turnState = new _DialogServiceTurnState__WEBPACK_IMPORTED_MODULE_1__.DialogServiceTurnState(this, id);\n        this.privTurnMap.set(id, turnState);\n        return this.privTurnMap.get(id);\n    }\n    GetTurn(id) {\n        return this.privTurnMap.get(id);\n    }\n    CompleteTurn(id) {\n        if (!this.privTurnMap.has(id)) {\n            throw new _common_Error__WEBPACK_IMPORTED_MODULE_0__.InvalidOperationError(\"Service error: Received turn end for an unknown turn id:\" + id);\n        }\n        const turnState = this.privTurnMap.get(id);\n        turnState.complete();\n        this.privTurnMap.delete(id);\n        return turnState;\n    }\n}\n\n//# sourceMappingURL=DialogServiceTurnStateManager.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceTurnStateManager.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DynamicGrammarBuilder.js":
  /*!***********************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DynamicGrammarBuilder.js ***!
    \***********************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"DynamicGrammarBuilder\": () => (/* binding */ DynamicGrammarBuilder)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Responsible for building the object to be sent to the speech service to support dynamic grammars.\n * @class DynamicGrammarBuilder\n */\nclass DynamicGrammarBuilder {\n    // Adds one more reference phrases to the dynamic grammar to send.\n    // All added phrases are generic phrases.\n    addPhrase(phrase) {\n        if (!this.privPhrases) {\n            this.privPhrases = [];\n        }\n        if (phrase instanceof Array) {\n            this.privPhrases = this.privPhrases.concat(phrase);\n        }\n        else {\n            this.privPhrases.push(phrase);\n        }\n    }\n    // Clears all phrases stored in the current object.\n    clearPhrases() {\n        this.privPhrases = undefined;\n    }\n    // Adds one or more reference grammars to the current grammar.\n    addReferenceGrammar(grammar) {\n        if (!this.privGrammars) {\n            this.privGrammars = [];\n        }\n        if (grammar instanceof Array) {\n            this.privGrammars = this.privGrammars.concat(grammar);\n        }\n        else {\n            this.privGrammars.push(grammar);\n        }\n    }\n    // clears all grammars stored on the recognizer.\n    clearGrammars() {\n        this.privGrammars = undefined;\n    }\n    // Generates an object that represents the dynamic grammar used by the Speech Service.\n    // This is done by building an object with the correct layout based on the phrases and reference grammars added to this instance\n    // of a DynamicGrammarBuilder\n    generateGrammarObject() {\n        if (this.privGrammars === undefined && this.privPhrases === undefined) {\n            return undefined;\n        }\n        const retObj = {};\n        retObj.ReferenceGrammars = this.privGrammars;\n        if (undefined !== this.privPhrases && 0 !== this.privPhrases.length) {\n            const retPhrases = [];\n            this.privPhrases.forEach((value) => {\n                retPhrases.push({\n                    Text: value,\n                });\n            });\n            retObj.Groups = [{ Type: \"Generic\", Items: retPhrases }];\n        }\n        return retObj;\n    }\n}\n\n//# sourceMappingURL=DynamicGrammarBuilder.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DynamicGrammarBuilder.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DynamicGrammarInterfaces.js":
  /*!**************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DynamicGrammarInterfaces.js ***!
    \**************************************************************************************************************************/
  /***/ (() => {
  
  eval("// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n//# sourceMappingURL=DynamicGrammarInterfaces.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DynamicGrammarInterfaces.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/EnumTranslation.js":
  /*!*****************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/EnumTranslation.js ***!
    \*****************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"EnumTranslation\": () => (/* binding */ EnumTranslation)\n/* harmony export */ });\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationReason.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/Enums.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\nclass EnumTranslation {\n    static implTranslateRecognitionResult(recognitionStatus) {\n        let reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.ResultReason.Canceled;\n        switch (recognitionStatus) {\n            case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.Success:\n                reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.ResultReason.RecognizedSpeech;\n                break;\n            case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.NoMatch:\n            case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.InitialSilenceTimeout:\n            case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.BabbleTimeout:\n            case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.EndOfDictation:\n                reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.ResultReason.NoMatch;\n                break;\n            case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.Error:\n            case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.BadRequest:\n            case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.Forbidden:\n            default:\n                reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.ResultReason.Canceled;\n                break;\n        }\n        return reason;\n    }\n    static implTranslateCancelResult(recognitionStatus) {\n        let reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.CancellationReason.EndOfStream;\n        switch (recognitionStatus) {\n            case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.Success:\n            case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.EndOfDictation:\n            case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.NoMatch:\n                reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.CancellationReason.EndOfStream;\n                break;\n            case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.InitialSilenceTimeout:\n            case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.BabbleTimeout:\n            case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.Error:\n            case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.BadRequest:\n            case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.Forbidden:\n            default:\n                reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.CancellationReason.Error;\n                break;\n        }\n        return reason;\n    }\n    static implTranslateCancelErrorCode(recognitionStatus) {\n        let reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.CancellationErrorCode.NoError;\n        switch (recognitionStatus) {\n            case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.Error:\n                reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.CancellationErrorCode.ServiceError;\n                break;\n            case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.TooManyRequests:\n                reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.CancellationErrorCode.TooManyRequests;\n                break;\n            case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.BadRequest:\n                reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.CancellationErrorCode.BadRequestParameters;\n                break;\n            case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.Forbidden:\n                reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.CancellationErrorCode.Forbidden;\n                break;\n            default:\n                reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.CancellationErrorCode.NoError;\n                break;\n        }\n        return reason;\n    }\n    static implTranslateErrorDetails(cancellationErrorCode) {\n        let errorDetails = \"The speech service encountered an internal error and could not continue.\";\n        switch (cancellationErrorCode) {\n            case _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.CancellationErrorCode.Forbidden:\n                errorDetails = \"The recognizer is using a free subscription that ran out of quota.\";\n                break;\n            case _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.CancellationErrorCode.BadRequestParameters:\n                errorDetails = \"Invalid parameter or unsupported audio format in the request.\";\n                break;\n            case _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.CancellationErrorCode.TooManyRequests:\n                errorDetails = \"The number of parallel requests exceeded the number of allowed concurrent transcriptions.\";\n                break;\n            default:\n                break;\n        }\n        return errorDetails;\n    }\n}\n\n//# sourceMappingURL=EnumTranslation.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/EnumTranslation.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js":
  /*!*********************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js ***!
    \*********************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AddedLmIntent\": () => (/* reexport safe */ _AddedLmIntent__WEBPACK_IMPORTED_MODULE_29__.AddedLmIntent),\n/* harmony export */   \"AgentConfig\": () => (/* reexport safe */ _AgentConfig__WEBPACK_IMPORTED_MODULE_37__.AgentConfig),\n/* harmony export */   \"AuthInfo\": () => (/* reexport safe */ _IAuthentication__WEBPACK_IMPORTED_MODULE_2__.AuthInfo),\n/* harmony export */   \"AutoDetectSourceLanguagesOpenRangeOptionName\": () => (/* binding */ AutoDetectSourceLanguagesOpenRangeOptionName),\n/* harmony export */   \"CancellationErrorCodePropertyName\": () => (/* binding */ CancellationErrorCodePropertyName),\n/* harmony export */   \"CognitiveSubscriptionKeyAuthentication\": () => (/* reexport safe */ _CognitiveSubscriptionKeyAuthentication__WEBPACK_IMPORTED_MODULE_0__.CognitiveSubscriptionKeyAuthentication),\n/* harmony export */   \"CognitiveTokenAuthentication\": () => (/* reexport safe */ _CognitiveTokenAuthentication__WEBPACK_IMPORTED_MODULE_1__.CognitiveTokenAuthentication),\n/* harmony export */   \"ConnectingToServiceEvent\": () => (/* reexport safe */ _RecognitionEvents__WEBPACK_IMPORTED_MODULE_6__.ConnectingToServiceEvent),\n/* harmony export */   \"Context\": () => (/* reexport safe */ _RecognizerConfig__WEBPACK_IMPORTED_MODULE_9__.Context),\n/* harmony export */   \"ConversationConnectionConfig\": () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_38__.ConversationConnectionConfig),\n/* harmony export */   \"ConversationManager\": () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_38__.ConversationManager),\n/* harmony export */   \"ConversationReceivedTranslationEventArgs\": () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_38__.ConversationReceivedTranslationEventArgs),\n/* harmony export */   \"ConversationRecognizerFactory\": () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_38__.ConversationRecognizerFactory),\n/* harmony export */   \"ConversationServiceRecognizer\": () => (/* reexport safe */ _ConversationServiceRecognizer__WEBPACK_IMPORTED_MODULE_8__.ConversationServiceRecognizer),\n/* harmony export */   \"ConversationTranslatorCommandTypes\": () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_38__.ConversationTranslatorCommandTypes),\n/* harmony export */   \"ConversationTranslatorMessageTypes\": () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_38__.ConversationTranslatorMessageTypes),\n/* harmony export */   \"DetailedSpeechPhrase\": () => (/* reexport safe */ _ServiceMessages_DetailedSpeechPhrase__WEBPACK_IMPORTED_MODULE_27__.DetailedSpeechPhrase),\n/* harmony export */   \"Device\": () => (/* reexport safe */ _RecognizerConfig__WEBPACK_IMPORTED_MODULE_9__.Device),\n/* harmony export */   \"DialogServiceAdapter\": () => (/* reexport safe */ _DialogServiceAdapter__WEBPACK_IMPORTED_MODULE_36__.DialogServiceAdapter),\n/* harmony export */   \"DynamicGrammarBuilder\": () => (/* reexport safe */ _DynamicGrammarBuilder__WEBPACK_IMPORTED_MODULE_34__.DynamicGrammarBuilder),\n/* harmony export */   \"EnumTranslation\": () => (/* reexport safe */ _EnumTranslation__WEBPACK_IMPORTED_MODULE_16__.EnumTranslation),\n/* harmony export */   \"ForceDictationPropertyName\": () => (/* binding */ ForceDictationPropertyName),\n/* harmony export */   \"IntentConnectionFactory\": () => (/* reexport safe */ _IntentConnectionFactory__WEBPACK_IMPORTED_MODULE_5__.IntentConnectionFactory),\n/* harmony export */   \"IntentResponse\": () => (/* reexport safe */ _ServiceMessages_IntentResponse__WEBPACK_IMPORTED_MODULE_31__.IntentResponse),\n/* harmony export */   \"IntentServiceRecognizer\": () => (/* reexport safe */ _IntentServiceRecognizer__WEBPACK_IMPORTED_MODULE_30__.IntentServiceRecognizer),\n/* harmony export */   \"InternalParticipants\": () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_38__.InternalParticipants),\n/* harmony export */   \"ListeningStartedEvent\": () => (/* reexport safe */ _RecognitionEvents__WEBPACK_IMPORTED_MODULE_6__.ListeningStartedEvent),\n/* harmony export */   \"LockRoomEventArgs\": () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_38__.LockRoomEventArgs),\n/* harmony export */   \"MetadataType\": () => (/* reexport safe */ _ServiceMessages_SynthesisAudioMetadata__WEBPACK_IMPORTED_MODULE_39__.MetadataType),\n/* harmony export */   \"MuteAllEventArgs\": () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_38__.MuteAllEventArgs),\n/* harmony export */   \"OS\": () => (/* reexport safe */ _RecognizerConfig__WEBPACK_IMPORTED_MODULE_9__.OS),\n/* harmony export */   \"OutputFormatPropertyName\": () => (/* binding */ OutputFormatPropertyName),\n/* harmony export */   \"ParticipantAttributeEventArgs\": () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_38__.ParticipantAttributeEventArgs),\n/* harmony export */   \"ParticipantEventArgs\": () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_38__.ParticipantEventArgs),\n/* harmony export */   \"ParticipantsListEventArgs\": () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_38__.ParticipantsListEventArgs),\n/* harmony export */   \"RecognitionCompletionStatus\": () => (/* reexport safe */ _RecognitionEvents__WEBPACK_IMPORTED_MODULE_6__.RecognitionCompletionStatus),\n/* harmony export */   \"RecognitionEndedEvent\": () => (/* reexport safe */ _RecognitionEvents__WEBPACK_IMPORTED_MODULE_6__.RecognitionEndedEvent),\n/* harmony export */   \"RecognitionMode\": () => (/* reexport safe */ _RecognizerConfig__WEBPACK_IMPORTED_MODULE_9__.RecognitionMode),\n/* harmony export */   \"RecognitionStartedEvent\": () => (/* reexport safe */ _RecognitionEvents__WEBPACK_IMPORTED_MODULE_6__.RecognitionStartedEvent),\n/* harmony export */   \"RecognitionStatus\": () => (/* reexport safe */ _ServiceMessages_Enums__WEBPACK_IMPORTED_MODULE_17__.RecognitionStatus),\n/* harmony export */   \"RecognitionTriggeredEvent\": () => (/* reexport safe */ _RecognitionEvents__WEBPACK_IMPORTED_MODULE_6__.RecognitionTriggeredEvent),\n/* harmony export */   \"RecognizerConfig\": () => (/* reexport safe */ _RecognizerConfig__WEBPACK_IMPORTED_MODULE_9__.RecognizerConfig),\n/* harmony export */   \"RequestSession\": () => (/* reexport safe */ _RequestSession__WEBPACK_IMPORTED_MODULE_32__.RequestSession),\n/* harmony export */   \"ServicePropertiesPropertyName\": () => (/* binding */ ServicePropertiesPropertyName),\n/* harmony export */   \"ServiceRecognizerBase\": () => (/* reexport safe */ _ServiceRecognizerBase__WEBPACK_IMPORTED_MODULE_7__.ServiceRecognizerBase),\n/* harmony export */   \"SimpleSpeechPhrase\": () => (/* reexport safe */ _ServiceMessages_SimpleSpeechPhrase__WEBPACK_IMPORTED_MODULE_28__.SimpleSpeechPhrase),\n/* harmony export */   \"SpeakerIdMessageAdapter\": () => (/* reexport safe */ _SpeakerIdMessageAdapter__WEBPACK_IMPORTED_MODULE_46__.SpeakerIdMessageAdapter),\n/* harmony export */   \"SpeakerRecognitionConfig\": () => (/* reexport safe */ _SpeakerRecognitionConfig__WEBPACK_IMPORTED_MODULE_45__.SpeakerRecognitionConfig),\n/* harmony export */   \"SpeechConnectionFactory\": () => (/* reexport safe */ _SpeechConnectionFactory__WEBPACK_IMPORTED_MODULE_12__.SpeechConnectionFactory),\n/* harmony export */   \"SpeechContext\": () => (/* reexport safe */ _SpeechContext__WEBPACK_IMPORTED_MODULE_33__.SpeechContext),\n/* harmony export */   \"SpeechDetected\": () => (/* reexport safe */ _ServiceMessages_SpeechDetected__WEBPACK_IMPORTED_MODULE_22__.SpeechDetected),\n/* harmony export */   \"SpeechHypothesis\": () => (/* reexport safe */ _ServiceMessages_SpeechHypothesis__WEBPACK_IMPORTED_MODULE_23__.SpeechHypothesis),\n/* harmony export */   \"SpeechKeyword\": () => (/* reexport safe */ _ServiceMessages_SpeechKeyword__WEBPACK_IMPORTED_MODULE_24__.SpeechKeyword),\n/* harmony export */   \"SpeechRecognitionEvent\": () => (/* reexport safe */ _RecognitionEvents__WEBPACK_IMPORTED_MODULE_6__.SpeechRecognitionEvent),\n/* harmony export */   \"SpeechResultFormat\": () => (/* reexport safe */ _RecognizerConfig__WEBPACK_IMPORTED_MODULE_9__.SpeechResultFormat),\n/* harmony export */   \"SpeechServiceConfig\": () => (/* reexport safe */ _RecognizerConfig__WEBPACK_IMPORTED_MODULE_9__.SpeechServiceConfig),\n/* harmony export */   \"SpeechServiceRecognizer\": () => (/* reexport safe */ _SpeechServiceRecognizer__WEBPACK_IMPORTED_MODULE_25__.SpeechServiceRecognizer),\n/* harmony export */   \"SpeechSynthesisConnectionFactory\": () => (/* reexport safe */ _SpeechSynthesisConnectionFactory__WEBPACK_IMPORTED_MODULE_15__.SpeechSynthesisConnectionFactory),\n/* harmony export */   \"SynthesisAdapterBase\": () => (/* reexport safe */ _SynthesisAdapterBase__WEBPACK_IMPORTED_MODULE_41__.SynthesisAdapterBase),\n/* harmony export */   \"SynthesisAudioMetadata\": () => (/* reexport safe */ _ServiceMessages_SynthesisAudioMetadata__WEBPACK_IMPORTED_MODULE_39__.SynthesisAudioMetadata),\n/* harmony export */   \"SynthesisContext\": () => (/* reexport safe */ _SynthesisContext__WEBPACK_IMPORTED_MODULE_44__.SynthesisContext),\n/* harmony export */   \"SynthesisRestAdapter\": () => (/* reexport safe */ _SynthesisRestAdapter__WEBPACK_IMPORTED_MODULE_42__.SynthesisRestAdapter),\n/* harmony export */   \"SynthesisServiceType\": () => (/* reexport safe */ _SynthesizerConfig__WEBPACK_IMPORTED_MODULE_43__.SynthesisServiceType),\n/* harmony export */   \"SynthesisStatus\": () => (/* reexport safe */ _ServiceMessages_Enums__WEBPACK_IMPORTED_MODULE_17__.SynthesisStatus),\n/* harmony export */   \"SynthesisTurn\": () => (/* reexport safe */ _SynthesisTurn__WEBPACK_IMPORTED_MODULE_40__.SynthesisTurn),\n/* harmony export */   \"SynthesizerConfig\": () => (/* reexport safe */ _SynthesizerConfig__WEBPACK_IMPORTED_MODULE_43__.SynthesizerConfig),\n/* harmony export */   \"System\": () => (/* reexport safe */ _RecognizerConfig__WEBPACK_IMPORTED_MODULE_9__.System),\n/* harmony export */   \"TranscriberConnectionFactory\": () => (/* reexport safe */ _TranscriberConnectionFactory__WEBPACK_IMPORTED_MODULE_13__.TranscriberConnectionFactory),\n/* harmony export */   \"TranscriberRecognizer\": () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_38__.TranscriberRecognizer),\n/* harmony export */   \"TranscriptionServiceRecognizer\": () => (/* reexport safe */ _TranscriptionServiceRecognizer__WEBPACK_IMPORTED_MODULE_26__.TranscriptionServiceRecognizer),\n/* harmony export */   \"TranslationConnectionFactory\": () => (/* reexport safe */ _TranslationConnectionFactory__WEBPACK_IMPORTED_MODULE_14__.TranslationConnectionFactory),\n/* harmony export */   \"TranslationHypothesis\": () => (/* reexport safe */ _ServiceMessages_TranslationHypothesis__WEBPACK_IMPORTED_MODULE_19__.TranslationHypothesis),\n/* harmony export */   \"TranslationPhrase\": () => (/* reexport safe */ _ServiceMessages_TranslationPhrase__WEBPACK_IMPORTED_MODULE_20__.TranslationPhrase),\n/* harmony export */   \"TranslationServiceRecognizer\": () => (/* reexport safe */ _TranslationServiceRecognizer__WEBPACK_IMPORTED_MODULE_21__.TranslationServiceRecognizer),\n/* harmony export */   \"TranslationSynthesisEnd\": () => (/* reexport safe */ _ServiceMessages_TranslationSynthesisEnd__WEBPACK_IMPORTED_MODULE_18__.TranslationSynthesisEnd),\n/* harmony export */   \"WebsocketMessageFormatter\": () => (/* reexport safe */ _WebsocketMessageFormatter__WEBPACK_IMPORTED_MODULE_11__.WebsocketMessageFormatter),\n/* harmony export */   \"connectivity\": () => (/* reexport safe */ _RecognizerConfig__WEBPACK_IMPORTED_MODULE_9__.connectivity),\n/* harmony export */   \"type\": () => (/* reexport safe */ _RecognizerConfig__WEBPACK_IMPORTED_MODULE_9__.type)\n/* harmony export */ });\n/* harmony import */ var _CognitiveSubscriptionKeyAuthentication__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./CognitiveSubscriptionKeyAuthentication */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/CognitiveSubscriptionKeyAuthentication.js\");\n/* harmony import */ var _CognitiveTokenAuthentication__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./CognitiveTokenAuthentication */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/CognitiveTokenAuthentication.js\");\n/* harmony import */ var _IAuthentication__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./IAuthentication */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IAuthentication.js\");\n/* harmony import */ var _IConnectionFactory__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./IConnectionFactory */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IConnectionFactory.js\");\n/* harmony import */ var _IConnectionFactory__WEBPACK_IMPORTED_MODULE_3___default = /*#__PURE__*/__webpack_require__.n(_IConnectionFactory__WEBPACK_IMPORTED_MODULE_3__);\n/* harmony reexport (unknown) */ var __WEBPACK_REEXPORT_OBJECT__ = {};\n/* harmony reexport (unknown) */ for(const __WEBPACK_IMPORT_KEY__ in _IConnectionFactory__WEBPACK_IMPORTED_MODULE_3__) if([\"default\",\"OutputFormatPropertyName\",\"CancellationErrorCodePropertyName\",\"ServicePropertiesPropertyName\",\"ForceDictationPropertyName\",\"AutoDetectSourceLanguagesOpenRangeOptionName\",\"CognitiveSubscriptionKeyAuthentication\",\"CognitiveTokenAuthentication\",\"AuthInfo\"].indexOf(__WEBPACK_IMPORT_KEY__) < 0) __WEBPACK_REEXPORT_OBJECT__[__WEBPACK_IMPORT_KEY__] = () => _IConnectionFactory__WEBPACK_IMPORTED_MODULE_3__[__WEBPACK_IMPORT_KEY__]\n/* harmony reexport (unknown) */ __webpack_require__.d(__webpack_exports__, __WEBPACK_REEXPORT_OBJECT__);\n/* harmony import */ var _ISynthesisConnectionFactory__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./ISynthesisConnectionFactory */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ISynthesisConnectionFactory.js\");\n/* harmony import */ var _ISynthesisConnectionFactory__WEBPACK_IMPORTED_MODULE_4___default = /*#__PURE__*/__webpack_require__.n(_ISynthesisConnectionFactory__WEBPACK_IMPORTED_MODULE_4__);\n/* harmony reexport (unknown) */ var __WEBPACK_REEXPORT_OBJECT__ = {};\n/* harmony reexport (unknown) */ for(const __WEBPACK_IMPORT_KEY__ in _ISynthesisConnectionFactory__WEBPACK_IMPORTED_MODULE_4__) if([\"default\",\"OutputFormatPropertyName\",\"CancellationErrorCodePropertyName\",\"ServicePropertiesPropertyName\",\"ForceDictationPropertyName\",\"AutoDetectSourceLanguagesOpenRangeOptionName\",\"CognitiveSubscriptionKeyAuthentication\",\"CognitiveTokenAuthentication\",\"AuthInfo\"].indexOf(__WEBPACK_IMPORT_KEY__) < 0) __WEBPACK_REEXPORT_OBJECT__[__WEBPACK_IMPORT_KEY__] = () => _ISynthesisConnectionFactory__WEBPACK_IMPORTED_MODULE_4__[__WEBPACK_IMPORT_KEY__]\n/* harmony reexport (unknown) */ __webpack_require__.d(__webpack_exports__, __WEBPACK_REEXPORT_OBJECT__);\n/* harmony import */ var _IntentConnectionFactory__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./IntentConnectionFactory */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IntentConnectionFactory.js\");\n/* harmony import */ var _RecognitionEvents__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./RecognitionEvents */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognitionEvents.js\");\n/* harmony import */ var _ServiceRecognizerBase__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./ServiceRecognizerBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceRecognizerBase.js\");\n/* harmony import */ var _ConversationServiceRecognizer__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./ConversationServiceRecognizer */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConversationServiceRecognizer.js\");\n/* harmony import */ var _RecognizerConfig__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./RecognizerConfig */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js\");\n/* harmony import */ var _SpeechServiceInterfaces__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./SpeechServiceInterfaces */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechServiceInterfaces.js\");\n/* harmony import */ var _SpeechServiceInterfaces__WEBPACK_IMPORTED_MODULE_10___default = /*#__PURE__*/__webpack_require__.n(_SpeechServiceInterfaces__WEBPACK_IMPORTED_MODULE_10__);\n/* harmony reexport (unknown) */ var __WEBPACK_REEXPORT_OBJECT__ = {};\n/* harmony reexport (unknown) */ for(const __WEBPACK_IMPORT_KEY__ in _SpeechServiceInterfaces__WEBPACK_IMPORTED_MODULE_10__) if([\"default\",\"OutputFormatPropertyName\",\"CancellationErrorCodePropertyName\",\"ServicePropertiesPropertyName\",\"ForceDictationPropertyName\",\"AutoDetectSourceLanguagesOpenRangeOptionName\",\"CognitiveSubscriptionKeyAuthentication\",\"CognitiveTokenAuthentication\",\"AuthInfo\",\"IntentConnectionFactory\",\"ConnectingToServiceEvent\",\"ListeningStartedEvent\",\"RecognitionCompletionStatus\",\"RecognitionEndedEvent\",\"RecognitionStartedEvent\",\"RecognitionTriggeredEvent\",\"SpeechRecognitionEvent\",\"ServiceRecognizerBase\",\"ConversationServiceRecognizer\",\"Context\",\"Device\",\"OS\",\"RecognitionMode\",\"RecognizerConfig\",\"SpeechResultFormat\",\"SpeechServiceConfig\",\"System\",\"connectivity\",\"type\"].indexOf(__WEBPACK_IMPORT_KEY__) < 0) __WEBPACK_REEXPORT_OBJECT__[__WEBPACK_IMPORT_KEY__] = () => _SpeechServiceInterfaces__WEBPACK_IMPORTED_MODULE_10__[__WEBPACK_IMPORT_KEY__]\n/* harmony reexport (unknown) */ __webpack_require__.d(__webpack_exports__, __WEBPACK_REEXPORT_OBJECT__);\n/* harmony import */ var _WebsocketMessageFormatter__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./WebsocketMessageFormatter */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/WebsocketMessageFormatter.js\");\n/* harmony import */ var _SpeechConnectionFactory__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./SpeechConnectionFactory */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionFactory.js\");\n/* harmony import */ var _TranscriberConnectionFactory__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./TranscriberConnectionFactory */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranscriberConnectionFactory.js\");\n/* harmony import */ var _TranslationConnectionFactory__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./TranslationConnectionFactory */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationConnectionFactory.js\");\n/* harmony import */ var _SpeechSynthesisConnectionFactory__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./SpeechSynthesisConnectionFactory */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechSynthesisConnectionFactory.js\");\n/* harmony import */ var _EnumTranslation__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ./EnumTranslation */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/EnumTranslation.js\");\n/* harmony import */ var _ServiceMessages_Enums__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ./ServiceMessages/Enums */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/Enums.js\");\n/* harmony import */ var _ServiceMessages_TranslationSynthesisEnd__WEBPACK_IMPORTED_MODULE_18__ = __webpack_require__(/*! ./ServiceMessages/TranslationSynthesisEnd */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationSynthesisEnd.js\");\n/* harmony import */ var _ServiceMessages_TranslationHypothesis__WEBPACK_IMPORTED_MODULE_19__ = __webpack_require__(/*! ./ServiceMessages/TranslationHypothesis */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationHypothesis.js\");\n/* harmony import */ var _ServiceMessages_TranslationPhrase__WEBPACK_IMPORTED_MODULE_20__ = __webpack_require__(/*! ./ServiceMessages/TranslationPhrase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationPhrase.js\");\n/* harmony import */ var _TranslationServiceRecognizer__WEBPACK_IMPORTED_MODULE_21__ = __webpack_require__(/*! ./TranslationServiceRecognizer */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationServiceRecognizer.js\");\n/* harmony import */ var _ServiceMessages_SpeechDetected__WEBPACK_IMPORTED_MODULE_22__ = __webpack_require__(/*! ./ServiceMessages/SpeechDetected */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechDetected.js\");\n/* harmony import */ var _ServiceMessages_SpeechHypothesis__WEBPACK_IMPORTED_MODULE_23__ = __webpack_require__(/*! ./ServiceMessages/SpeechHypothesis */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechHypothesis.js\");\n/* harmony import */ var _ServiceMessages_SpeechKeyword__WEBPACK_IMPORTED_MODULE_24__ = __webpack_require__(/*! ./ServiceMessages/SpeechKeyword */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechKeyword.js\");\n/* harmony import */ var _SpeechServiceRecognizer__WEBPACK_IMPORTED_MODULE_25__ = __webpack_require__(/*! ./SpeechServiceRecognizer */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechServiceRecognizer.js\");\n/* harmony import */ var _TranscriptionServiceRecognizer__WEBPACK_IMPORTED_MODULE_26__ = __webpack_require__(/*! ./TranscriptionServiceRecognizer */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranscriptionServiceRecognizer.js\");\n/* harmony import */ var _ServiceMessages_DetailedSpeechPhrase__WEBPACK_IMPORTED_MODULE_27__ = __webpack_require__(/*! ./ServiceMessages/DetailedSpeechPhrase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/DetailedSpeechPhrase.js\");\n/* harmony import */ var _ServiceMessages_SimpleSpeechPhrase__WEBPACK_IMPORTED_MODULE_28__ = __webpack_require__(/*! ./ServiceMessages/SimpleSpeechPhrase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SimpleSpeechPhrase.js\");\n/* harmony import */ var _AddedLmIntent__WEBPACK_IMPORTED_MODULE_29__ = __webpack_require__(/*! ./AddedLmIntent */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/AddedLmIntent.js\");\n/* harmony import */ var _IntentServiceRecognizer__WEBPACK_IMPORTED_MODULE_30__ = __webpack_require__(/*! ./IntentServiceRecognizer */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IntentServiceRecognizer.js\");\n/* harmony import */ var _ServiceMessages_IntentResponse__WEBPACK_IMPORTED_MODULE_31__ = __webpack_require__(/*! ./ServiceMessages/IntentResponse */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/IntentResponse.js\");\n/* harmony import */ var _RequestSession__WEBPACK_IMPORTED_MODULE_32__ = __webpack_require__(/*! ./RequestSession */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RequestSession.js\");\n/* harmony import */ var _SpeechContext__WEBPACK_IMPORTED_MODULE_33__ = __webpack_require__(/*! ./SpeechContext */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechContext.js\");\n/* harmony import */ var _DynamicGrammarBuilder__WEBPACK_IMPORTED_MODULE_34__ = __webpack_require__(/*! ./DynamicGrammarBuilder */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DynamicGrammarBuilder.js\");\n/* harmony import */ var _DynamicGrammarInterfaces__WEBPACK_IMPORTED_MODULE_35__ = __webpack_require__(/*! ./DynamicGrammarInterfaces */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DynamicGrammarInterfaces.js\");\n/* harmony import */ var _DynamicGrammarInterfaces__WEBPACK_IMPORTED_MODULE_35___default = /*#__PURE__*/__webpack_require__.n(_DynamicGrammarInterfaces__WEBPACK_IMPORTED_MODULE_35__);\n/* harmony reexport (unknown) */ var __WEBPACK_REEXPORT_OBJECT__ = {};\n/* harmony reexport (unknown) */ for(const __WEBPACK_IMPORT_KEY__ in _DynamicGrammarInterfaces__WEBPACK_IMPORTED_MODULE_35__) if([\"default\",\"OutputFormatPropertyName\",\"CancellationErrorCodePropertyName\",\"ServicePropertiesPropertyName\",\"ForceDictationPropertyName\",\"AutoDetectSourceLanguagesOpenRangeOptionName\",\"CognitiveSubscriptionKeyAuthentication\",\"CognitiveTokenAuthentication\",\"AuthInfo\",\"IntentConnectionFactory\",\"ConnectingToServiceEvent\",\"ListeningStartedEvent\",\"RecognitionCompletionStatus\",\"RecognitionEndedEvent\",\"RecognitionStartedEvent\",\"RecognitionTriggeredEvent\",\"SpeechRecognitionEvent\",\"ServiceRecognizerBase\",\"ConversationServiceRecognizer\",\"Context\",\"Device\",\"OS\",\"RecognitionMode\",\"RecognizerConfig\",\"SpeechResultFormat\",\"SpeechServiceConfig\",\"System\",\"connectivity\",\"type\",\"WebsocketMessageFormatter\",\"SpeechConnectionFactory\",\"TranscriberConnectionFactory\",\"TranslationConnectionFactory\",\"SpeechSynthesisConnectionFactory\",\"EnumTranslation\",\"RecognitionStatus\",\"SynthesisStatus\",\"TranslationSynthesisEnd\",\"TranslationHypothesis\",\"TranslationPhrase\",\"TranslationServiceRecognizer\",\"SpeechDetected\",\"SpeechHypothesis\",\"SpeechKeyword\",\"SpeechServiceRecognizer\",\"TranscriptionServiceRecognizer\",\"DetailedSpeechPhrase\",\"SimpleSpeechPhrase\",\"AddedLmIntent\",\"IntentServiceRecognizer\",\"IntentResponse\",\"RequestSession\",\"SpeechContext\",\"DynamicGrammarBuilder\"].indexOf(__WEBPACK_IMPORT_KEY__) < 0) __WEBPACK_REEXPORT_OBJECT__[__WEBPACK_IMPORT_KEY__] = () => _DynamicGrammarInterfaces__WEBPACK_IMPORTED_MODULE_35__[__WEBPACK_IMPORT_KEY__]\n/* harmony reexport (unknown) */ __webpack_require__.d(__webpack_exports__, __WEBPACK_REEXPORT_OBJECT__);\n/* harmony import */ var _DialogServiceAdapter__WEBPACK_IMPORTED_MODULE_36__ = __webpack_require__(/*! ./DialogServiceAdapter */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceAdapter.js\");\n/* harmony import */ var _AgentConfig__WEBPACK_IMPORTED_MODULE_37__ = __webpack_require__(/*! ./AgentConfig */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/AgentConfig.js\");\n/* harmony import */ var _Transcription_Exports__WEBPACK_IMPORTED_MODULE_38__ = __webpack_require__(/*! ./Transcription/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/Exports.js\");\n/* harmony import */ var _ServiceMessages_SynthesisAudioMetadata__WEBPACK_IMPORTED_MODULE_39__ = __webpack_require__(/*! ./ServiceMessages/SynthesisAudioMetadata */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SynthesisAudioMetadata.js\");\n/* harmony import */ var _SynthesisTurn__WEBPACK_IMPORTED_MODULE_40__ = __webpack_require__(/*! ./SynthesisTurn */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisTurn.js\");\n/* harmony import */ var _SynthesisAdapterBase__WEBPACK_IMPORTED_MODULE_41__ = __webpack_require__(/*! ./SynthesisAdapterBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisAdapterBase.js\");\n/* harmony import */ var _SynthesisRestAdapter__WEBPACK_IMPORTED_MODULE_42__ = __webpack_require__(/*! ./SynthesisRestAdapter */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisRestAdapter.js\");\n/* harmony import */ var _SynthesizerConfig__WEBPACK_IMPORTED_MODULE_43__ = __webpack_require__(/*! ./SynthesizerConfig */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesizerConfig.js\");\n/* harmony import */ var _SynthesisContext__WEBPACK_IMPORTED_MODULE_44__ = __webpack_require__(/*! ./SynthesisContext */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisContext.js\");\n/* harmony import */ var _SpeakerRecognitionConfig__WEBPACK_IMPORTED_MODULE_45__ = __webpack_require__(/*! ./SpeakerRecognitionConfig */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeakerRecognitionConfig.js\");\n/* harmony import */ var _SpeakerIdMessageAdapter__WEBPACK_IMPORTED_MODULE_46__ = __webpack_require__(/*! ./SpeakerIdMessageAdapter */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeakerIdMessageAdapter.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n// Make sure not to export internal modules.\n//\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nconst OutputFormatPropertyName = \"OutputFormat\";\nconst CancellationErrorCodePropertyName = \"CancellationErrorCode\";\nconst ServicePropertiesPropertyName = \"ServiceProperties\";\nconst ForceDictationPropertyName = \"ForceDictation\";\nconst AutoDetectSourceLanguagesOpenRangeOptionName = \"OpenRange\";\n\n//# sourceMappingURL=Exports.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js":
  /*!*************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js ***!
    \*************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"HeaderNames\": () => (/* binding */ HeaderNames)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nclass HeaderNames {\n}\nHeaderNames.AuthKey = \"Ocp-Apim-Subscription-Key\";\nHeaderNames.Authorization = \"Authorization\";\nHeaderNames.ConnectionId = \"X-ConnectionId\";\nHeaderNames.ContentType = \"Content-Type\";\nHeaderNames.CustomCommandsAppId = \"X-CommandsAppId\";\nHeaderNames.Path = \"Path\";\nHeaderNames.RequestId = \"X-RequestId\";\nHeaderNames.RequestStreamId = \"X-StreamId\";\nHeaderNames.RequestTimestamp = \"X-Timestamp\";\n\n//# sourceMappingURL=HeaderNames.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IAuthentication.js":
  /*!*****************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IAuthentication.js ***!
    \*****************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AuthInfo\": () => (/* binding */ AuthInfo)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nclass AuthInfo {\n    constructor(headerName, token) {\n        this.privHeaderName = headerName;\n        this.privToken = token;\n    }\n    get headerName() {\n        return this.privHeaderName;\n    }\n    get token() {\n        return this.privToken;\n    }\n}\n\n//# sourceMappingURL=IAuthentication.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IAuthentication.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IConnectionFactory.js":
  /*!********************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IConnectionFactory.js ***!
    \********************************************************************************************************************/
  /***/ (() => {
  
  eval("// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n//# sourceMappingURL=IConnectionFactory.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IConnectionFactory.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ISynthesisConnectionFactory.js":
  /*!*****************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ISynthesisConnectionFactory.js ***!
    \*****************************************************************************************************************************/
  /***/ (() => {
  
  eval("// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n//# sourceMappingURL=ISynthesisConnectionFactory.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ISynthesisConnectionFactory.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IntentConnectionFactory.js":
  /*!*************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IntentConnectionFactory.js ***!
    \*************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"IntentConnectionFactory\": () => (/* binding */ IntentConnectionFactory)\n/* harmony export */ });\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketConnection.js\");\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ProxyInfo.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./ConnectionFactoryBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/WebsocketMessageFormatter.js\");\n/* harmony import */ var _HeaderNames__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./HeaderNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\n\n\nclass IntentConnectionFactory extends _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__.ConnectionFactoryBase {\n    create(config, authInfo, connectionId) {\n        let endpoint = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Endpoint);\n        if (!endpoint) {\n            const region = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_IntentRegion);\n            const hostSuffix = _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__.ConnectionFactoryBase.getHostSuffix(region);\n            const host = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Host, \"wss://\" + region + \".sr.speech\" + hostSuffix);\n            endpoint = host + \"/speech/recognition/interactive/cognitiveservices/v1\";\n        }\n        const queryParams = {\n            format: \"simple\",\n            language: config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_RecoLanguage),\n        };\n        this.setCommonUrlParams(config, queryParams, endpoint);\n        const headers = {};\n        if (authInfo.token !== undefined && authInfo.token !== \"\") {\n            headers[authInfo.headerName] = authInfo.token;\n        }\n        headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_2__.HeaderNames.ConnectionId] = connectionId;\n        config.parameters.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Url, endpoint);\n        const enableCompression = config.parameters.getProperty(\"SPEECH-EnableWebsocketCompression\", \"false\") === \"true\";\n        return new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_3__.WebsocketConnection(endpoint, queryParams, headers, new _Exports__WEBPACK_IMPORTED_MODULE_4__.WebsocketMessageFormatter(), _common_browser_Exports__WEBPACK_IMPORTED_MODULE_5__.ProxyInfo.fromRecognizerConfig(config), enableCompression, connectionId);\n    }\n    getSpeechRegionFromIntentRegion(intentRegion) {\n        switch (intentRegion) {\n            case \"West US\":\n            case \"US West\":\n            case \"westus\":\n                return \"uswest\";\n            case \"West US 2\":\n            case \"US West 2\":\n            case \"westus2\":\n                return \"uswest2\";\n            case \"South Central US\":\n            case \"US South Central\":\n            case \"southcentralus\":\n                return \"ussouthcentral\";\n            case \"West Central US\":\n            case \"US West Central\":\n            case \"westcentralus\":\n                return \"uswestcentral\";\n            case \"East US\":\n            case \"US East\":\n            case \"eastus\":\n                return \"useast\";\n            case \"East US 2\":\n            case \"US East 2\":\n            case \"eastus2\":\n                return \"useast2\";\n            case \"West Europe\":\n            case \"Europe West\":\n            case \"westeurope\":\n                return \"europewest\";\n            case \"North Europe\":\n            case \"Europe North\":\n            case \"northeurope\":\n                return \"europenorth\";\n            case \"Brazil South\":\n            case \"South Brazil\":\n            case \"southbrazil\":\n                return \"brazilsouth\";\n            case \"Australia East\":\n            case \"East Australia\":\n            case \"eastaustralia\":\n                return \"australiaeast\";\n            case \"Southeast Asia\":\n            case \"Asia Southeast\":\n            case \"southeastasia\":\n                return \"asiasoutheast\";\n            case \"East Asia\":\n            case \"Asia East\":\n            case \"eastasia\":\n                return \"asiaeast\";\n            default:\n                return intentRegion;\n        }\n    }\n}\n\n//# sourceMappingURL=IntentConnectionFactory.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IntentConnectionFactory.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IntentServiceRecognizer.js":
  /*!*************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IntentServiceRecognizer.js ***!
    \*************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"IntentServiceRecognizer\": () => (/* binding */ IntentServiceRecognizer)\n/* harmony export */ });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionResult.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionEventArgs.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionCanceledEventArgs.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceRecognizerBase.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechHypothesis.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SimpleSpeechPhrase.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/EnumTranslation.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/IntentResponse.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\n// eslint-disable-next-line max-classes-per-file\nclass IntentServiceRecognizer extends _Exports__WEBPACK_IMPORTED_MODULE_0__.ServiceRecognizerBase {\n    constructor(authentication, connectionFactory, audioSource, recognizerConfig, recognizer) {\n        super(authentication, connectionFactory, audioSource, recognizerConfig, recognizer);\n        this.privIntentRecognizer = recognizer;\n        this.privIntentDataSent = false;\n    }\n    setIntents(addedIntents, umbrellaIntent) {\n        this.privAddedLmIntents = addedIntents;\n        this.privUmbrellaIntent = umbrellaIntent;\n        this.privIntentDataSent = true;\n    }\n    processTypeSpecificMessages(connectionMessage) {\n        let result;\n        let ev;\n        let processed = false;\n        const resultProps = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyCollection();\n        if (connectionMessage.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_2__.MessageType.Text) {\n            resultProps.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceResponse_JsonResult, connectionMessage.textBody);\n        }\n        switch (connectionMessage.path.toLowerCase()) {\n            case \"speech.hypothesis\":\n                const speechHypothesis = _Exports__WEBPACK_IMPORTED_MODULE_4__.SpeechHypothesis.fromJSON(connectionMessage.textBody);\n                result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.IntentRecognitionResult(undefined, this.privRequestSession.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.ResultReason.RecognizingIntent, speechHypothesis.Text, speechHypothesis.Duration, speechHypothesis.Offset + this.privRequestSession.currentTurnAudioOffset, speechHypothesis.Language, speechHypothesis.LanguageDetectionConfidence, undefined, connectionMessage.textBody, resultProps);\n                this.privRequestSession.onHypothesis(result.offset);\n                ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_7__.IntentRecognitionEventArgs(result, speechHypothesis.Offset + this.privRequestSession.currentTurnAudioOffset, this.privRequestSession.sessionId);\n                if (!!this.privIntentRecognizer.recognizing) {\n                    try {\n                        this.privIntentRecognizer.recognizing(this.privIntentRecognizer, ev);\n                        /* eslint-disable no-empty */\n                    }\n                    catch (error) {\n                        // Not going to let errors in the event handler\n                        // trip things up.\n                    }\n                }\n                processed = true;\n                break;\n            case \"speech.phrase\":\n                const simple = _Exports__WEBPACK_IMPORTED_MODULE_8__.SimpleSpeechPhrase.fromJSON(connectionMessage.textBody);\n                result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.IntentRecognitionResult(undefined, this.privRequestSession.requestId, _Exports__WEBPACK_IMPORTED_MODULE_9__.EnumTranslation.implTranslateRecognitionResult(simple.RecognitionStatus), simple.DisplayText, simple.Duration, simple.Offset + this.privRequestSession.currentTurnAudioOffset, simple.Language, simple.LanguageDetectionConfidence, undefined, connectionMessage.textBody, resultProps);\n                ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_7__.IntentRecognitionEventArgs(result, result.offset, this.privRequestSession.sessionId);\n                const sendEvent = () => {\n                    if (!!this.privIntentRecognizer.recognized) {\n                        try {\n                            this.privIntentRecognizer.recognized(this.privIntentRecognizer, ev);\n                            /* eslint-disable no-empty */\n                        }\n                        catch (error) {\n                            // Not going to let errors in the event handler\n                            // trip things up.\n                        }\n                    }\n                    // report result to promise.\n                    if (!!this.privSuccessCallback) {\n                        try {\n                            this.privSuccessCallback(result);\n                        }\n                        catch (e) {\n                            if (!!this.privErrorCallback) {\n                                this.privErrorCallback(e);\n                            }\n                        }\n                        // Only invoke the call back once.\n                        // and if it's successful don't invoke the\n                        // error after that.\n                        this.privSuccessCallback = undefined;\n                        this.privErrorCallback = undefined;\n                    }\n                };\n                // If intent data was sent, the terminal result for this recognizer is an intent being found.\n                // If no intent data was sent, the terminal event is speech recognition being successful.\n                if (false === this.privIntentDataSent || _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.ResultReason.NoMatch === ev.result.reason) {\n                    // Advance the buffers.\n                    this.privRequestSession.onPhraseRecognized(ev.offset + ev.result.duration);\n                    sendEvent();\n                }\n                else {\n                    // Squirrel away the args, when the response event arrives it will build upon them\n                    // and then return\n                    this.privPendingIntentArgs = ev;\n                }\n                processed = true;\n                break;\n            case \"response\":\n                // Response from LUIS\n                ev = this.privPendingIntentArgs;\n                this.privPendingIntentArgs = undefined;\n                if (undefined === ev) {\n                    if (\"\" === connectionMessage.textBody) {\n                        // This condition happens if there is nothing but silence in the\n                        // audio sent to the service.\n                        return;\n                    }\n                    // Odd... Not sure this can happen\n                    ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_7__.IntentRecognitionEventArgs(new _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.IntentRecognitionResult(), 0, this.privRequestSession.sessionId);\n                }\n                const intentResponse = _Exports__WEBPACK_IMPORTED_MODULE_10__.IntentResponse.fromJSON(connectionMessage.textBody);\n                // If LUIS didn't return anything, send the existing event, else\n                // modify it to show the match.\n                // See if the intent found is in the list of intents asked for.\n                if (null !== intentResponse && !!intentResponse.topScoringIntent && !!intentResponse.topScoringIntent.intent) {\n                    let addedIntent = this.privAddedLmIntents[intentResponse.topScoringIntent.intent];\n                    if (this.privUmbrellaIntent !== undefined) {\n                        addedIntent = this.privUmbrellaIntent;\n                    }\n                    if (!!addedIntent) {\n                        const intentId = addedIntent === undefined || addedIntent.intentName === undefined ? intentResponse.topScoringIntent.intent : addedIntent.intentName;\n                        let reason = ev.result.reason;\n                        if (undefined !== intentId) {\n                            reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.ResultReason.RecognizedIntent;\n                        }\n                        // make sure, properties is set.\n                        const properties = (undefined !== ev.result.properties) ?\n                            ev.result.properties : new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyCollection();\n                        properties.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.LanguageUnderstandingServiceResponse_JsonResult, connectionMessage.textBody);\n                        ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_7__.IntentRecognitionEventArgs(new _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.IntentRecognitionResult(intentId, ev.result.resultId, reason, ev.result.text, ev.result.duration, ev.result.offset, undefined, undefined, ev.result.errorDetails, ev.result.json, properties), ev.offset, ev.sessionId);\n                    }\n                }\n                this.privRequestSession.onPhraseRecognized(ev.offset + ev.result.duration);\n                if (!!this.privIntentRecognizer.recognized) {\n                    try {\n                        this.privIntentRecognizer.recognized(this.privIntentRecognizer, ev);\n                        /* eslint-disable no-empty */\n                    }\n                    catch (error) {\n                        // Not going to let errors in the event handler\n                        // trip things up.\n                    }\n                }\n                // report result to promise.\n                if (!!this.privSuccessCallback) {\n                    try {\n                        this.privSuccessCallback(ev.result);\n                    }\n                    catch (e) {\n                        if (!!this.privErrorCallback) {\n                            this.privErrorCallback(e);\n                        }\n                    }\n                    // Only invoke the call back once.\n                    // and if it's successful don't invoke the\n                    // error after that.\n                    this.privSuccessCallback = undefined;\n                    this.privErrorCallback = undefined;\n                }\n                processed = true;\n                break;\n            default:\n                break;\n        }\n        const defferal = new _common_Exports__WEBPACK_IMPORTED_MODULE_11__.Deferred();\n        defferal.resolve(processed);\n        return defferal.promise;\n    }\n    // Cancels recognition.\n    cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {\n        const properties = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyCollection();\n        properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_12__.CancellationErrorCodePropertyName, _sdk_Exports__WEBPACK_IMPORTED_MODULE_13__.CancellationErrorCode[errorCode]);\n        if (!!this.privIntentRecognizer.canceled) {\n            const cancelEvent = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_14__.IntentRecognitionCanceledEventArgs(cancellationReason, error, errorCode, undefined, undefined, sessionId);\n            try {\n                this.privIntentRecognizer.canceled(this.privIntentRecognizer, cancelEvent);\n                /* eslint-disable no-empty */\n            }\n            catch (_a) { }\n        }\n        if (!!this.privSuccessCallback) {\n            const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.IntentRecognitionResult(undefined, // Intent Id\n            requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.ResultReason.Canceled, undefined, // Text\n            undefined, // Duration\n            undefined, // Offset\n            undefined, // Language\n            undefined, // LanguageDetectionConfidence\n            error, undefined, // Json\n            properties);\n            try {\n                this.privSuccessCallback(result);\n                this.privSuccessCallback = undefined;\n                /* eslint-disable no-empty */\n            }\n            catch (_b) { }\n        }\n    }\n}\n\n//# sourceMappingURL=IntentServiceRecognizer.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IntentServiceRecognizer.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/QueryParameterNames.js":
  /*!*********************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/QueryParameterNames.js ***!
    \*********************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"QueryParameterNames\": () => (/* binding */ QueryParameterNames)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nclass QueryParameterNames {\n}\nQueryParameterNames.BotId = \"botid\";\nQueryParameterNames.CustomSpeechDeploymentId = \"cid\";\nQueryParameterNames.CustomVoiceDeploymentId = \"deploymentId\";\nQueryParameterNames.EnableAudioLogging = \"storeAudio\";\nQueryParameterNames.EnableLanguageId = \"lidEnabled\";\nQueryParameterNames.EnableWordLevelTimestamps = \"wordLevelTimestamps\";\nQueryParameterNames.EndSilenceTimeoutMs = \"endSilenceTimeoutMs\";\nQueryParameterNames.SegmentationSilenceTimeoutMs = \"segmentationSilenceTimeoutMs\";\nQueryParameterNames.Format = \"format\";\nQueryParameterNames.InitialSilenceTimeoutMs = \"initialSilenceTimeoutMs\";\nQueryParameterNames.Language = \"language\";\nQueryParameterNames.Profanity = \"profanity\";\nQueryParameterNames.RequestBotStatusMessages = \"enableBotMessageStatus\";\nQueryParameterNames.StableIntermediateThreshold = \"stableIntermediateThreshold\";\nQueryParameterNames.StableTranslation = \"stableTranslation\";\nQueryParameterNames.TestHooks = \"testhooks\";\nQueryParameterNames.Postprocessing = \"postprocessing\";\nQueryParameterNames.CtsMeetingId = \"meetingId\";\nQueryParameterNames.CtsDeviceId = \"deviceId\";\nQueryParameterNames.CtsIsParticipant = \"isParticipant\";\n\n//# sourceMappingURL=QueryParameterNames.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/QueryParameterNames.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognitionEvents.js":
  /*!*******************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognitionEvents.js ***!
    \*******************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConnectingToServiceEvent\": () => (/* binding */ ConnectingToServiceEvent),\n/* harmony export */   \"ListeningStartedEvent\": () => (/* binding */ ListeningStartedEvent),\n/* harmony export */   \"RecognitionCompletionStatus\": () => (/* binding */ RecognitionCompletionStatus),\n/* harmony export */   \"RecognitionEndedEvent\": () => (/* binding */ RecognitionEndedEvent),\n/* harmony export */   \"RecognitionStartedEvent\": () => (/* binding */ RecognitionStartedEvent),\n/* harmony export */   \"RecognitionTriggeredEvent\": () => (/* binding */ RecognitionTriggeredEvent),\n/* harmony export */   \"SpeechRecognitionEvent\": () => (/* binding */ SpeechRecognitionEvent)\n/* harmony export */ });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/PlatformEvent.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/* eslint-disable max-classes-per-file */\n\nclass SpeechRecognitionEvent extends _common_Exports__WEBPACK_IMPORTED_MODULE_0__.PlatformEvent {\n    constructor(eventName, requestId, sessionId, eventType = _common_Exports__WEBPACK_IMPORTED_MODULE_0__.EventType.Info) {\n        super(eventName, eventType);\n        this.privRequestId = requestId;\n        this.privSessionId = sessionId;\n    }\n    get requestId() {\n        return this.privRequestId;\n    }\n    get sessionId() {\n        return this.privSessionId;\n    }\n}\nclass RecognitionTriggeredEvent extends SpeechRecognitionEvent {\n    constructor(requestId, sessionId, audioSourceId, audioNodeId) {\n        super(\"RecognitionTriggeredEvent\", requestId, sessionId);\n        this.privAudioSourceId = audioSourceId;\n        this.privAudioNodeId = audioNodeId;\n    }\n    get audioSourceId() {\n        return this.privAudioSourceId;\n    }\n    get audioNodeId() {\n        return this.privAudioNodeId;\n    }\n}\nclass ListeningStartedEvent extends SpeechRecognitionEvent {\n    constructor(requestId, sessionId, audioSourceId, audioNodeId) {\n        super(\"ListeningStartedEvent\", requestId, sessionId);\n        this.privAudioSourceId = audioSourceId;\n        this.privAudioNodeId = audioNodeId;\n    }\n    get audioSourceId() {\n        return this.privAudioSourceId;\n    }\n    get audioNodeId() {\n        return this.privAudioNodeId;\n    }\n}\nclass ConnectingToServiceEvent extends SpeechRecognitionEvent {\n    constructor(requestId, authFetchEventid, sessionId) {\n        super(\"ConnectingToServiceEvent\", requestId, sessionId);\n        this.privAuthFetchEventid = authFetchEventid;\n    }\n    get authFetchEventid() {\n        return this.privAuthFetchEventid;\n    }\n}\nclass RecognitionStartedEvent extends SpeechRecognitionEvent {\n    constructor(requestId, audioSourceId, audioNodeId, authFetchEventId, sessionId) {\n        super(\"RecognitionStartedEvent\", requestId, sessionId);\n        this.privAudioSourceId = audioSourceId;\n        this.privAudioNodeId = audioNodeId;\n        this.privAuthFetchEventId = authFetchEventId;\n    }\n    get audioSourceId() {\n        return this.privAudioSourceId;\n    }\n    get audioNodeId() {\n        return this.privAudioNodeId;\n    }\n    get authFetchEventId() {\n        return this.privAuthFetchEventId;\n    }\n}\nvar RecognitionCompletionStatus;\n(function (RecognitionCompletionStatus) {\n    RecognitionCompletionStatus[RecognitionCompletionStatus[\"Success\"] = 0] = \"Success\";\n    RecognitionCompletionStatus[RecognitionCompletionStatus[\"AudioSourceError\"] = 1] = \"AudioSourceError\";\n    RecognitionCompletionStatus[RecognitionCompletionStatus[\"AudioSourceTimeout\"] = 2] = \"AudioSourceTimeout\";\n    RecognitionCompletionStatus[RecognitionCompletionStatus[\"AuthTokenFetchError\"] = 3] = \"AuthTokenFetchError\";\n    RecognitionCompletionStatus[RecognitionCompletionStatus[\"AuthTokenFetchTimeout\"] = 4] = \"AuthTokenFetchTimeout\";\n    RecognitionCompletionStatus[RecognitionCompletionStatus[\"UnAuthorized\"] = 5] = \"UnAuthorized\";\n    RecognitionCompletionStatus[RecognitionCompletionStatus[\"ConnectTimeout\"] = 6] = \"ConnectTimeout\";\n    RecognitionCompletionStatus[RecognitionCompletionStatus[\"ConnectError\"] = 7] = \"ConnectError\";\n    RecognitionCompletionStatus[RecognitionCompletionStatus[\"ClientRecognitionActivityTimeout\"] = 8] = \"ClientRecognitionActivityTimeout\";\n    RecognitionCompletionStatus[RecognitionCompletionStatus[\"UnknownError\"] = 9] = \"UnknownError\";\n})(RecognitionCompletionStatus || (RecognitionCompletionStatus = {}));\nclass RecognitionEndedEvent extends SpeechRecognitionEvent {\n    constructor(requestId, audioSourceId, audioNodeId, authFetchEventId, sessionId, serviceTag, status, error) {\n        super(\"RecognitionEndedEvent\", requestId, sessionId, status === RecognitionCompletionStatus.Success ? _common_Exports__WEBPACK_IMPORTED_MODULE_0__.EventType.Info : _common_Exports__WEBPACK_IMPORTED_MODULE_0__.EventType.Error);\n        this.privAudioSourceId = audioSourceId;\n        this.privAudioNodeId = audioNodeId;\n        this.privAuthFetchEventId = authFetchEventId;\n        this.privStatus = status;\n        this.privError = error;\n        this.privServiceTag = serviceTag;\n    }\n    get audioSourceId() {\n        return this.privAudioSourceId;\n    }\n    get audioNodeId() {\n        return this.privAudioNodeId;\n    }\n    get authFetchEventId() {\n        return this.privAuthFetchEventId;\n    }\n    get serviceTag() {\n        return this.privServiceTag;\n    }\n    get status() {\n        return this.privStatus;\n    }\n    get error() {\n        return this.privError;\n    }\n}\n\n//# sourceMappingURL=RecognitionEvents.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognitionEvents.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js":
  /*!******************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js ***!
    \******************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Context\": () => (/* binding */ Context),\n/* harmony export */   \"Device\": () => (/* binding */ Device),\n/* harmony export */   \"OS\": () => (/* binding */ OS),\n/* harmony export */   \"RecognitionMode\": () => (/* binding */ RecognitionMode),\n/* harmony export */   \"RecognizerConfig\": () => (/* binding */ RecognizerConfig),\n/* harmony export */   \"SpeechResultFormat\": () => (/* binding */ SpeechResultFormat),\n/* harmony export */   \"SpeechServiceConfig\": () => (/* binding */ SpeechServiceConfig),\n/* harmony export */   \"System\": () => (/* binding */ System),\n/* harmony export */   \"connectivity\": () => (/* binding */ connectivity),\n/* harmony export */   \"type\": () => (/* binding */ type)\n/* harmony export */ });\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/* eslint-disable max-classes-per-file */\n\nvar RecognitionMode;\n(function (RecognitionMode) {\n    RecognitionMode[RecognitionMode[\"Interactive\"] = 0] = \"Interactive\";\n    RecognitionMode[RecognitionMode[\"Conversation\"] = 1] = \"Conversation\";\n    RecognitionMode[RecognitionMode[\"Dictation\"] = 2] = \"Dictation\";\n})(RecognitionMode || (RecognitionMode = {}));\nvar SpeechResultFormat;\n(function (SpeechResultFormat) {\n    SpeechResultFormat[SpeechResultFormat[\"Simple\"] = 0] = \"Simple\";\n    SpeechResultFormat[SpeechResultFormat[\"Detailed\"] = 1] = \"Detailed\";\n})(SpeechResultFormat || (SpeechResultFormat = {}));\nclass RecognizerConfig {\n    constructor(speechServiceConfig, parameters) {\n        this.privSpeechServiceConfig = speechServiceConfig ? speechServiceConfig : new SpeechServiceConfig(new Context(null));\n        this.privParameters = parameters;\n        this.privMaxRetryCount = parseInt(parameters.getProperty(\"SPEECH-Error-MaxRetryCount\", \"4\"), 10);\n        this.privLanguageIdMode = parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_LanguageIdMode, undefined);\n    }\n    get parameters() {\n        return this.privParameters;\n    }\n    get recognitionMode() {\n        return this.privRecognitionMode;\n    }\n    set recognitionMode(value) {\n        this.privRecognitionMode = value;\n        this.privRecognitionActivityTimeout = value === RecognitionMode.Interactive ? 8000 : 25000;\n        this.privSpeechServiceConfig.Recognition = RecognitionMode[value];\n    }\n    get SpeechServiceConfig() {\n        return this.privSpeechServiceConfig;\n    }\n    get recognitionActivityTimeout() {\n        return this.privRecognitionActivityTimeout;\n    }\n    get isContinuousRecognition() {\n        return this.privRecognitionMode !== RecognitionMode.Interactive;\n    }\n    get languageIdMode() {\n        return this.privLanguageIdMode;\n    }\n    get autoDetectSourceLanguages() {\n        return this.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages, undefined);\n    }\n    get recognitionEndpointVersion() {\n        return this.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_RecognitionEndpointVersion, undefined);\n    }\n    get sourceLanguageModels() {\n        const models = [];\n        let modelsExist = false;\n        if (this.autoDetectSourceLanguages !== undefined) {\n            for (const language of this.autoDetectSourceLanguages.split(\",\")) {\n                const customProperty = language + _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_EndpointId.toString();\n                const modelId = this.parameters.getProperty(customProperty, undefined);\n                if (modelId !== undefined) {\n                    models.push({ language, endpoint: modelId });\n                    modelsExist = true;\n                }\n                else {\n                    models.push({ language, endpoint: \"\" });\n                }\n            }\n        }\n        return modelsExist ? models : undefined;\n    }\n    get maxRetryCount() {\n        return this.privMaxRetryCount;\n    }\n}\n// The config is serialized and sent as the Speech.Config\nclass SpeechServiceConfig {\n    constructor(context) {\n        this.context = context;\n    }\n    serialize() {\n        return JSON.stringify(this, (key, value) => {\n            if (value && typeof value === \"object\") {\n                const replacement = {};\n                for (const k in value) {\n                    if (Object.hasOwnProperty.call(value, k)) {\n                        // eslint-disable-next-line @typescript-eslint/no-unsafe-assignment\n                        replacement[k && k.charAt(0).toLowerCase() + k.substring(1)] = value[k];\n                    }\n                }\n                return replacement;\n            }\n            return value;\n        });\n    }\n    get Context() {\n        return this.context;\n    }\n    get Recognition() {\n        return this.recognition;\n    }\n    set Recognition(value) {\n        this.recognition = value.toLowerCase();\n    }\n}\nclass Context {\n    constructor(os) {\n        this.system = new System();\n        this.os = os;\n    }\n}\nclass System {\n    constructor() {\n        // Note: below will be patched for official builds.\n        const SPEECHSDK_CLIENTSDK_VERSION = \"1.25.1\";\n        this.name = \"SpeechSDK\";\n        this.version = SPEECHSDK_CLIENTSDK_VERSION;\n        this.build = \"JavaScript\";\n        this.lang = \"JavaScript\";\n    }\n}\nclass OS {\n    constructor(platform, name, version) {\n        this.platform = platform;\n        this.name = name;\n        this.version = version;\n    }\n}\nclass Device {\n    constructor(manufacturer, model, version) {\n        this.manufacturer = manufacturer;\n        this.model = model;\n        this.version = version;\n    }\n}\nvar connectivity;\n(function (connectivity) {\n    connectivity[\"Bluetooth\"] = \"Bluetooth\";\n    connectivity[\"Wired\"] = \"Wired\";\n    connectivity[\"WiFi\"] = \"WiFi\";\n    connectivity[\"Cellular\"] = \"Cellular\";\n    connectivity[\"InBuilt\"] = \"InBuilt\";\n    connectivity[\"Unknown\"] = \"Unknown\";\n})(connectivity || (connectivity = {}));\nvar type;\n(function (type) {\n    type[\"Phone\"] = \"Phone\";\n    type[\"Speaker\"] = \"Speaker\";\n    type[\"Car\"] = \"Car\";\n    type[\"Headset\"] = \"Headset\";\n    type[\"Thermostat\"] = \"Thermostat\";\n    type[\"Microphones\"] = \"Microphones\";\n    type[\"Deskphone\"] = \"Deskphone\";\n    type[\"RemoteControl\"] = \"RemoteControl\";\n    type[\"Unknown\"] = \"Unknown\";\n    type[\"File\"] = \"File\";\n    type[\"Stream\"] = \"Stream\";\n})(type || (type = {}));\n\n//# sourceMappingURL=RecognizerConfig.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RequestSession.js":
  /*!****************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RequestSession.js ***!
    \****************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"RequestSession\": () => (/* binding */ RequestSession)\n/* harmony export */ });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Events.js\");\n/* harmony import */ var _RecognitionEvents__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./RecognitionEvents */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognitionEvents.js\");\n/* harmony import */ var _ServiceTelemetryListener_Internal__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ServiceTelemetryListener.Internal */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceTelemetryListener.Internal.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\nclass RequestSession {\n    constructor(audioSourceId) {\n        this.privIsDisposed = false;\n        this.privDetachables = new Array();\n        this.privIsAudioNodeDetached = false;\n        this.privIsRecognizing = false;\n        this.privIsSpeechEnded = false;\n        this.privTurnStartAudioOffset = 0;\n        this.privLastRecoOffset = 0;\n        this.privHypothesisReceived = false;\n        this.privBytesSent = 0;\n        this.privRecogNumber = 0;\n        this.privInTurn = false;\n        this.privConnectionAttempts = 0;\n        this.privAudioSourceId = audioSourceId;\n        this.privRequestId = (0,_common_Exports__WEBPACK_IMPORTED_MODULE_0__.createNoDashGuid)();\n        this.privAudioNodeId = (0,_common_Exports__WEBPACK_IMPORTED_MODULE_0__.createNoDashGuid)();\n        this.privTurnDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.Deferred();\n        // We're not in a turn, so resolve.\n        this.privTurnDeferral.resolve();\n    }\n    get sessionId() {\n        return this.privSessionId;\n    }\n    get requestId() {\n        return this.privRequestId;\n    }\n    get audioNodeId() {\n        return this.privAudioNodeId;\n    }\n    get turnCompletionPromise() {\n        return this.privTurnDeferral.promise;\n    }\n    get isSpeechEnded() {\n        return this.privIsSpeechEnded;\n    }\n    get isRecognizing() {\n        return this.privIsRecognizing;\n    }\n    get currentTurnAudioOffset() {\n        return this.privTurnStartAudioOffset;\n    }\n    get recogNumber() {\n        return this.privRecogNumber;\n    }\n    get numConnectionAttempts() {\n        return this.privConnectionAttempts;\n    }\n    // The number of bytes sent for the current connection.\n    // Counter is reset to 0 each time a connection is established.\n    get bytesSent() {\n        return this.privBytesSent;\n    }\n    listenForServiceTelemetry(eventSource) {\n        if (!!this.privServiceTelemetryListener) {\n            this.privDetachables.push(eventSource.attachListener(this.privServiceTelemetryListener));\n        }\n    }\n    startNewRecognition() {\n        this.privIsSpeechEnded = false;\n        this.privIsRecognizing = true;\n        this.privTurnStartAudioOffset = 0;\n        this.privLastRecoOffset = 0;\n        this.privRecogNumber++;\n        this.privServiceTelemetryListener = new _ServiceTelemetryListener_Internal__WEBPACK_IMPORTED_MODULE_2__.ServiceTelemetryListener(this.privRequestId, this.privAudioSourceId, this.privAudioNodeId);\n        this.onEvent(new _RecognitionEvents__WEBPACK_IMPORTED_MODULE_3__.RecognitionTriggeredEvent(this.requestId, this.privSessionId, this.privAudioSourceId, this.privAudioNodeId));\n    }\n    onAudioSourceAttachCompleted(audioNode, isError) {\n        return __awaiter(this, void 0, void 0, function* () {\n            this.privAudioNode = audioNode;\n            this.privIsAudioNodeDetached = false;\n            if (isError) {\n                yield this.onComplete();\n            }\n            else {\n                this.onEvent(new _RecognitionEvents__WEBPACK_IMPORTED_MODULE_3__.ListeningStartedEvent(this.privRequestId, this.privSessionId, this.privAudioSourceId, this.privAudioNodeId));\n            }\n        });\n    }\n    onPreConnectionStart(authFetchEventId, connectionId) {\n        this.privAuthFetchEventId = authFetchEventId;\n        this.privSessionId = connectionId;\n        this.onEvent(new _RecognitionEvents__WEBPACK_IMPORTED_MODULE_3__.ConnectingToServiceEvent(this.privRequestId, this.privAuthFetchEventId, this.privSessionId));\n    }\n    onAuthCompleted(isError) {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (isError) {\n                yield this.onComplete();\n            }\n        });\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    onConnectionEstablishCompleted(statusCode, reason) {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (statusCode === 200) {\n                this.onEvent(new _RecognitionEvents__WEBPACK_IMPORTED_MODULE_3__.RecognitionStartedEvent(this.requestId, this.privAudioSourceId, this.privAudioNodeId, this.privAuthFetchEventId, this.privSessionId));\n                if (!!this.privAudioNode) {\n                    this.privAudioNode.replay();\n                }\n                this.privTurnStartAudioOffset = this.privLastRecoOffset;\n                this.privBytesSent = 0;\n                return;\n            }\n            else if (statusCode === 403) {\n                yield this.onComplete();\n            }\n        });\n    }\n    onServiceTurnEndResponse(continuousRecognition) {\n        return __awaiter(this, void 0, void 0, function* () {\n            this.privTurnDeferral.resolve();\n            if (!continuousRecognition || this.isSpeechEnded) {\n                yield this.onComplete();\n                this.privInTurn = false;\n            }\n            else {\n                // Start a new request set.\n                this.privTurnStartAudioOffset = this.privLastRecoOffset;\n                this.privAudioNode.replay();\n            }\n        });\n    }\n    onSpeechContext() {\n        this.privRequestId = (0,_common_Exports__WEBPACK_IMPORTED_MODULE_0__.createNoDashGuid)();\n    }\n    onServiceTurnStartResponse() {\n        if (!!this.privTurnDeferral && !!this.privInTurn) {\n            // What? How are we starting a turn with another not done?\n            this.privTurnDeferral.reject(\"Another turn started before current completed.\");\n            // Avoid UnhandledPromiseRejection if privTurnDeferral is not being awaited\n            // eslint-disable-next-line @typescript-eslint/no-empty-function\n            this.privTurnDeferral.promise.then().catch(() => { });\n        }\n        this.privInTurn = true;\n        this.privTurnDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.Deferred();\n    }\n    onHypothesis(offset) {\n        if (!this.privHypothesisReceived) {\n            this.privHypothesisReceived = true;\n            this.privServiceTelemetryListener.hypothesisReceived(this.privAudioNode.findTimeAtOffset(offset));\n        }\n    }\n    onPhraseRecognized(offset) {\n        this.privServiceTelemetryListener.phraseReceived(this.privAudioNode.findTimeAtOffset(offset));\n        this.onServiceRecognized(offset);\n    }\n    onServiceRecognized(offset) {\n        this.privLastRecoOffset = offset;\n        this.privHypothesisReceived = false;\n        this.privAudioNode.shrinkBuffers(offset);\n        this.privConnectionAttempts = 0;\n    }\n    onAudioSent(bytesSent) {\n        this.privBytesSent += bytesSent;\n    }\n    onRetryConnection() {\n        this.privConnectionAttempts++;\n    }\n    dispose() {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (!this.privIsDisposed) {\n                // we should have completed by now. If we did not its an unknown error.\n                this.privIsDisposed = true;\n                for (const detachable of this.privDetachables) {\n                    yield detachable.detach();\n                }\n                if (!!this.privServiceTelemetryListener) {\n                    this.privServiceTelemetryListener.dispose();\n                }\n                this.privIsRecognizing = false;\n            }\n        });\n    }\n    getTelemetry() {\n        if (this.privServiceTelemetryListener.hasTelemetry) {\n            return this.privServiceTelemetryListener.getTelemetry();\n        }\n        else {\n            return null;\n        }\n    }\n    onStopRecognizing() {\n        return __awaiter(this, void 0, void 0, function* () {\n            yield this.onComplete();\n        });\n    }\n    // Should be called with the audioNode for this session has indicated that it is out of speech.\n    onSpeechEnded() {\n        this.privIsSpeechEnded = true;\n    }\n    onEvent(event) {\n        if (!!this.privServiceTelemetryListener) {\n            this.privServiceTelemetryListener.onEvent(event);\n        }\n        _common_Exports__WEBPACK_IMPORTED_MODULE_4__.Events.instance.onEvent(event);\n    }\n    onComplete() {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (!!this.privIsRecognizing) {\n                this.privIsRecognizing = false;\n                yield this.detachAudioNode();\n            }\n        });\n    }\n    detachAudioNode() {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (!this.privIsAudioNodeDetached) {\n                this.privIsAudioNodeDetached = true;\n                if (this.privAudioNode) {\n                    yield this.privAudioNode.detach();\n                }\n            }\n        });\n    }\n}\n\n//# sourceMappingURL=RequestSession.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RequestSession.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/ActivityResponsePayload.js":
  /*!*****************************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/ActivityResponsePayload.js ***!
    \*****************************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ActivityPayloadResponse\": () => (/* binding */ ActivityPayloadResponse),\n/* harmony export */   \"MessageDataStreamType\": () => (/* binding */ MessageDataStreamType)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n// response\nclass ActivityPayloadResponse {\n    constructor(json) {\n        this.privActivityResponse = JSON.parse(json);\n    }\n    static fromJSON(json) {\n        return new ActivityPayloadResponse(json);\n    }\n    get conversationId() {\n        return this.privActivityResponse.conversationId;\n    }\n    get messageDataStreamType() {\n        return this.privActivityResponse.messageDataStreamType;\n    }\n    get messagePayload() {\n        return this.privActivityResponse.messagePayload;\n    }\n    get version() {\n        return this.privActivityResponse.version;\n    }\n}\nvar MessageDataStreamType;\n(function (MessageDataStreamType) {\n    MessageDataStreamType[MessageDataStreamType[\"None\"] = 0] = \"None\";\n    MessageDataStreamType[MessageDataStreamType[\"TextToSpeechAudio\"] = 1] = \"TextToSpeechAudio\";\n})(MessageDataStreamType || (MessageDataStreamType = {}));\n\n//# sourceMappingURL=ActivityResponsePayload.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/ActivityResponsePayload.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/DetailedSpeechPhrase.js":
  /*!**************************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/DetailedSpeechPhrase.js ***!
    \**************************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"DetailedSpeechPhrase\": () => (/* binding */ DetailedSpeechPhrase)\n/* harmony export */ });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/Enums.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nclass DetailedSpeechPhrase {\n    constructor(json) {\n        this.privDetailedSpeechPhrase = JSON.parse(json);\n        this.privDetailedSpeechPhrase.RecognitionStatus = _Exports__WEBPACK_IMPORTED_MODULE_0__.RecognitionStatus[this.privDetailedSpeechPhrase.RecognitionStatus];\n    }\n    static fromJSON(json) {\n        return new DetailedSpeechPhrase(json);\n    }\n    getJsonWithCorrectedOffsets(baseOffset) {\n        if (!!this.privDetailedSpeechPhrase.NBest) {\n            let firstWordOffset;\n            for (const phrase of this.privDetailedSpeechPhrase.NBest) {\n                if (!!phrase.Words && !!phrase.Words[0]) {\n                    firstWordOffset = phrase.Words[0].Offset;\n                    break;\n                }\n            }\n            if (!!firstWordOffset && firstWordOffset < baseOffset) {\n                const offset = baseOffset - firstWordOffset;\n                for (const details of this.privDetailedSpeechPhrase.NBest) {\n                    if (!!details.Words) {\n                        for (const word of details.Words) {\n                            word.Offset += offset;\n                        }\n                    }\n                }\n            }\n        }\n        return JSON.stringify(this.privDetailedSpeechPhrase);\n    }\n    get RecognitionStatus() {\n        return this.privDetailedSpeechPhrase.RecognitionStatus;\n    }\n    get NBest() {\n        return this.privDetailedSpeechPhrase.NBest;\n    }\n    get Duration() {\n        return this.privDetailedSpeechPhrase.Duration;\n    }\n    get Offset() {\n        return this.privDetailedSpeechPhrase.Offset;\n    }\n    get Language() {\n        return this.privDetailedSpeechPhrase.PrimaryLanguage === undefined ? undefined : this.privDetailedSpeechPhrase.PrimaryLanguage.Language;\n    }\n    get LanguageDetectionConfidence() {\n        return this.privDetailedSpeechPhrase.PrimaryLanguage === undefined ? undefined : this.privDetailedSpeechPhrase.PrimaryLanguage.Confidence;\n    }\n    get Text() {\n        if (!!this.privDetailedSpeechPhrase.NBest && this.privDetailedSpeechPhrase.NBest[0]) {\n            return this.privDetailedSpeechPhrase.NBest[0].Display || this.privDetailedSpeechPhrase.NBest[0].DisplayText;\n        }\n        return this.privDetailedSpeechPhrase.DisplayText;\n    }\n    get SpeakerId() {\n        return this.privDetailedSpeechPhrase.SpeakerId;\n    }\n}\n\n//# sourceMappingURL=DetailedSpeechPhrase.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/DetailedSpeechPhrase.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/Enums.js":
  /*!***********************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/Enums.js ***!
    \***********************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"RecognitionStatus\": () => (/* binding */ RecognitionStatus),\n/* harmony export */   \"SynthesisStatus\": () => (/* binding */ SynthesisStatus)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * @class SynthesisStatus\n * @private\n */\nvar SynthesisStatus;\n(function (SynthesisStatus) {\n    /**\n     * The response contains valid audio data.\n     * @member SynthesisStatus.Success\n     */\n    SynthesisStatus[SynthesisStatus[\"Success\"] = 0] = \"Success\";\n    /**\n     * Indicates the end of audio data. No valid audio data is included in the message.\n     * @member SynthesisStatus.SynthesisEnd\n     */\n    SynthesisStatus[SynthesisStatus[\"SynthesisEnd\"] = 1] = \"SynthesisEnd\";\n    /**\n     * Indicates an error occurred during synthesis data processing.\n     * @member SynthesisStatus.Error\n     */\n    SynthesisStatus[SynthesisStatus[\"Error\"] = 2] = \"Error\";\n})(SynthesisStatus || (SynthesisStatus = {}));\nvar RecognitionStatus;\n(function (RecognitionStatus) {\n    RecognitionStatus[RecognitionStatus[\"Success\"] = 0] = \"Success\";\n    RecognitionStatus[RecognitionStatus[\"NoMatch\"] = 1] = \"NoMatch\";\n    RecognitionStatus[RecognitionStatus[\"InitialSilenceTimeout\"] = 2] = \"InitialSilenceTimeout\";\n    RecognitionStatus[RecognitionStatus[\"BabbleTimeout\"] = 3] = \"BabbleTimeout\";\n    RecognitionStatus[RecognitionStatus[\"Error\"] = 4] = \"Error\";\n    RecognitionStatus[RecognitionStatus[\"EndOfDictation\"] = 5] = \"EndOfDictation\";\n    RecognitionStatus[RecognitionStatus[\"TooManyRequests\"] = 6] = \"TooManyRequests\";\n    RecognitionStatus[RecognitionStatus[\"BadRequest\"] = 7] = \"BadRequest\";\n    RecognitionStatus[RecognitionStatus[\"Forbidden\"] = 8] = \"Forbidden\";\n})(RecognitionStatus || (RecognitionStatus = {}));\n\n//# sourceMappingURL=Enums.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/Enums.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/IntentResponse.js":
  /*!********************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/IntentResponse.js ***!
    \********************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"IntentResponse\": () => (/* binding */ IntentResponse)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n// response\nclass IntentResponse {\n    constructor(json) {\n        if (json === \"\") {\n            this.privIntentResponse = {};\n        }\n        else {\n            this.privIntentResponse = JSON.parse(json);\n        }\n    }\n    static fromJSON(json) {\n        return new IntentResponse(json);\n    }\n    get query() {\n        return this.privIntentResponse.query;\n    }\n    get topScoringIntent() {\n        return this.privIntentResponse.topScoringIntent;\n    }\n    get entities() {\n        return this.privIntentResponse.entities;\n    }\n}\n\n//# sourceMappingURL=IntentResponse.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/IntentResponse.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SimpleSpeechPhrase.js":
  /*!************************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SimpleSpeechPhrase.js ***!
    \************************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SimpleSpeechPhrase\": () => (/* binding */ SimpleSpeechPhrase)\n/* harmony export */ });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/Enums.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nclass SimpleSpeechPhrase {\n    constructor(json) {\n        this.privSimpleSpeechPhrase = JSON.parse(json);\n        this.privSimpleSpeechPhrase.RecognitionStatus = _Exports__WEBPACK_IMPORTED_MODULE_0__.RecognitionStatus[this.privSimpleSpeechPhrase.RecognitionStatus];\n    }\n    static fromJSON(json) {\n        return new SimpleSpeechPhrase(json);\n    }\n    get RecognitionStatus() {\n        return this.privSimpleSpeechPhrase.RecognitionStatus;\n    }\n    get DisplayText() {\n        return this.privSimpleSpeechPhrase.DisplayText;\n    }\n    get Offset() {\n        return this.privSimpleSpeechPhrase.Offset;\n    }\n    get Duration() {\n        return this.privSimpleSpeechPhrase.Duration;\n    }\n    get Language() {\n        return this.privSimpleSpeechPhrase.PrimaryLanguage === undefined ? undefined : this.privSimpleSpeechPhrase.PrimaryLanguage.Language;\n    }\n    get LanguageDetectionConfidence() {\n        return this.privSimpleSpeechPhrase.PrimaryLanguage === undefined ? undefined : this.privSimpleSpeechPhrase.PrimaryLanguage.Confidence;\n    }\n    get SpeakerId() {\n        return this.privSimpleSpeechPhrase.SpeakerId;\n    }\n}\n\n//# sourceMappingURL=SimpleSpeechPhrase.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SimpleSpeechPhrase.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechDetected.js":
  /*!********************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechDetected.js ***!
    \********************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SpeechDetected\": () => (/* binding */ SpeechDetected)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nclass SpeechDetected {\n    constructor(json) {\n        this.privSpeechStartDetected = JSON.parse(json);\n    }\n    static fromJSON(json) {\n        return new SpeechDetected(json);\n    }\n    get Offset() {\n        return this.privSpeechStartDetected.Offset;\n    }\n}\n\n//# sourceMappingURL=SpeechDetected.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechDetected.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechHypothesis.js":
  /*!**********************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechHypothesis.js ***!
    \**********************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SpeechHypothesis\": () => (/* binding */ SpeechHypothesis)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nclass SpeechHypothesis {\n    constructor(json) {\n        this.privSpeechHypothesis = JSON.parse(json);\n    }\n    static fromJSON(json) {\n        return new SpeechHypothesis(json);\n    }\n    get Text() {\n        return this.privSpeechHypothesis.Text;\n    }\n    get Offset() {\n        return this.privSpeechHypothesis.Offset;\n    }\n    get Duration() {\n        return this.privSpeechHypothesis.Duration;\n    }\n    get Language() {\n        return this.privSpeechHypothesis.PrimaryLanguage === undefined ? undefined : this.privSpeechHypothesis.PrimaryLanguage.Language;\n    }\n    get LanguageDetectionConfidence() {\n        return this.privSpeechHypothesis.PrimaryLanguage === undefined ? undefined : this.privSpeechHypothesis.PrimaryLanguage.Confidence;\n    }\n    get SpeakerId() {\n        return this.privSpeechHypothesis.SpeakerId;\n    }\n}\n\n//# sourceMappingURL=SpeechHypothesis.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechHypothesis.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechKeyword.js":
  /*!*******************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechKeyword.js ***!
    \*******************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SpeechKeyword\": () => (/* binding */ SpeechKeyword)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nclass SpeechKeyword {\n    constructor(json) {\n        this.privSpeechKeyword = JSON.parse(json);\n    }\n    static fromJSON(json) {\n        return new SpeechKeyword(json);\n    }\n    get Status() {\n        return this.privSpeechKeyword.Status;\n    }\n    get Text() {\n        return this.privSpeechKeyword.Text;\n    }\n    get Offset() {\n        return this.privSpeechKeyword.Offset;\n    }\n    get Duration() {\n        return this.privSpeechKeyword.Duration;\n    }\n}\n\n//# sourceMappingURL=SpeechKeyword.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechKeyword.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SynthesisAudioMetadata.js":
  /*!****************************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SynthesisAudioMetadata.js ***!
    \****************************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"MetadataType\": () => (/* binding */ MetadataType),\n/* harmony export */   \"SynthesisAudioMetadata\": () => (/* binding */ SynthesisAudioMetadata)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar MetadataType;\n(function (MetadataType) {\n    MetadataType[\"WordBoundary\"] = \"WordBoundary\";\n    MetadataType[\"Bookmark\"] = \"Bookmark\";\n    MetadataType[\"Viseme\"] = \"Viseme\";\n    MetadataType[\"SentenceBoundary\"] = \"SentenceBoundary\";\n    MetadataType[\"SessionEnd\"] = \"SessionEnd\";\n})(MetadataType || (MetadataType = {}));\nclass SynthesisAudioMetadata {\n    constructor(json) {\n        this.privSynthesisAudioMetadata = JSON.parse(json);\n    }\n    static fromJSON(json) {\n        return new SynthesisAudioMetadata(json);\n    }\n    get Metadata() {\n        return this.privSynthesisAudioMetadata.Metadata;\n    }\n}\n\n//# sourceMappingURL=SynthesisAudioMetadata.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SynthesisAudioMetadata.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationHypothesis.js":
  /*!***************************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationHypothesis.js ***!
    \***************************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"TranslationHypothesis\": () => (/* binding */ TranslationHypothesis)\n/* harmony export */ });\n/* harmony import */ var _TranslationStatus__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../TranslationStatus */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationStatus.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nclass TranslationHypothesis {\n    constructor(json) {\n        this.privTranslationHypothesis = JSON.parse(json);\n        this.privTranslationHypothesis.Translation.TranslationStatus = _TranslationStatus__WEBPACK_IMPORTED_MODULE_0__.TranslationStatus[this.privTranslationHypothesis.Translation.TranslationStatus];\n    }\n    static fromJSON(json) {\n        return new TranslationHypothesis(json);\n    }\n    get Duration() {\n        return this.privTranslationHypothesis.Duration;\n    }\n    get Offset() {\n        return this.privTranslationHypothesis.Offset;\n    }\n    get Text() {\n        return this.privTranslationHypothesis.Text;\n    }\n    get Translation() {\n        return this.privTranslationHypothesis.Translation;\n    }\n}\n\n//# sourceMappingURL=TranslationHypothesis.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationHypothesis.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationPhrase.js":
  /*!***********************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationPhrase.js ***!
    \***********************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"TranslationPhrase\": () => (/* binding */ TranslationPhrase)\n/* harmony export */ });\n/* harmony import */ var _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../sdk/Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/Enums.js\");\n/* harmony import */ var _TranslationStatus__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../TranslationStatus */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationStatus.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\nclass TranslationPhrase {\n    constructor(phrase) {\n        this.privTranslationPhrase = phrase;\n        this.privTranslationPhrase.RecognitionStatus = _Exports__WEBPACK_IMPORTED_MODULE_0__.RecognitionStatus[this.privTranslationPhrase.RecognitionStatus];\n        if (this.privTranslationPhrase.Translation !== undefined) {\n            this.privTranslationPhrase.Translation.TranslationStatus = _TranslationStatus__WEBPACK_IMPORTED_MODULE_1__.TranslationStatus[this.privTranslationPhrase.Translation.TranslationStatus];\n        }\n    }\n    static fromJSON(json) {\n        return new TranslationPhrase(JSON.parse(json));\n    }\n    static fromTranslationResponse(translationResponse) {\n        _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__.Contracts.throwIfNullOrUndefined(translationResponse, \"translationResponse\");\n        const phrase = translationResponse.SpeechPhrase;\n        translationResponse.SpeechPhrase = undefined;\n        phrase.Translation = translationResponse;\n        phrase.Text = phrase.DisplayText;\n        return new TranslationPhrase(phrase);\n    }\n    get RecognitionStatus() {\n        return this.privTranslationPhrase.RecognitionStatus;\n    }\n    get Offset() {\n        return this.privTranslationPhrase.Offset;\n    }\n    get Duration() {\n        return this.privTranslationPhrase.Duration;\n    }\n    get Text() {\n        return this.privTranslationPhrase.Text;\n    }\n    get Translation() {\n        return this.privTranslationPhrase.Translation;\n    }\n}\n\n//# sourceMappingURL=TranslationPhrase.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationPhrase.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationSynthesisEnd.js":
  /*!*****************************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationSynthesisEnd.js ***!
    \*****************************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"TranslationSynthesisEnd\": () => (/* binding */ TranslationSynthesisEnd)\n/* harmony export */ });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/Enums.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nclass TranslationSynthesisEnd {\n    constructor(json) {\n        this.privSynthesisEnd = JSON.parse(json);\n        this.privSynthesisEnd.SynthesisStatus = _Exports__WEBPACK_IMPORTED_MODULE_0__.SynthesisStatus[this.privSynthesisEnd.SynthesisStatus];\n    }\n    static fromJSON(json) {\n        return new TranslationSynthesisEnd(json);\n    }\n    get SynthesisStatus() {\n        return this.privSynthesisEnd.SynthesisStatus;\n    }\n    get FailureReason() {\n        return this.privSynthesisEnd.FailureReason;\n    }\n}\n\n//# sourceMappingURL=TranslationSynthesisEnd.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationSynthesisEnd.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TurnStatusPayload.js":
  /*!***********************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TurnStatusPayload.js ***!
    \***********************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"TurnStatusResponsePayload\": () => (/* binding */ TurnStatusResponsePayload)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nclass TurnStatusResponsePayload {\n    constructor(json) {\n        this.privMessageStatusResponse = JSON.parse(json);\n    }\n    static fromJSON(json) {\n        return new TurnStatusResponsePayload(json);\n    }\n    get interactionId() {\n        return this.privMessageStatusResponse.interactionId;\n    }\n    get conversationId() {\n        return this.privMessageStatusResponse.conversationId;\n    }\n    get statusCode() {\n        // Payloads may contain a limited set of textual representations or a numeric status\n        // code. The textual values are here converted into numeric ones.\n        switch (this.privMessageStatusResponse.statusCode) {\n            case \"Success\":\n                return 200;\n            case \"Failed\":\n                return 400;\n            case \"TimedOut\":\n                return 429;\n            default:\n                // eslint-disable-next-line @typescript-eslint/no-unsafe-return\n                return this.privMessageStatusResponse.statusCode;\n        }\n    }\n}\n\n//# sourceMappingURL=TurnStatusPayload.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TurnStatusPayload.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceRecognizerBase.js":
  /*!***********************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceRecognizerBase.js ***!
    \***********************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ServiceRecognizerBase\": () => (/* binding */ ServiceRecognizerBase)\n/* harmony export */ });\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ReplayableAudioNode.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/EventSource.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Timeout.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionEvents.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_18__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IConnection.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_19__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationReason.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SessionEventArgs.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionEventArgs.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RequestSession.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DynamicGrammarBuilder.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechContext.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/AgentConfig.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechDetected.js\");\n/* harmony import */ var _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./SpeechConnectionMessage.Internal */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionMessage.Internal.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\n\n\nclass ServiceRecognizerBase {\n    constructor(authentication, connectionFactory, audioSource, recognizerConfig, recognizer) {\n        // A promise for a configured connection.\n        // Do not consume directly, call fetchConnection instead.\n        this.privConnectionConfigurationPromise = undefined;\n        // A promise for a connection, but one that has not had the speech context sent yet.\n        // Do not consume directly, call fetchConnection instead.\n        this.privConnectionPromise = undefined;\n        this.privSetTimeout = setTimeout;\n        this.privIsLiveAudio = false;\n        this.recognizeOverride = undefined;\n        this.disconnectOverride = undefined;\n        this.receiveMessageOverride = undefined;\n        this.sendPrePayloadJSONOverride = undefined;\n        this.postConnectImplOverride = undefined;\n        this.configConnectionOverride = undefined;\n        this.handleSpeechPhraseMessage = undefined;\n        this.handleSpeechHypothesisMessage = undefined;\n        if (!authentication) {\n            throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__.ArgumentNullError(\"authentication\");\n        }\n        if (!connectionFactory) {\n            throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__.ArgumentNullError(\"connectionFactory\");\n        }\n        if (!audioSource) {\n            throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__.ArgumentNullError(\"audioSource\");\n        }\n        if (!recognizerConfig) {\n            throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__.ArgumentNullError(\"recognizerConfig\");\n        }\n        this.privMustReportEndOfStream = false;\n        this.privAuthentication = authentication;\n        this.privConnectionFactory = connectionFactory;\n        this.privAudioSource = audioSource;\n        this.privRecognizerConfig = recognizerConfig;\n        this.privIsDisposed = false;\n        this.privRecognizer = recognizer;\n        this.privRequestSession = new _Exports__WEBPACK_IMPORTED_MODULE_1__.RequestSession(this.privAudioSource.id());\n        this.privConnectionEvents = new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.EventSource();\n        this.privServiceEvents = new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.EventSource();\n        this.privDynamicGrammar = new _Exports__WEBPACK_IMPORTED_MODULE_3__.DynamicGrammarBuilder();\n        this.privSpeechContext = new _Exports__WEBPACK_IMPORTED_MODULE_4__.SpeechContext(this.privDynamicGrammar);\n        this.privAgentConfig = new _Exports__WEBPACK_IMPORTED_MODULE_5__.AgentConfig();\n        if (typeof (Blob) !== \"undefined\" && typeof (Worker) !== \"undefined\") {\n            this.privSetTimeout = _common_Exports__WEBPACK_IMPORTED_MODULE_6__.Timeout.setTimeout;\n        }\n        this.connectionEvents.attach((connectionEvent) => {\n            if (connectionEvent.name === \"ConnectionClosedEvent\") {\n                const connectionClosedEvent = connectionEvent;\n                if (connectionClosedEvent.statusCode === 1003 ||\n                    connectionClosedEvent.statusCode === 1007 ||\n                    connectionClosedEvent.statusCode === 1002 ||\n                    connectionClosedEvent.statusCode === 4000 ||\n                    this.privRequestSession.numConnectionAttempts > this.privRecognizerConfig.maxRetryCount) {\n                    void this.cancelRecognitionLocal(_sdk_Exports__WEBPACK_IMPORTED_MODULE_7__.CancellationReason.Error, connectionClosedEvent.statusCode === 1007 ? _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__.CancellationErrorCode.BadRequestParameters : _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__.CancellationErrorCode.ConnectionFailure, `${connectionClosedEvent.reason} websocket error code: ${connectionClosedEvent.statusCode}`);\n                }\n            }\n        });\n    }\n    get audioSource() {\n        return this.privAudioSource;\n    }\n    get speechContext() {\n        return this.privSpeechContext;\n    }\n    get dynamicGrammar() {\n        return this.privDynamicGrammar;\n    }\n    get agentConfig() {\n        return this.privAgentConfig;\n    }\n    set conversationTranslatorToken(token) {\n        this.privRecognizerConfig.parameters.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.PropertyId.ConversationTranslator_Token, token);\n    }\n    set authentication(auth) {\n        this.privAuthentication = this.authentication;\n    }\n    isDisposed() {\n        return this.privIsDisposed;\n    }\n    dispose(reason) {\n        return __awaiter(this, void 0, void 0, function* () {\n            this.privIsDisposed = true;\n            if (this.privConnectionConfigurationPromise !== undefined) {\n                try {\n                    const connection = yield this.privConnectionConfigurationPromise;\n                    yield connection.dispose(reason);\n                }\n                catch (error) {\n                    // The connection is in a bad state. But we're trying to kill it, so...\n                    return;\n                }\n            }\n        });\n    }\n    get connectionEvents() {\n        return this.privConnectionEvents;\n    }\n    get serviceEvents() {\n        return this.privServiceEvents;\n    }\n    get recognitionMode() {\n        return this.privRecognizerConfig.recognitionMode;\n    }\n    recognize(recoMode, successCallback, errorCallBack) {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (this.recognizeOverride !== undefined) {\n                yield this.recognizeOverride(recoMode, successCallback, errorCallBack);\n                return;\n            }\n            // Clear the existing configuration promise to force a re-transmission of config and context.\n            this.privConnectionConfigurationPromise = undefined;\n            this.privRecognizerConfig.recognitionMode = recoMode;\n            this.privSuccessCallback = successCallback;\n            this.privErrorCallback = errorCallBack;\n            this.privRequestSession.startNewRecognition();\n            this.privRequestSession.listenForServiceTelemetry(this.privAudioSource.events);\n            // Start the connection to the service. The promise this will create is stored and will be used by configureConnection().\n            const conPromise = this.connectImpl();\n            let audioNode;\n            try {\n                const audioStreamNode = yield this.audioSource.attach(this.privRequestSession.audioNodeId);\n                const format = yield this.audioSource.format;\n                const deviceInfo = yield this.audioSource.deviceInfo;\n                this.privIsLiveAudio = deviceInfo.type && deviceInfo.type === _Exports__WEBPACK_IMPORTED_MODULE_10__.type.Microphones;\n                audioNode = new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_11__.ReplayableAudioNode(audioStreamNode, format.avgBytesPerSec);\n                yield this.privRequestSession.onAudioSourceAttachCompleted(audioNode, false);\n                this.privRecognizerConfig.SpeechServiceConfig.Context.audio = { source: deviceInfo };\n            }\n            catch (error) {\n                yield this.privRequestSession.onStopRecognizing();\n                throw error;\n            }\n            try {\n                yield conPromise;\n            }\n            catch (error) {\n                yield this.cancelRecognitionLocal(_sdk_Exports__WEBPACK_IMPORTED_MODULE_7__.CancellationReason.Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__.CancellationErrorCode.ConnectionFailure, error);\n                return;\n            }\n            const sessionStartEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_12__.SessionEventArgs(this.privRequestSession.sessionId);\n            if (!!this.privRecognizer.sessionStarted) {\n                this.privRecognizer.sessionStarted(this.privRecognizer, sessionStartEventArgs);\n            }\n            void this.receiveMessage();\n            const audioSendPromise = this.sendAudio(audioNode);\n            audioSendPromise.catch((error) => __awaiter(this, void 0, void 0, function* () {\n                yield this.cancelRecognitionLocal(_sdk_Exports__WEBPACK_IMPORTED_MODULE_7__.CancellationReason.Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__.CancellationErrorCode.RuntimeError, error);\n            }));\n            return;\n        });\n    }\n    stopRecognizing() {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (this.privRequestSession.isRecognizing) {\n                try {\n                    yield this.audioSource.turnOff();\n                    yield this.sendFinalAudio();\n                    yield this.privRequestSession.onStopRecognizing();\n                    yield this.privRequestSession.turnCompletionPromise;\n                }\n                finally {\n                    yield this.privRequestSession.dispose();\n                }\n            }\n            return;\n        });\n    }\n    connect() {\n        return __awaiter(this, void 0, void 0, function* () {\n            yield this.connectImpl();\n            return Promise.resolve();\n        });\n    }\n    connectAsync(cb, err) {\n        this.connectImpl().then(() => {\n            try {\n                if (!!cb) {\n                    cb();\n                }\n            }\n            catch (e) {\n                if (!!err) {\n                    err(e);\n                }\n            }\n        }, (reason) => {\n            try {\n                if (!!err) {\n                    err(reason);\n                }\n                /* eslint-disable no-empty */\n            }\n            catch (error) {\n            }\n        });\n    }\n    disconnect() {\n        return __awaiter(this, void 0, void 0, function* () {\n            yield this.cancelRecognitionLocal(_sdk_Exports__WEBPACK_IMPORTED_MODULE_7__.CancellationReason.Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__.CancellationErrorCode.NoError, \"Disconnecting\");\n            if (this.disconnectOverride !== undefined) {\n                yield this.disconnectOverride();\n            }\n            if (this.privConnectionPromise !== undefined) {\n                try {\n                    yield (yield this.privConnectionPromise).dispose();\n                }\n                catch (error) {\n                }\n            }\n            this.privConnectionPromise = undefined;\n        });\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    sendMessage(message) {\n        return;\n    }\n    sendNetworkMessage(path, payload) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const type = typeof payload === \"string\" ? _common_Exports__WEBPACK_IMPORTED_MODULE_13__.MessageType.Text : _common_Exports__WEBPACK_IMPORTED_MODULE_13__.MessageType.Binary;\n            const contentType = typeof payload === \"string\" ? \"application/json\" : \"\";\n            const connection = yield this.fetchConnection();\n            return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_14__.SpeechConnectionMessage(type, path, this.privRequestSession.requestId, contentType, payload));\n        });\n    }\n    set activityTemplate(messagePayload) {\n        this.privActivityTemplate = messagePayload;\n    }\n    get activityTemplate() {\n        return this.privActivityTemplate;\n    }\n    sendTelemetryData() {\n        return __awaiter(this, void 0, void 0, function* () {\n            const telemetryData = this.privRequestSession.getTelemetry();\n            if (ServiceRecognizerBase.telemetryDataEnabled !== true ||\n                this.privIsDisposed ||\n                null === telemetryData) {\n                return;\n            }\n            if (!!ServiceRecognizerBase.telemetryData) {\n                try {\n                    ServiceRecognizerBase.telemetryData(telemetryData);\n                    /* eslint-disable no-empty */\n                }\n                catch (_a) { }\n            }\n            const connection = yield this.fetchConnection();\n            yield connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_14__.SpeechConnectionMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_13__.MessageType.Text, \"telemetry\", this.privRequestSession.requestId, \"application/json\", telemetryData));\n        });\n    }\n    // Cancels recognition.\n    cancelRecognitionLocal(cancellationReason, errorCode, error) {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (!!this.privRequestSession.isRecognizing) {\n                yield this.privRequestSession.onStopRecognizing();\n                this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, cancellationReason, errorCode, error);\n            }\n        });\n    }\n    receiveMessage() {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                if (this.privIsDisposed) {\n                    // We're done.\n                    return;\n                }\n                let connection = yield this.fetchConnection();\n                const message = yield connection.read();\n                if (this.receiveMessageOverride !== undefined) {\n                    return this.receiveMessageOverride();\n                }\n                // indicates we are draining the queue and it came with no message;\n                if (!message) {\n                    if (!this.privRequestSession.isRecognizing) {\n                        return;\n                    }\n                    else {\n                        return this.receiveMessage();\n                    }\n                }\n                this.privServiceHasSentMessage = true;\n                const connectionMessage = _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_14__.SpeechConnectionMessage.fromConnectionMessage(message);\n                if (connectionMessage.requestId.toLowerCase() === this.privRequestSession.requestId.toLowerCase()) {\n                    switch (connectionMessage.path.toLowerCase()) {\n                        case \"turn.start\":\n                            this.privMustReportEndOfStream = true;\n                            this.privRequestSession.onServiceTurnStartResponse();\n                            break;\n                        case \"speech.startdetected\":\n                            const speechStartDetected = _Exports__WEBPACK_IMPORTED_MODULE_15__.SpeechDetected.fromJSON(connectionMessage.textBody);\n                            const speechStartEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_16__.RecognitionEventArgs(speechStartDetected.Offset, this.privRequestSession.sessionId);\n                            if (!!this.privRecognizer.speechStartDetected) {\n                                this.privRecognizer.speechStartDetected(this.privRecognizer, speechStartEventArgs);\n                            }\n                            break;\n                        case \"speech.enddetected\":\n                            let json;\n                            if (connectionMessage.textBody.length > 0) {\n                                json = connectionMessage.textBody;\n                            }\n                            else {\n                                // If the request was empty, the JSON returned is empty.\n                                json = \"{ Offset: 0 }\";\n                            }\n                            const speechStopDetected = _Exports__WEBPACK_IMPORTED_MODULE_15__.SpeechDetected.fromJSON(json);\n                            // Only shrink the buffers for continuous recognition.\n                            // For single shot, the speech.phrase message will come after the speech.end and it should own buffer shrink.\n                            if (this.privRecognizerConfig.isContinuousRecognition) {\n                                this.privRequestSession.onServiceRecognized(speechStopDetected.Offset + this.privRequestSession.currentTurnAudioOffset);\n                            }\n                            const speechStopEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_16__.RecognitionEventArgs(speechStopDetected.Offset + this.privRequestSession.currentTurnAudioOffset, this.privRequestSession.sessionId);\n                            if (!!this.privRecognizer.speechEndDetected) {\n                                this.privRecognizer.speechEndDetected(this.privRecognizer, speechStopEventArgs);\n                            }\n                            break;\n                        case \"turn.end\":\n                            yield this.sendTelemetryData();\n                            if (this.privRequestSession.isSpeechEnded && this.privMustReportEndOfStream) {\n                                this.privMustReportEndOfStream = false;\n                                yield this.cancelRecognitionLocal(_sdk_Exports__WEBPACK_IMPORTED_MODULE_7__.CancellationReason.EndOfStream, _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__.CancellationErrorCode.NoError, undefined);\n                            }\n                            const sessionStopEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_12__.SessionEventArgs(this.privRequestSession.sessionId);\n                            yield this.privRequestSession.onServiceTurnEndResponse(this.privRecognizerConfig.isContinuousRecognition);\n                            if (!this.privRecognizerConfig.isContinuousRecognition || this.privRequestSession.isSpeechEnded || !this.privRequestSession.isRecognizing) {\n                                if (!!this.privRecognizer.sessionStopped) {\n                                    this.privRecognizer.sessionStopped(this.privRecognizer, sessionStopEventArgs);\n                                }\n                                return;\n                            }\n                            else {\n                                connection = yield this.fetchConnection();\n                                yield this.sendPrePayloadJSON(connection);\n                            }\n                            break;\n                        default:\n                            if (!(yield this.processTypeSpecificMessages(connectionMessage))) {\n                                // here are some messages that the derived class has not processed, dispatch them to connect class\n                                if (!!this.privServiceEvents) {\n                                    this.serviceEvents.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_17__.ServiceEvent(connectionMessage.path.toLowerCase(), connectionMessage.textBody));\n                                }\n                            }\n                    }\n                }\n                return this.receiveMessage();\n            }\n            catch (error) {\n                return null;\n            }\n        });\n    }\n    sendSpeechContext(connection, generateNewRequestId) {\n        const speechContextJson = this.speechContext.toJSON();\n        if (generateNewRequestId) {\n            this.privRequestSession.onSpeechContext();\n        }\n        if (speechContextJson) {\n            return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_14__.SpeechConnectionMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_13__.MessageType.Text, \"speech.context\", this.privRequestSession.requestId, \"application/json\", speechContextJson));\n        }\n        return;\n    }\n    // Encapsulated for derived service recognizers that need to send additional JSON\n    sendPrePayloadJSON(connection, generateNewRequestId = true) {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (this.sendPrePayloadJSONOverride !== undefined) {\n                return this.sendPrePayloadJSONOverride(connection);\n            }\n            yield this.sendSpeechContext(connection, generateNewRequestId);\n            yield this.sendWaveHeader(connection);\n            return;\n        });\n    }\n    sendWaveHeader(connection) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const format = yield this.audioSource.format;\n            // this.writeBufferToConsole(format.header);\n            return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_14__.SpeechConnectionMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_13__.MessageType.Binary, \"audio\", this.privRequestSession.requestId, \"audio/x-wav\", format.header));\n        });\n    }\n    // Establishes a websocket connection to the end point.\n    connectImpl() {\n        if (this.privConnectionPromise !== undefined) {\n            return this.privConnectionPromise.then((connection) => {\n                if (connection.state() === _common_Exports__WEBPACK_IMPORTED_MODULE_18__.ConnectionState.Disconnected) {\n                    this.privConnectionId = null;\n                    this.privConnectionPromise = undefined;\n                    this.privServiceHasSentMessage = false;\n                    return this.connectImpl();\n                }\n                return this.privConnectionPromise;\n            }, () => {\n                this.privConnectionId = null;\n                this.privConnectionPromise = undefined;\n                this.privServiceHasSentMessage = false;\n                return this.connectImpl();\n            });\n        }\n        this.privConnectionPromise = this.retryableConnect();\n        // Attach an empty handler to allow the promise to run in the background while\n        // other startup events happen. It'll eventually be awaited on.\n        // eslint-disable-next-line @typescript-eslint/no-empty-function\n        this.privConnectionPromise.catch(() => { });\n        if (this.postConnectImplOverride !== undefined) {\n            return this.postConnectImplOverride(this.privConnectionPromise);\n        }\n        return this.privConnectionPromise;\n    }\n    sendSpeechServiceConfig(connection, requestSession, SpeechServiceConfigJson) {\n        requestSession.onSpeechContext();\n        // filter out anything that is not required for the service to work.\n        if (ServiceRecognizerBase.telemetryDataEnabled !== true) {\n            const withTelemetry = JSON.parse(SpeechServiceConfigJson);\n            const replacement = {\n                context: {\n                    system: withTelemetry.context.system,\n                },\n            };\n            SpeechServiceConfigJson = JSON.stringify(replacement);\n        }\n        if (this.privRecognizerConfig.parameters.getProperty(\"f0f5debc-f8c9-4892-ac4b-90a7ab359fd2\", \"false\").toLowerCase() === \"true\") {\n            const json = JSON.parse(SpeechServiceConfigJson);\n            json.context.DisableReferenceChannel = \"True\";\n            json.context.MicSpec = \"1_0_0\";\n            SpeechServiceConfigJson = JSON.stringify(json);\n        }\n        if (SpeechServiceConfigJson) {\n            return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_14__.SpeechConnectionMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_13__.MessageType.Text, \"speech.config\", requestSession.requestId, \"application/json\", SpeechServiceConfigJson));\n        }\n        return;\n    }\n    fetchConnection() {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (this.privConnectionConfigurationPromise !== undefined) {\n                return this.privConnectionConfigurationPromise.then((connection) => {\n                    if (connection.state() === _common_Exports__WEBPACK_IMPORTED_MODULE_18__.ConnectionState.Disconnected) {\n                        this.privConnectionId = null;\n                        this.privConnectionConfigurationPromise = undefined;\n                        this.privServiceHasSentMessage = false;\n                        return this.fetchConnection();\n                    }\n                    return this.privConnectionConfigurationPromise;\n                }, () => {\n                    this.privConnectionId = null;\n                    this.privConnectionConfigurationPromise = undefined;\n                    this.privServiceHasSentMessage = false;\n                    return this.fetchConnection();\n                });\n            }\n            this.privConnectionConfigurationPromise = this.configureConnection();\n            return yield this.privConnectionConfigurationPromise;\n        });\n    }\n    sendAudio(audioStreamNode) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const audioFormat = yield this.audioSource.format;\n            // The time we last sent data to the service.\n            let nextSendTime = Date.now();\n            // Max amount to send before we start to throttle\n            const fastLaneSizeMs = this.privRecognizerConfig.parameters.getProperty(\"SPEECH-TransmitLengthBeforThrottleMs\", \"5000\");\n            const maxSendUnthrottledBytes = audioFormat.avgBytesPerSec / 1000 * parseInt(fastLaneSizeMs, 10);\n            const startRecogNumber = this.privRequestSession.recogNumber;\n            const readAndUploadCycle = () => __awaiter(this, void 0, void 0, function* () {\n                // If speech is done, stop sending audio.\n                if (!this.privIsDisposed &&\n                    !this.privRequestSession.isSpeechEnded &&\n                    this.privRequestSession.isRecognizing &&\n                    this.privRequestSession.recogNumber === startRecogNumber) {\n                    const connection = yield this.fetchConnection();\n                    const audioStreamChunk = yield audioStreamNode.read();\n                    // we have a new audio chunk to upload.\n                    if (this.privRequestSession.isSpeechEnded) {\n                        // If service already recognized audio end then don't send any more audio\n                        return;\n                    }\n                    let payload;\n                    let sendDelay;\n                    if (!audioStreamChunk || audioStreamChunk.isEnd) {\n                        payload = null;\n                        sendDelay = 0;\n                    }\n                    else {\n                        payload = audioStreamChunk.buffer;\n                        this.privRequestSession.onAudioSent(payload.byteLength);\n                        if (maxSendUnthrottledBytes >= this.privRequestSession.bytesSent) {\n                            sendDelay = 0;\n                        }\n                        else {\n                            sendDelay = Math.max(0, nextSendTime - Date.now());\n                        }\n                    }\n                    if (0 !== sendDelay) {\n                        yield this.delay(sendDelay);\n                    }\n                    if (payload !== null) {\n                        nextSendTime = Date.now() + (payload.byteLength * 1000 / (audioFormat.avgBytesPerSec * 2));\n                    }\n                    // Are we still alive?\n                    if (!this.privIsDisposed &&\n                        !this.privRequestSession.isSpeechEnded &&\n                        this.privRequestSession.isRecognizing &&\n                        this.privRequestSession.recogNumber === startRecogNumber) {\n                        connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_14__.SpeechConnectionMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_13__.MessageType.Binary, \"audio\", this.privRequestSession.requestId, null, payload)).catch(() => {\n                            // eslint-disable-next-line @typescript-eslint/no-empty-function\n                            this.privRequestSession.onServiceTurnEndResponse(this.privRecognizerConfig.isContinuousRecognition).catch(() => { });\n                        });\n                        if (!(audioStreamChunk === null || audioStreamChunk === void 0 ? void 0 : audioStreamChunk.isEnd)) {\n                            // this.writeBufferToConsole(payload);\n                            // Regardless of success or failure, schedule the next upload.\n                            // If the underlying connection was broken, the next cycle will\n                            // get a new connection and re-transmit missing audio automatically.\n                            return readAndUploadCycle();\n                        }\n                        else {\n                            // the audio stream has been closed, no need to schedule next\n                            // read-upload cycle.\n                            if (!this.privIsLiveAudio) {\n                                this.privRequestSession.onSpeechEnded();\n                            }\n                        }\n                    }\n                }\n            });\n            return readAndUploadCycle();\n        });\n    }\n    retryableConnect() {\n        return __awaiter(this, void 0, void 0, function* () {\n            let isUnAuthorized = false;\n            this.privAuthFetchEventId = (0,_common_Exports__WEBPACK_IMPORTED_MODULE_19__.createNoDashGuid)();\n            const sessionId = this.privRequestSession.sessionId;\n            this.privConnectionId = (sessionId !== undefined) ? sessionId : (0,_common_Exports__WEBPACK_IMPORTED_MODULE_19__.createNoDashGuid)();\n            this.privRequestSession.onPreConnectionStart(this.privAuthFetchEventId, this.privConnectionId);\n            let lastStatusCode = 0;\n            let lastReason = \"\";\n            while (this.privRequestSession.numConnectionAttempts <= this.privRecognizerConfig.maxRetryCount) {\n                // Get the auth information for the connection. This is a bit of overkill for the current API surface, but leaving the plumbing in place to be able to raise a developer-customer\n                // facing event when a connection fails to let them try and provide new auth information.\n                const authPromise = isUnAuthorized ? this.privAuthentication.fetchOnExpiry(this.privAuthFetchEventId) : this.privAuthentication.fetch(this.privAuthFetchEventId);\n                const auth = yield authPromise;\n                yield this.privRequestSession.onAuthCompleted(false);\n                // Create the connection\n                const connection = this.privConnectionFactory.create(this.privRecognizerConfig, auth, this.privConnectionId);\n                // Attach the telemetry handlers.\n                this.privRequestSession.listenForServiceTelemetry(connection.events);\n                // Attach to the underlying event. No need to hold onto the detach pointers as in the event the connection goes away,\n                // it'll stop sending events.\n                connection.events.attach((event) => {\n                    this.connectionEvents.onEvent(event);\n                });\n                const response = yield connection.open();\n                // 200 == everything is fine.\n                if (response.statusCode === 200) {\n                    yield this.privRequestSession.onConnectionEstablishCompleted(response.statusCode);\n                    return Promise.resolve(connection);\n                }\n                else if (response.statusCode === 1006) {\n                    isUnAuthorized = true;\n                }\n                lastStatusCode = response.statusCode;\n                lastReason = response.reason;\n                this.privRequestSession.onRetryConnection();\n            }\n            yield this.privRequestSession.onConnectionEstablishCompleted(lastStatusCode, lastReason);\n            return Promise.reject(`Unable to contact server. StatusCode: ${lastStatusCode}, ${this.privRecognizerConfig.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.PropertyId.SpeechServiceConnection_Endpoint)} Reason: ${lastReason}`);\n        });\n    }\n    delay(delayMs) {\n        return new Promise((resolve) => this.privSetTimeout(resolve, delayMs));\n    }\n    writeBufferToConsole(buffer) {\n        let out = \"Buffer Size: \";\n        if (null === buffer) {\n            out += \"null\";\n        }\n        else {\n            const readView = new Uint8Array(buffer);\n            out += `${buffer.byteLength}\\r\\n`;\n            for (let i = 0; i < buffer.byteLength; i++) {\n                out += readView[i].toString(16).padStart(2, \"0\") + \" \";\n                if (((i + 1) % 16) === 0) {\n                    // eslint-disable-next-line no-console\n                    console.info(out);\n                    out = \"\";\n                }\n            }\n        }\n        // eslint-disable-next-line no-console\n        console.info(out);\n    }\n    sendFinalAudio() {\n        return __awaiter(this, void 0, void 0, function* () {\n            const connection = yield this.fetchConnection();\n            yield connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_14__.SpeechConnectionMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_13__.MessageType.Binary, \"audio\", this.privRequestSession.requestId, null, null));\n            return;\n        });\n    }\n    // Takes an established websocket connection to the endpoint and sends speech configuration information.\n    configureConnection() {\n        return __awaiter(this, void 0, void 0, function* () {\n            const connection = yield this.connectImpl();\n            if (this.configConnectionOverride !== undefined) {\n                return this.configConnectionOverride(connection);\n            }\n            yield this.sendSpeechServiceConfig(connection, this.privRequestSession, this.privRecognizerConfig.SpeechServiceConfig.serialize());\n            yield this.sendPrePayloadJSON(connection, false);\n            return connection;\n        });\n    }\n}\nServiceRecognizerBase.telemetryDataEnabled = true;\n\n//# sourceMappingURL=ServiceRecognizerBase.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceRecognizerBase.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceTelemetryListener.Internal.js":
  /*!***********************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceTelemetryListener.Internal.js ***!
    \***********************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ServiceTelemetryListener\": () => (/* binding */ ServiceTelemetryListener)\n/* harmony export */ });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/AudioSourceEvents.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionEvents.js\");\n/* harmony import */ var _RecognitionEvents__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./RecognitionEvents */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognitionEvents.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/* eslint-disable max-classes-per-file */\n\n\nclass ServiceTelemetryListener {\n    constructor(requestId, audioSourceId, audioNodeId) {\n        this.privIsDisposed = false;\n        this.privListeningTriggerMetric = null;\n        this.privMicMetric = null;\n        this.privConnectionEstablishMetric = null;\n        this.privRequestId = requestId;\n        this.privAudioSourceId = audioSourceId;\n        this.privAudioNodeId = audioNodeId;\n        this.privReceivedMessages = {};\n        this.privPhraseLatencies = [];\n        this.privHypothesisLatencies = [];\n    }\n    phraseReceived(audioReceivedTime) {\n        if (audioReceivedTime > 0) { // 0 indicates the time is unknown. Drop it.\n            this.privPhraseLatencies.push(Date.now() - audioReceivedTime);\n        }\n    }\n    hypothesisReceived(audioReceivedTime) {\n        if (audioReceivedTime > 0) { // 0 indicates the time is unknown. Drop it.\n            this.privHypothesisLatencies.push(Date.now() - audioReceivedTime);\n        }\n    }\n    onEvent(e) {\n        if (this.privIsDisposed) {\n            return;\n        }\n        if (e instanceof _RecognitionEvents__WEBPACK_IMPORTED_MODULE_0__.RecognitionTriggeredEvent && e.requestId === this.privRequestId) {\n            this.privListeningTriggerMetric = {\n                End: e.eventTime,\n                Name: \"ListeningTrigger\",\n                Start: e.eventTime,\n            };\n        }\n        if (e instanceof _common_Exports__WEBPACK_IMPORTED_MODULE_1__.AudioStreamNodeAttachingEvent && e.audioSourceId === this.privAudioSourceId && e.audioNodeId === this.privAudioNodeId) {\n            this.privMicStartTime = e.eventTime;\n        }\n        if (e instanceof _common_Exports__WEBPACK_IMPORTED_MODULE_1__.AudioStreamNodeAttachedEvent && e.audioSourceId === this.privAudioSourceId && e.audioNodeId === this.privAudioNodeId) {\n            this.privMicStartTime = e.eventTime;\n        }\n        if (e instanceof _common_Exports__WEBPACK_IMPORTED_MODULE_1__.AudioSourceErrorEvent && e.audioSourceId === this.privAudioSourceId) {\n            if (!this.privMicMetric) {\n                this.privMicMetric = {\n                    End: e.eventTime,\n                    Error: e.error,\n                    Name: \"Microphone\",\n                    Start: this.privMicStartTime,\n                };\n            }\n        }\n        if (e instanceof _common_Exports__WEBPACK_IMPORTED_MODULE_1__.AudioStreamNodeErrorEvent && e.audioSourceId === this.privAudioSourceId && e.audioNodeId === this.privAudioNodeId) {\n            if (!this.privMicMetric) {\n                this.privMicMetric = {\n                    End: e.eventTime,\n                    Error: e.error,\n                    Name: \"Microphone\",\n                    Start: this.privMicStartTime,\n                };\n            }\n        }\n        if (e instanceof _common_Exports__WEBPACK_IMPORTED_MODULE_1__.AudioStreamNodeDetachedEvent && e.audioSourceId === this.privAudioSourceId && e.audioNodeId === this.privAudioNodeId) {\n            if (!this.privMicMetric) {\n                this.privMicMetric = {\n                    End: e.eventTime,\n                    Name: \"Microphone\",\n                    Start: this.privMicStartTime,\n                };\n            }\n        }\n        if (e instanceof _RecognitionEvents__WEBPACK_IMPORTED_MODULE_0__.ConnectingToServiceEvent && e.requestId === this.privRequestId) {\n            this.privConnectionId = e.sessionId;\n        }\n        if (e instanceof _common_Exports__WEBPACK_IMPORTED_MODULE_2__.ConnectionStartEvent && e.connectionId === this.privConnectionId) {\n            this.privConnectionStartTime = e.eventTime;\n        }\n        if (e instanceof _common_Exports__WEBPACK_IMPORTED_MODULE_2__.ConnectionEstablishedEvent && e.connectionId === this.privConnectionId) {\n            if (!this.privConnectionEstablishMetric) {\n                this.privConnectionEstablishMetric = {\n                    End: e.eventTime,\n                    Id: this.privConnectionId,\n                    Name: \"Connection\",\n                    Start: this.privConnectionStartTime,\n                };\n            }\n        }\n        if (e instanceof _common_Exports__WEBPACK_IMPORTED_MODULE_2__.ConnectionEstablishErrorEvent && e.connectionId === this.privConnectionId) {\n            if (!this.privConnectionEstablishMetric) {\n                this.privConnectionEstablishMetric = {\n                    End: e.eventTime,\n                    Error: this.getConnectionError(e.statusCode),\n                    Id: this.privConnectionId,\n                    Name: \"Connection\",\n                    Start: this.privConnectionStartTime,\n                };\n            }\n        }\n        if (e instanceof _common_Exports__WEBPACK_IMPORTED_MODULE_2__.ConnectionMessageReceivedEvent && e.connectionId === this.privConnectionId) {\n            if (e.message && e.message.headers && e.message.headers.path) {\n                if (!this.privReceivedMessages[e.message.headers.path]) {\n                    this.privReceivedMessages[e.message.headers.path] = new Array();\n                }\n                const maxMessagesToSend = 50;\n                if (this.privReceivedMessages[e.message.headers.path].length < maxMessagesToSend) {\n                    this.privReceivedMessages[e.message.headers.path].push(e.networkReceivedTime);\n                }\n            }\n        }\n    }\n    getTelemetry() {\n        const metrics = new Array();\n        if (this.privListeningTriggerMetric) {\n            metrics.push(this.privListeningTriggerMetric);\n        }\n        if (this.privMicMetric) {\n            metrics.push(this.privMicMetric);\n        }\n        if (this.privConnectionEstablishMetric) {\n            metrics.push(this.privConnectionEstablishMetric);\n        }\n        if (this.privPhraseLatencies.length > 0) {\n            metrics.push({\n                PhraseLatencyMs: this.privPhraseLatencies,\n            });\n        }\n        if (this.privHypothesisLatencies.length > 0) {\n            metrics.push({\n                FirstHypothesisLatencyMs: this.privHypothesisLatencies,\n            });\n        }\n        const telemetry = {\n            Metrics: metrics,\n            ReceivedMessages: this.privReceivedMessages,\n        };\n        const json = JSON.stringify(telemetry);\n        // We dont want to send the same telemetry again. So clean those out.\n        this.privReceivedMessages = {};\n        this.privListeningTriggerMetric = null;\n        this.privMicMetric = null;\n        this.privConnectionEstablishMetric = null;\n        this.privPhraseLatencies = [];\n        this.privHypothesisLatencies = [];\n        return json;\n    }\n    // Determines if there are any telemetry events to send to the service.\n    get hasTelemetry() {\n        return (Object.keys(this.privReceivedMessages).length !== 0 ||\n            this.privListeningTriggerMetric !== null ||\n            this.privMicMetric !== null ||\n            this.privConnectionEstablishMetric !== null ||\n            this.privPhraseLatencies.length !== 0 ||\n            this.privHypothesisLatencies.length !== 0);\n    }\n    dispose() {\n        this.privIsDisposed = true;\n    }\n    getConnectionError(statusCode) {\n        /*\n        -- Websocket status codes --\n        NormalClosure = 1000,\n        EndpointUnavailable = 1001,\n        ProtocolError = 1002,\n        InvalidMessageType = 1003,\n        Empty = 1005,\n        InvalidPayloadData = 1007,\n        PolicyViolation = 1008,\n        MessageTooBig = 1009,\n        MandatoryExtension = 1010,\n        InternalServerError = 1011\n        */\n        switch (statusCode) {\n            case 400:\n            case 1002:\n            case 1003:\n            case 1005:\n            case 1007:\n            case 1008:\n            case 1009: return \"BadRequest\";\n            case 401: return \"Unauthorized\";\n            case 403: return \"Forbidden\";\n            case 503:\n            case 1001: return \"ServerUnavailable\";\n            case 500:\n            case 1011: return \"ServerError\";\n            case 408:\n            case 504: return \"Timeout\";\n            default: return \"statuscode:\" + statusCode.toString();\n        }\n    }\n}\n\n//# sourceMappingURL=ServiceTelemetryListener.Internal.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceTelemetryListener.Internal.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeakerIdMessageAdapter.js":
  /*!*************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeakerIdMessageAdapter.js ***!
    \*************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SpeakerIdMessageAdapter\": () => (/* binding */ SpeakerIdMessageAdapter)\n/* harmony export */ });\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/RestConfigBase.js\");\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/RestMessageAdapter.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileType.js\");\n/* harmony import */ var _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./ConnectionFactoryBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js\");\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\n/**\n * Implements methods for speaker recognition classes, sending requests to endpoint\n * and parsing response into expected format\n * @class SpeakerIdMessageAdapter\n */\nclass SpeakerIdMessageAdapter {\n    constructor(config) {\n        let endpoint = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_Endpoint, undefined);\n        if (!endpoint) {\n            const region = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_Region, \"westus\");\n            const hostSuffix = _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_1__.ConnectionFactoryBase.getHostSuffix(region);\n            endpoint = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_Host, `https://${region}.api.cognitive${hostSuffix}`);\n        }\n        this.privUri = `${endpoint}/speaker-recognition/{mode}/{dependency}/profiles`;\n        const options = _common_browser_Exports__WEBPACK_IMPORTED_MODULE_2__.RestConfigBase.requestOptions;\n        options.headers[_common_browser_Exports__WEBPACK_IMPORTED_MODULE_2__.RestConfigBase.configParams.subscriptionKey] = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_Key, undefined);\n        this.privApiVersion = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeakerRecognition_Api_Version, \"2021-09-05\");\n        this.privRestAdapter = new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_3__.RestMessageAdapter(options);\n    }\n    /**\n     * Sends create profile request to endpoint.\n     * @function\n     * @param {VoiceProfileType} profileType - type of voice profile to create.\n     * @param {string} lang - language/locale of voice profile\n     * @public\n     * @returns {Promise<IRestResponse>} promised rest response containing id of created profile.\n     */\n    createProfile(profileType, lang) {\n        const uri = this.getOperationUri(profileType);\n        return this.privRestAdapter.request(_common_browser_Exports__WEBPACK_IMPORTED_MODULE_3__.RestRequestType.Post, uri, this.getQueryParams({}), { locale: lang });\n    }\n    /**\n     * Sends create enrollment request to endpoint.\n     * @function\n     * @param {VoiceProfile} profileType - voice profile for which to create new enrollment.\n     * @param {IAudioSource} audioSource - audioSource from which to pull data to send\n     * @public\n     * @returns {Promise<IRestResponse>} rest response to enrollment request.\n     */\n    createEnrollment(profile, audioSource) {\n        const uri = this.getOperationUri(profile.profileType) + \"/\" + profile.profileId + \"/enrollments\";\n        // eslint-disable-next-line @typescript-eslint/no-unsafe-argument\n        return audioSource.blob.then((result) => this.privRestAdapter.request(_common_browser_Exports__WEBPACK_IMPORTED_MODULE_3__.RestRequestType.File, uri, this.getQueryParams({ ignoreMinLength: \"true\" }), null, result));\n    }\n    /**\n     * Sends verification request to endpoint.\n     * @function\n     * @param {SpeakerVerificationModel} model - voice model to verify against.\n     * @param {IAudioSource} audioSource - audioSource from which to pull data to send\n     * @public\n     * @returns {Promise<IRestResponse>} rest response to enrollment request.\n     */\n    verifySpeaker(model, audioSource) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const uri = this.getOperationUri(model.voiceProfile.profileType) + \"/\" + model.voiceProfile.profileId + \":verify\";\n            try {\n                const result = yield audioSource.blob;\n                return this.privRestAdapter.request(_common_browser_Exports__WEBPACK_IMPORTED_MODULE_3__.RestRequestType.File, uri, this.getQueryParams({ ignoreMinLength: \"true\" }), null, result);\n            }\n            catch (e) {\n                return Promise.resolve({ data: e });\n            }\n        });\n    }\n    /**\n     * Sends identification request to endpoint.\n     * @function\n     * @param {SpeakerIdentificationModel} model - voice profiles against which to identify.\n     * @param {IAudioSource} audioSource - audioSource from which to pull data to send\n     * @public\n     * @returns {Promise<IRestResponse>} rest response to enrollment request.\n     */\n    identifySpeaker(model, audioSource) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const uri = this.getOperationUri(_sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.VoiceProfileType.TextIndependentIdentification) + \":identifySingleSpeaker\";\n            try {\n                const result = yield audioSource.blob;\n                return this.privRestAdapter.request(_common_browser_Exports__WEBPACK_IMPORTED_MODULE_3__.RestRequestType.File, uri, this.getQueryParams({ profileIds: model.voiceProfileIds, ignoreMinLength: \"true\" }), null, result);\n            }\n            catch (e) {\n                return Promise.resolve({ data: e });\n            }\n        });\n    }\n    /**\n     * Sends profile status request to endpoint.\n     * @function\n     * @param {VoiceProfile} profile - voice profile to check.\n     * @public\n     * @returns {Promise<IRestResponse>} rest response to status request\n     */\n    getProfileStatus(profile) {\n        const uri = `${this.getOperationUri(profile.profileType)}/${profile.profileId}`;\n        return this.privRestAdapter.request(_common_browser_Exports__WEBPACK_IMPORTED_MODULE_3__.RestRequestType.Get, uri, this.getQueryParams());\n    }\n    /**\n     * Sends get all profiles request to endpoint.\n     * @function\n     * @param {VoiceProfileType} profileType - type of profiles to return list of\n     * @public\n     * @returns {Promise<IRestResponse>} promised rest response containing all profiles\n     */\n    getProfiles(profileType) {\n        const uri = this.getOperationUri(profileType);\n        return this.privRestAdapter.request(_common_browser_Exports__WEBPACK_IMPORTED_MODULE_3__.RestRequestType.Get, uri, this.getQueryParams());\n    }\n    /**\n     * Sends get activation/auth phrases request to endpoint.\n     * @function\n     * @param {VoiceProfileType} profileType - type of profiles to return phrases for\n     * @param {string} lang - language/locale of voice profile\n     * @public\n     * @returns {Promise<IRestResponse>} promised rest response containing list of valid phrases\n     */\n    getPhrases(profileType, lang) {\n        const uri = `${this.getOperationUri(profileType)}`.replace(\"profiles\", \"phrases\") + \"/\" + lang;\n        return this.privRestAdapter.request(_common_browser_Exports__WEBPACK_IMPORTED_MODULE_3__.RestRequestType.Get, uri, this.getQueryParams());\n    }\n    /**\n     * Sends delete profile request to endpoint.\n     * @function\n     * @param {VoiceProfile} profile - voice profile to delete.\n     * @public\n     * @returns {Promise<IRestResponse>} rest response to deletion request\n     */\n    deleteProfile(profile) {\n        const uri = this.getOperationUri(profile.profileType) + \"/\" + profile.profileId;\n        return this.privRestAdapter.request(_common_browser_Exports__WEBPACK_IMPORTED_MODULE_3__.RestRequestType.Delete, uri, this.getQueryParams());\n    }\n    /**\n     * Sends reset profile request to endpoint.\n     * @function\n     * @param {VoiceProfile} profile - voice profile to reset enrollments for.\n     * @public\n     * @returns {Promise<IRestResponse>} rest response to reset request\n     */\n    resetProfile(profile) {\n        const uri = this.getOperationUri(profile.profileType) + \"/\" + profile.profileId + \":reset\";\n        return this.privRestAdapter.request(_common_browser_Exports__WEBPACK_IMPORTED_MODULE_3__.RestRequestType.Post, uri, this.getQueryParams());\n    }\n    getOperationUri(profileType) {\n        const mode = profileType === _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.VoiceProfileType.TextIndependentIdentification ? \"identification\" : \"verification\";\n        const dependency = profileType === _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.VoiceProfileType.TextDependentVerification ? \"text-dependent\" : \"text-independent\";\n        return this.privUri.replace(\"{mode}\", mode).replace(\"{dependency}\", dependency);\n    }\n    getQueryParams(params = {}) {\n        params[_common_browser_Exports__WEBPACK_IMPORTED_MODULE_2__.RestConfigBase.configParams.apiVersion] = this.privApiVersion;\n        return params;\n    }\n}\n\n//# sourceMappingURL=SpeakerIdMessageAdapter.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeakerIdMessageAdapter.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeakerRecognitionConfig.js":
  /*!**************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeakerRecognitionConfig.js ***!
    \**************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SpeakerRecognitionConfig\": () => (/* binding */ SpeakerRecognitionConfig)\n/* harmony export */ });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nclass SpeakerRecognitionConfig {\n    constructor(context, parameters) {\n        this.privContext = context ? context : new _Exports__WEBPACK_IMPORTED_MODULE_0__.Context(null);\n        this.privParameters = parameters;\n    }\n    get parameters() {\n        return this.privParameters;\n    }\n    get Context() {\n        return this.privContext;\n    }\n}\n\n//# sourceMappingURL=SpeakerRecognitionConfig.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeakerRecognitionConfig.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionFactory.js":
  /*!*************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionFactory.js ***!
    \*************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SpeechConnectionFactory\": () => (/* binding */ SpeechConnectionFactory)\n/* harmony export */ });\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketConnection.js\");\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ProxyInfo.js\");\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/OutputFormat.js\");\n/* harmony import */ var _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./ConnectionFactoryBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/WebsocketMessageFormatter.js\");\n/* harmony import */ var _HeaderNames__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./HeaderNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js\");\n/* harmony import */ var _QueryParameterNames__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./QueryParameterNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/QueryParameterNames.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\n\n\n\n\nclass SpeechConnectionFactory extends _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__.ConnectionFactoryBase {\n    constructor() {\n        super(...arguments);\n        this.interactiveRelativeUri = \"/speech/recognition/interactive/cognitiveservices/v1\";\n        this.conversationRelativeUri = \"/speech/recognition/conversation/cognitiveservices/v1\";\n        this.dictationRelativeUri = \"/speech/recognition/dictation/cognitiveservices/v1\";\n        this.universalUri = \"/speech/universal/v\";\n    }\n    create(config, authInfo, connectionId) {\n        let endpoint = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Endpoint, undefined);\n        const region = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Region, undefined);\n        const hostSuffix = _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__.ConnectionFactoryBase.getHostSuffix(region);\n        const host = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Host, \"wss://\" + region + \".stt.speech\" + hostSuffix);\n        const queryParams = {};\n        const endpointId = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_EndpointId, undefined);\n        const language = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_RecoLanguage, undefined);\n        if (endpointId) {\n            if (!endpoint || endpoint.search(_QueryParameterNames__WEBPACK_IMPORTED_MODULE_2__.QueryParameterNames.CustomSpeechDeploymentId) === -1) {\n                queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_2__.QueryParameterNames.CustomSpeechDeploymentId] = endpointId;\n            }\n        }\n        else if (language) {\n            if (!endpoint || endpoint.search(_QueryParameterNames__WEBPACK_IMPORTED_MODULE_2__.QueryParameterNames.Language) === -1) {\n                queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_2__.QueryParameterNames.Language] = language;\n            }\n        }\n        if (!endpoint || endpoint.search(_QueryParameterNames__WEBPACK_IMPORTED_MODULE_2__.QueryParameterNames.Format) === -1) {\n            queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_2__.QueryParameterNames.Format] = config.parameters.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__.OutputFormatPropertyName, _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.OutputFormat[_sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.OutputFormat.Simple]).toLowerCase();\n        }\n        if (config.autoDetectSourceLanguages !== undefined) {\n            queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_2__.QueryParameterNames.EnableLanguageId] = \"true\";\n        }\n        this.setCommonUrlParams(config, queryParams, endpoint);\n        if (!endpoint) {\n            switch (config.recognitionMode) {\n                case _Exports__WEBPACK_IMPORTED_MODULE_5__.RecognitionMode.Conversation:\n                    if (config.parameters.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__.ForceDictationPropertyName, \"false\") === \"true\") {\n                        endpoint = host + this.dictationRelativeUri;\n                    }\n                    else {\n                        if (config.recognitionEndpointVersion !== undefined && parseInt(config.recognitionEndpointVersion, 10) > 1) {\n                            endpoint = `${host}${this.universalUri}${config.recognitionEndpointVersion}`;\n                        }\n                        else {\n                            endpoint = host + this.conversationRelativeUri;\n                        }\n                    }\n                    break;\n                case _Exports__WEBPACK_IMPORTED_MODULE_5__.RecognitionMode.Dictation:\n                    endpoint = host + this.dictationRelativeUri;\n                    break;\n                default:\n                    if (config.recognitionEndpointVersion !== undefined && parseInt(config.recognitionEndpointVersion, 10) > 1) {\n                        endpoint = `${host}${this.universalUri}${config.recognitionEndpointVersion}`;\n                    }\n                    else {\n                        endpoint = host + this.interactiveRelativeUri; // default is interactive\n                    }\n                    break;\n            }\n        }\n        const headers = {};\n        if (authInfo.token !== undefined && authInfo.token !== \"\") {\n            headers[authInfo.headerName] = authInfo.token;\n        }\n        headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_6__.HeaderNames.ConnectionId] = connectionId;\n        const enableCompression = config.parameters.getProperty(\"SPEECH-EnableWebsocketCompression\", \"false\") === \"true\";\n        const webSocketConnection = new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_7__.WebsocketConnection(endpoint, queryParams, headers, new _Exports__WEBPACK_IMPORTED_MODULE_8__.WebsocketMessageFormatter(), _common_browser_Exports__WEBPACK_IMPORTED_MODULE_9__.ProxyInfo.fromRecognizerConfig(config), enableCompression, connectionId);\n        // Set the value of SpeechServiceConnection_Url to webSocketConnection.uri (and not to `endpoint`), since this value is the final\n        // URI that was used to make the connection (including query parameters).\n        const uri = webSocketConnection.uri;\n        config.parameters.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Url, uri);\n        return webSocketConnection;\n    }\n}\n\n//# sourceMappingURL=SpeechConnectionFactory.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionFactory.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionMessage.Internal.js":
  /*!**********************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionMessage.Internal.js ***!
    \**********************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SpeechConnectionMessage\": () => (/* binding */ SpeechConnectionMessage)\n/* harmony export */ });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js\");\n/* harmony import */ var _HeaderNames__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./HeaderNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\nclass SpeechConnectionMessage extends _common_Exports__WEBPACK_IMPORTED_MODULE_0__.ConnectionMessage {\n    constructor(messageType, path, requestId, contentType, body, streamId, additionalHeaders, id) {\n        if (!path) {\n            throw new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.ArgumentNullError(\"path\");\n        }\n        if (!requestId) {\n            throw new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.ArgumentNullError(\"requestId\");\n        }\n        const headers = {};\n        headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_2__.HeaderNames.Path] = path;\n        headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_2__.HeaderNames.RequestId] = requestId;\n        headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_2__.HeaderNames.RequestTimestamp] = new Date().toISOString();\n        if (contentType) {\n            headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_2__.HeaderNames.ContentType] = contentType;\n        }\n        if (streamId) {\n            headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_2__.HeaderNames.RequestStreamId] = streamId;\n        }\n        if (additionalHeaders) {\n            for (const headerName in additionalHeaders) {\n                if (headerName) {\n                    headers[headerName] = additionalHeaders[headerName];\n                }\n            }\n        }\n        if (id) {\n            super(messageType, body, headers, id);\n        }\n        else {\n            super(messageType, body, headers);\n        }\n        this.privPath = path;\n        this.privRequestId = requestId;\n        this.privContentType = contentType;\n        this.privStreamId = streamId;\n        this.privAdditionalHeaders = additionalHeaders;\n    }\n    get path() {\n        return this.privPath;\n    }\n    get requestId() {\n        return this.privRequestId;\n    }\n    get contentType() {\n        return this.privContentType;\n    }\n    get streamId() {\n        return this.privStreamId;\n    }\n    get additionalHeaders() {\n        return this.privAdditionalHeaders;\n    }\n    static fromConnectionMessage(message) {\n        let path = null;\n        let requestId = null;\n        let contentType = null;\n        // let requestTimestamp = null;\n        let streamId = null;\n        const additionalHeaders = {};\n        if (message.headers) {\n            for (const headerName in message.headers) {\n                if (headerName) {\n                    if (headerName.toLowerCase() === _HeaderNames__WEBPACK_IMPORTED_MODULE_2__.HeaderNames.Path.toLowerCase()) {\n                        path = message.headers[headerName];\n                    }\n                    else if (headerName.toLowerCase() === _HeaderNames__WEBPACK_IMPORTED_MODULE_2__.HeaderNames.RequestId.toLowerCase()) {\n                        requestId = message.headers[headerName];\n                        // } else if (headerName.toLowerCase() === HeaderNames.RequestTimestamp.toLowerCase()) {\n                        //  requestTimestamp = message.headers[headerName];\n                    }\n                    else if (headerName.toLowerCase() === _HeaderNames__WEBPACK_IMPORTED_MODULE_2__.HeaderNames.ContentType.toLowerCase()) {\n                        contentType = message.headers[headerName];\n                    }\n                    else if (headerName.toLowerCase() === _HeaderNames__WEBPACK_IMPORTED_MODULE_2__.HeaderNames.RequestStreamId.toLowerCase()) {\n                        streamId = message.headers[headerName];\n                    }\n                    else {\n                        additionalHeaders[headerName] = message.headers[headerName];\n                    }\n                }\n            }\n        }\n        return new SpeechConnectionMessage(message.messageType, path, requestId, contentType, message.body, streamId, additionalHeaders, message.id);\n    }\n}\n\n//# sourceMappingURL=SpeechConnectionMessage.Internal.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionMessage.Internal.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechContext.js":
  /*!***************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechContext.js ***!
    \***************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SpeechContext\": () => (/* binding */ SpeechContext)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Represents the JSON used in the speech.context message sent to the speech service.\n * The dynamic grammar is always refreshed from the encapsulated dynamic grammar object.\n */\nclass SpeechContext {\n    constructor(dynamicGrammar) {\n        this.privContext = {};\n        this.privDynamicGrammar = dynamicGrammar;\n    }\n    /**\n     * Adds a section to the speech.context object.\n     * @param sectionName Name of the section to add.\n     * @param value JSON serializable object that represents the value.\n     */\n    setSection(sectionName, value) {\n        this.privContext[sectionName] = value;\n    }\n    /**\n     * @Internal\n     * This is only used by pronunciation assessment config.\n     * Do not use externally, object returned will change without warning or notice.\n     */\n    setPronunciationAssessmentParams(params) {\n        if (this.privContext.phraseDetection === undefined) {\n            this.privContext.phraseDetection = {\n                enrichment: {\n                    pronunciationAssessment: {}\n                }\n            };\n        }\n        this.privContext.phraseDetection.enrichment.pronunciationAssessment = JSON.parse(params);\n        this.setWordLevelTimings();\n        this.privContext.phraseOutput.detailed.options.push(\"PronunciationAssessment\");\n        if (this.privContext.phraseOutput.detailed.options.indexOf(\"SNR\") === -1) {\n            this.privContext.phraseOutput.detailed.options.push(\"SNR\");\n        }\n    }\n    setWordLevelTimings() {\n        if (this.privContext.phraseOutput === undefined) {\n            this.privContext.phraseOutput = {\n                detailed: {\n                    options: []\n                },\n                format: {}\n            };\n        }\n        if (this.privContext.phraseOutput.detailed === undefined) {\n            this.privContext.phraseOutput.detailed = {\n                options: []\n            };\n        }\n        this.privContext.phraseOutput.format = \"Detailed\";\n        if (this.privContext.phraseOutput.detailed.options.indexOf(\"WordTimings\") === -1) {\n            this.privContext.phraseOutput.detailed.options.push(\"WordTimings\");\n        }\n    }\n    toJSON() {\n        const dgi = this.privDynamicGrammar.generateGrammarObject();\n        this.setSection(\"dgi\", dgi);\n        const ret = JSON.stringify(this.privContext);\n        return ret;\n    }\n}\n\n//# sourceMappingURL=SpeechContext.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechContext.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechServiceInterfaces.js":
  /*!*************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechServiceInterfaces.js ***!
    \*************************************************************************************************************************/
  /***/ (() => {
  
  eval("// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n//# sourceMappingURL=SpeechServiceInterfaces.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechServiceInterfaces.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechServiceRecognizer.js":
  /*!*************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechServiceRecognizer.js ***!
    \*************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SpeechServiceRecognizer\": () => (/* binding */ SpeechServiceRecognizer)\n/* harmony export */ });\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionResult.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionEventArgs.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/OutputFormat.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionCanceledEventArgs.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceRecognizerBase.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechHypothesis.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SimpleSpeechPhrase.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/EnumTranslation.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/Enums.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/DetailedSpeechPhrase.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n// eslint-disable-next-line max-classes-per-file\nclass SpeechServiceRecognizer extends _Exports__WEBPACK_IMPORTED_MODULE_0__.ServiceRecognizerBase {\n    constructor(authentication, connectionFactory, audioSource, recognizerConfig, speechRecognizer) {\n        super(authentication, connectionFactory, audioSource, recognizerConfig, speechRecognizer);\n        this.privSpeechRecognizer = speechRecognizer;\n        const phraseDetection = {};\n        const speechSegmentationTimeout = recognizerConfig.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.Speech_SegmentationSilenceTimeoutMs, undefined);\n        if (speechSegmentationTimeout !== undefined) {\n            const segmentationSilenceTimeoutMs = parseInt(speechSegmentationTimeout, 10);\n            phraseDetection.mode = \"INTERACTIVE\";\n            phraseDetection.INTERACTIVE = {\n                segmentation: {\n                    mode: \"Custom\",\n                    segmentationSilenceTimeoutMs\n                }\n            };\n        }\n        if (recognizerConfig.autoDetectSourceLanguages !== undefined) {\n            const sourceLanguages = recognizerConfig.autoDetectSourceLanguages.split(\",\");\n            let speechContextLidMode;\n            if (recognizerConfig.languageIdMode === \"Continuous\") {\n                speechContextLidMode = \"DetectContinuous\";\n            }\n            else { // recognizerConfig.languageIdMode === \"AtStart\"\n                speechContextLidMode = \"DetectAtAudioStart\";\n            }\n            this.privSpeechContext.setSection(\"languageId\", {\n                Priority: \"PrioritizeLatency\",\n                languages: sourceLanguages,\n                mode: speechContextLidMode,\n                onSuccess: { action: \"Recognize\" },\n                onUnknown: { action: \"None\" }\n            });\n            this.privSpeechContext.setSection(\"phraseOutput\", {\n                interimResults: {\n                    resultType: \"Auto\"\n                },\n                phraseResults: {\n                    resultType: \"Always\"\n                }\n            });\n            const customModels = recognizerConfig.sourceLanguageModels;\n            if (customModels !== undefined) {\n                phraseDetection.customModels = customModels;\n                phraseDetection.onInterim = { action: \"None\" };\n                phraseDetection.onSuccess = { action: \"None\" };\n            }\n        }\n        const isEmpty = (obj) => {\n            // eslint-disable-next-line guard-for-in, brace-style\n            for (const x in obj) {\n                return false;\n            }\n            return true;\n        };\n        if (!isEmpty(phraseDetection)) {\n            this.privSpeechContext.setSection(\"phraseDetection\", phraseDetection);\n        }\n    }\n    processTypeSpecificMessages(connectionMessage) {\n        return __awaiter(this, void 0, void 0, function* () {\n            let result;\n            const resultProps = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyCollection();\n            resultProps.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceResponse_JsonResult, connectionMessage.textBody);\n            let processed = false;\n            switch (connectionMessage.path.toLowerCase()) {\n                case \"speech.hypothesis\":\n                case \"speech.fragment\":\n                    const hypothesis = _Exports__WEBPACK_IMPORTED_MODULE_3__.SpeechHypothesis.fromJSON(connectionMessage.textBody);\n                    const offset = hypothesis.Offset + this.privRequestSession.currentTurnAudioOffset;\n                    result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.SpeechRecognitionResult(this.privRequestSession.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.RecognizingSpeech, hypothesis.Text, hypothesis.Duration, offset, hypothesis.Language, hypothesis.LanguageDetectionConfidence, undefined, // Speaker Id\n                    undefined, connectionMessage.textBody, resultProps);\n                    this.privRequestSession.onHypothesis(offset);\n                    const ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.SpeechRecognitionEventArgs(result, hypothesis.Duration, this.privRequestSession.sessionId);\n                    if (!!this.privSpeechRecognizer.recognizing) {\n                        try {\n                            this.privSpeechRecognizer.recognizing(this.privSpeechRecognizer, ev);\n                            /* eslint-disable no-empty */\n                        }\n                        catch (error) {\n                            // Not going to let errors in the event handler\n                            // trip things up.\n                        }\n                    }\n                    processed = true;\n                    break;\n                case \"speech.phrase\":\n                    const simple = _Exports__WEBPACK_IMPORTED_MODULE_7__.SimpleSpeechPhrase.fromJSON(connectionMessage.textBody);\n                    const resultReason = _Exports__WEBPACK_IMPORTED_MODULE_8__.EnumTranslation.implTranslateRecognitionResult(simple.RecognitionStatus);\n                    this.privRequestSession.onPhraseRecognized(this.privRequestSession.currentTurnAudioOffset + simple.Offset + simple.Duration);\n                    if (_sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.Canceled === resultReason) {\n                        const cancelReason = _Exports__WEBPACK_IMPORTED_MODULE_8__.EnumTranslation.implTranslateCancelResult(simple.RecognitionStatus);\n                        const cancellationErrorCode = _Exports__WEBPACK_IMPORTED_MODULE_8__.EnumTranslation.implTranslateCancelErrorCode(simple.RecognitionStatus);\n                        yield this.cancelRecognitionLocal(cancelReason, cancellationErrorCode, _Exports__WEBPACK_IMPORTED_MODULE_8__.EnumTranslation.implTranslateErrorDetails(cancellationErrorCode));\n                    }\n                    else {\n                        if (!(this.privRequestSession.isSpeechEnded && resultReason === _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.NoMatch && simple.RecognitionStatus !== _Exports__WEBPACK_IMPORTED_MODULE_9__.RecognitionStatus.InitialSilenceTimeout)) {\n                            if (this.privRecognizerConfig.parameters.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_10__.OutputFormatPropertyName) === _sdk_Exports__WEBPACK_IMPORTED_MODULE_11__.OutputFormat[_sdk_Exports__WEBPACK_IMPORTED_MODULE_11__.OutputFormat.Simple]) {\n                                result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.SpeechRecognitionResult(this.privRequestSession.requestId, resultReason, simple.DisplayText, simple.Duration, simple.Offset + this.privRequestSession.currentTurnAudioOffset, simple.Language, simple.LanguageDetectionConfidence, undefined, // Speaker Id\n                                undefined, connectionMessage.textBody, resultProps);\n                            }\n                            else {\n                                const detailed = _Exports__WEBPACK_IMPORTED_MODULE_12__.DetailedSpeechPhrase.fromJSON(connectionMessage.textBody);\n                                const totalOffset = detailed.Offset + this.privRequestSession.currentTurnAudioOffset;\n                                const offsetCorrectedJson = detailed.getJsonWithCorrectedOffsets(totalOffset);\n                                result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.SpeechRecognitionResult(this.privRequestSession.requestId, resultReason, detailed.RecognitionStatus === _Exports__WEBPACK_IMPORTED_MODULE_9__.RecognitionStatus.Success ? detailed.NBest[0].Display : undefined, detailed.Duration, totalOffset, detailed.Language, detailed.LanguageDetectionConfidence, undefined, // Speaker Id\n                                undefined, offsetCorrectedJson, resultProps);\n                            }\n                            const event = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.SpeechRecognitionEventArgs(result, result.offset, this.privRequestSession.sessionId);\n                            if (!!this.privSpeechRecognizer.recognized) {\n                                try {\n                                    this.privSpeechRecognizer.recognized(this.privSpeechRecognizer, event);\n                                    /* eslint-disable no-empty */\n                                }\n                                catch (error) {\n                                    // Not going to let errors in the event handler\n                                    // trip things up.\n                                }\n                            }\n                        }\n                        if (!!this.privSuccessCallback) {\n                            try {\n                                this.privSuccessCallback(result);\n                            }\n                            catch (e) {\n                                if (!!this.privErrorCallback) {\n                                    this.privErrorCallback(e);\n                                }\n                            }\n                            // Only invoke the call back once.\n                            // and if it's successful don't invoke the\n                            // error after that.\n                            this.privSuccessCallback = undefined;\n                            this.privErrorCallback = undefined;\n                        }\n                    }\n                    processed = true;\n                    break;\n                default:\n                    break;\n            }\n            return processed;\n        });\n    }\n    // Cancels recognition.\n    cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {\n        const properties = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyCollection();\n        properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_10__.CancellationErrorCodePropertyName, _sdk_Exports__WEBPACK_IMPORTED_MODULE_13__.CancellationErrorCode[errorCode]);\n        if (!!this.privSpeechRecognizer.canceled) {\n            const cancelEvent = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_14__.SpeechRecognitionCanceledEventArgs(cancellationReason, error, errorCode, undefined, sessionId);\n            try {\n                this.privSpeechRecognizer.canceled(this.privSpeechRecognizer, cancelEvent);\n                /* eslint-disable no-empty */\n            }\n            catch (_a) { }\n        }\n        if (!!this.privSuccessCallback) {\n            const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.SpeechRecognitionResult(requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.Canceled, undefined, // Text\n            undefined, // Duration\n            undefined, // Offset\n            undefined, // Language\n            undefined, // Language Detection Confidence\n            undefined, // Speaker Id\n            error, undefined, // Json\n            properties);\n            try {\n                this.privSuccessCallback(result);\n                this.privSuccessCallback = undefined;\n                /* eslint-disable no-empty */\n            }\n            catch (_b) { }\n        }\n    }\n}\n\n//# sourceMappingURL=SpeechServiceRecognizer.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechServiceRecognizer.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechSynthesisConnectionFactory.js":
  /*!**********************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechSynthesisConnectionFactory.js ***!
    \**********************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SpeechSynthesisConnectionFactory\": () => (/* binding */ SpeechSynthesisConnectionFactory)\n/* harmony export */ });\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketConnection.js\");\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ProxyInfo.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./ConnectionFactoryBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/WebsocketMessageFormatter.js\");\n/* harmony import */ var _HeaderNames__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./HeaderNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js\");\n/* harmony import */ var _QueryParameterNames__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./QueryParameterNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/QueryParameterNames.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\n\n\n\nclass SpeechSynthesisConnectionFactory {\n    constructor() {\n        this.synthesisUri = \"/cognitiveservices/websocket/v1\";\n    }\n    create(config, authInfo, connectionId) {\n        let endpoint = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_Endpoint, undefined);\n        const region = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_Region, undefined);\n        const hostSuffix = _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_1__.ConnectionFactoryBase.getHostSuffix(region);\n        const endpointId = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_EndpointId, undefined);\n        const hostPrefix = (endpointId === undefined) ? \"tts\" : \"voice\";\n        const host = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_Host, \"wss://\" + region + \".\" + hostPrefix + \".speech\" + hostSuffix);\n        const queryParams = {};\n        if (!endpoint) {\n            endpoint = host + this.synthesisUri;\n        }\n        const headers = {};\n        if (authInfo.token !== undefined && authInfo.token !== \"\") {\n            headers[authInfo.headerName] = authInfo.token;\n        }\n        headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_2__.HeaderNames.ConnectionId] = connectionId;\n        if (endpointId !== undefined) {\n            headers[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_3__.QueryParameterNames.CustomVoiceDeploymentId] = endpointId;\n        }\n        config.parameters.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_Url, endpoint);\n        const enableCompression = config.parameters.getProperty(\"SPEECH-EnableWebsocketCompression\", \"false\") === \"true\";\n        return new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_4__.WebsocketConnection(endpoint, queryParams, headers, new _Exports__WEBPACK_IMPORTED_MODULE_5__.WebsocketMessageFormatter(), _common_browser_Exports__WEBPACK_IMPORTED_MODULE_6__.ProxyInfo.fromParameters(config.parameters), enableCompression, connectionId);\n    }\n}\n\n//# sourceMappingURL=SpeechSynthesisConnectionFactory.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechSynthesisConnectionFactory.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisAdapterBase.js":
  /*!**********************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisAdapterBase.js ***!
    \**********************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SynthesisAdapterBase\": () => (/* binding */ SynthesisAdapterBase)\n/* harmony export */ });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/EventSource.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_18__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionEvents.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_19__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IConnection.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_20__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationReason.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisEventArgs.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisResult.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisWordBoundaryEventArgs.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisBookmarkEventArgs.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisVisemeEventArgs.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_21__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisTurn.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisContext.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/AgentConfig.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SynthesisAudioMetadata.js\");\n/* harmony import */ var _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./SpeechConnectionMessage.Internal */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionMessage.Internal.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\n\nclass SynthesisAdapterBase {\n    constructor(authentication, connectionFactory, synthesizerConfig, speechSynthesizer, audioDestination) {\n        this.speakOverride = undefined;\n        this.receiveMessageOverride = undefined;\n        this.connectImplOverride = undefined;\n        this.configConnectionOverride = undefined;\n        // A promise for a configured connection.\n        // Do not consume directly, call fetchConnection instead.\n        this.privConnectionConfigurationPromise = undefined;\n        if (!authentication) {\n            throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__.ArgumentNullError(\"authentication\");\n        }\n        if (!connectionFactory) {\n            throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__.ArgumentNullError(\"connectionFactory\");\n        }\n        if (!synthesizerConfig) {\n            throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__.ArgumentNullError(\"synthesizerConfig\");\n        }\n        this.privAuthentication = authentication;\n        this.privConnectionFactory = connectionFactory;\n        this.privSynthesizerConfig = synthesizerConfig;\n        this.privIsDisposed = false;\n        this.privSpeechSynthesizer = speechSynthesizer;\n        this.privSessionAudioDestination = audioDestination;\n        this.privSynthesisTurn = new _Exports__WEBPACK_IMPORTED_MODULE_1__.SynthesisTurn();\n        this.privConnectionEvents = new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.EventSource();\n        this.privServiceEvents = new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.EventSource();\n        this.privSynthesisContext = new _Exports__WEBPACK_IMPORTED_MODULE_3__.SynthesisContext(this.privSpeechSynthesizer);\n        this.privAgentConfig = new _Exports__WEBPACK_IMPORTED_MODULE_4__.AgentConfig();\n        this.connectionEvents.attach((connectionEvent) => {\n            if (connectionEvent.name === \"ConnectionClosedEvent\") {\n                const connectionClosedEvent = connectionEvent;\n                if (connectionClosedEvent.statusCode !== 1000) {\n                    this.cancelSynthesisLocal(_sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.CancellationReason.Error, connectionClosedEvent.statusCode === 1007 ? _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.CancellationErrorCode.BadRequestParameters : _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.CancellationErrorCode.ConnectionFailure, `${connectionClosedEvent.reason} websocket error code: ${connectionClosedEvent.statusCode}`);\n                }\n            }\n        });\n    }\n    get synthesisContext() {\n        return this.privSynthesisContext;\n    }\n    get agentConfig() {\n        return this.privAgentConfig;\n    }\n    get connectionEvents() {\n        return this.privConnectionEvents;\n    }\n    get serviceEvents() {\n        return this.privServiceEvents;\n    }\n    set activityTemplate(messagePayload) {\n        this.privActivityTemplate = messagePayload;\n    }\n    get activityTemplate() {\n        return this.privActivityTemplate;\n    }\n    set audioOutputFormat(format) {\n        this.privAudioOutputFormat = format;\n        this.privSynthesisTurn.audioOutputFormat = format;\n        if (this.privSessionAudioDestination !== undefined) {\n            this.privSessionAudioDestination.format = format;\n        }\n        if (this.synthesisContext !== undefined) {\n            this.synthesisContext.audioOutputFormat = format;\n        }\n    }\n    static addHeader(audio, format) {\n        if (!format.hasHeader) {\n            return audio;\n        }\n        format.updateHeader(audio.byteLength);\n        const tmp = new Uint8Array(audio.byteLength + format.header.byteLength);\n        tmp.set(new Uint8Array(format.header), 0);\n        tmp.set(new Uint8Array(audio), format.header.byteLength);\n        return tmp.buffer;\n    }\n    isDisposed() {\n        return this.privIsDisposed;\n    }\n    dispose(reason) {\n        return __awaiter(this, void 0, void 0, function* () {\n            this.privIsDisposed = true;\n            if (this.privSessionAudioDestination !== undefined) {\n                this.privSessionAudioDestination.close();\n            }\n            if (this.privConnectionConfigurationPromise !== undefined) {\n                const connection = yield this.privConnectionConfigurationPromise;\n                yield connection.dispose(reason);\n            }\n        });\n    }\n    connect() {\n        return __awaiter(this, void 0, void 0, function* () {\n            yield this.connectImpl();\n        });\n    }\n    sendNetworkMessage(path, payload) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const type = typeof payload === \"string\" ? _common_Exports__WEBPACK_IMPORTED_MODULE_7__.MessageType.Text : _common_Exports__WEBPACK_IMPORTED_MODULE_7__.MessageType.Binary;\n            const contentType = typeof payload === \"string\" ? \"application/json\" : \"\";\n            const connection = yield this.fetchConnection();\n            return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_8__.SpeechConnectionMessage(type, path, this.privSynthesisTurn.requestId, contentType, payload));\n        });\n    }\n    Speak(text, isSSML, requestId, successCallback, errorCallBack, audioDestination) {\n        return __awaiter(this, void 0, void 0, function* () {\n            let ssml;\n            if (isSSML) {\n                ssml = text;\n            }\n            else {\n                ssml = this.privSpeechSynthesizer.buildSsml(text);\n            }\n            if (this.speakOverride !== undefined) {\n                return this.speakOverride(ssml, requestId, successCallback, errorCallBack);\n            }\n            this.privSuccessCallback = successCallback;\n            this.privErrorCallback = errorCallBack;\n            this.privSynthesisTurn.startNewSynthesis(requestId, text, isSSML, audioDestination);\n            try {\n                yield this.connectImpl();\n                const connection = yield this.fetchConnection();\n                yield this.sendSynthesisContext(connection);\n                yield this.sendSsmlMessage(connection, ssml, requestId);\n                const synthesisStartEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.SpeechSynthesisEventArgs(new _sdk_Exports__WEBPACK_IMPORTED_MODULE_10__.SpeechSynthesisResult(requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_11__.ResultReason.SynthesizingAudioStarted));\n                if (!!this.privSpeechSynthesizer.synthesisStarted) {\n                    this.privSpeechSynthesizer.synthesisStarted(this.privSpeechSynthesizer, synthesisStartEventArgs);\n                }\n                void this.receiveMessage();\n            }\n            catch (e) {\n                this.cancelSynthesisLocal(_sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.CancellationReason.Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.CancellationErrorCode.ConnectionFailure, e);\n                return Promise.reject(e);\n            }\n        });\n    }\n    // Cancels synthesis.\n    cancelSynthesis(requestId, cancellationReason, errorCode, error) {\n        const properties = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_12__.PropertyCollection();\n        properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_13__.CancellationErrorCodePropertyName, _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.CancellationErrorCode[errorCode]);\n        const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_10__.SpeechSynthesisResult(requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_11__.ResultReason.Canceled, undefined, error, properties);\n        if (!!this.privSpeechSynthesizer.SynthesisCanceled) {\n            const cancelEvent = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.SpeechSynthesisEventArgs(result);\n            try {\n                this.privSpeechSynthesizer.SynthesisCanceled(this.privSpeechSynthesizer, cancelEvent);\n                /* eslint-disable no-empty */\n            }\n            catch (_a) { }\n        }\n        if (!!this.privSuccessCallback) {\n            try {\n                this.privSuccessCallback(result);\n                /* eslint-disable no-empty */\n            }\n            catch (_b) { }\n        }\n    }\n    // Cancels synthesis.\n    cancelSynthesisLocal(cancellationReason, errorCode, error) {\n        if (!!this.privSynthesisTurn.isSynthesizing) {\n            this.privSynthesisTurn.onStopSynthesizing();\n            this.cancelSynthesis(this.privSynthesisTurn.requestId, cancellationReason, errorCode, error);\n        }\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    processTypeSpecificMessages(connectionMessage) {\n        return true;\n    }\n    receiveMessage() {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                const connection = yield this.fetchConnection();\n                const message = yield connection.read();\n                if (this.receiveMessageOverride !== undefined) {\n                    return this.receiveMessageOverride();\n                }\n                if (this.privIsDisposed) {\n                    // We're done.\n                    return;\n                }\n                // indicates we are draining the queue and it came with no message;\n                if (!message) {\n                    if (!this.privSynthesisTurn.isSynthesizing) {\n                        return;\n                    }\n                    else {\n                        return this.receiveMessage();\n                    }\n                }\n                const connectionMessage = _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_8__.SpeechConnectionMessage.fromConnectionMessage(message);\n                if (connectionMessage.requestId.toLowerCase() === this.privSynthesisTurn.requestId.toLowerCase()) {\n                    switch (connectionMessage.path.toLowerCase()) {\n                        case \"turn.start\":\n                            this.privSynthesisTurn.onServiceTurnStartResponse();\n                            break;\n                        case \"response\":\n                            this.privSynthesisTurn.onServiceResponseMessage(connectionMessage.textBody);\n                            break;\n                        case \"audio\":\n                            if (this.privSynthesisTurn.streamId.toLowerCase() === connectionMessage.streamId.toLowerCase()\n                                && !!connectionMessage.binaryBody) {\n                                this.privSynthesisTurn.onAudioChunkReceived(connectionMessage.binaryBody);\n                                if (!!this.privSpeechSynthesizer.synthesizing) {\n                                    try {\n                                        const audioWithHeader = SynthesisAdapterBase.addHeader(connectionMessage.binaryBody, this.privSynthesisTurn.audioOutputFormat);\n                                        const ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.SpeechSynthesisEventArgs(new _sdk_Exports__WEBPACK_IMPORTED_MODULE_10__.SpeechSynthesisResult(this.privSynthesisTurn.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_11__.ResultReason.SynthesizingAudio, audioWithHeader));\n                                        this.privSpeechSynthesizer.synthesizing(this.privSpeechSynthesizer, ev);\n                                    }\n                                    catch (error) {\n                                        // Not going to let errors in the event handler\n                                        // trip things up.\n                                    }\n                                }\n                                if (this.privSessionAudioDestination !== undefined) {\n                                    this.privSessionAudioDestination.write(connectionMessage.binaryBody);\n                                }\n                            }\n                            break;\n                        case \"audio.metadata\":\n                            const metadataList = _Exports__WEBPACK_IMPORTED_MODULE_14__.SynthesisAudioMetadata.fromJSON(connectionMessage.textBody).Metadata;\n                            for (const metadata of metadataList) {\n                                switch (metadata.Type) {\n                                    case _Exports__WEBPACK_IMPORTED_MODULE_14__.MetadataType.WordBoundary:\n                                    case _Exports__WEBPACK_IMPORTED_MODULE_14__.MetadataType.SentenceBoundary:\n                                        this.privSynthesisTurn.onTextBoundaryEvent(metadata);\n                                        const wordBoundaryEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_15__.SpeechSynthesisWordBoundaryEventArgs(metadata.Data.Offset, metadata.Data.Duration, metadata.Data.text.Text, metadata.Data.text.Length, metadata.Type === _Exports__WEBPACK_IMPORTED_MODULE_14__.MetadataType.WordBoundary\n                                            ? this.privSynthesisTurn.currentTextOffset : this.privSynthesisTurn.currentSentenceOffset, metadata.Data.text.BoundaryType);\n                                        if (!!this.privSpeechSynthesizer.wordBoundary) {\n                                            try {\n                                                this.privSpeechSynthesizer.wordBoundary(this.privSpeechSynthesizer, wordBoundaryEventArgs);\n                                            }\n                                            catch (error) {\n                                                // Not going to let errors in the event handler\n                                                // trip things up.\n                                            }\n                                        }\n                                        break;\n                                    case _Exports__WEBPACK_IMPORTED_MODULE_14__.MetadataType.Bookmark:\n                                        const bookmarkEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_16__.SpeechSynthesisBookmarkEventArgs(metadata.Data.Offset, metadata.Data.Bookmark);\n                                        if (!!this.privSpeechSynthesizer.bookmarkReached) {\n                                            try {\n                                                this.privSpeechSynthesizer.bookmarkReached(this.privSpeechSynthesizer, bookmarkEventArgs);\n                                            }\n                                            catch (error) {\n                                                // Not going to let errors in the event handler\n                                                // trip things up.\n                                            }\n                                        }\n                                        break;\n                                    case _Exports__WEBPACK_IMPORTED_MODULE_14__.MetadataType.Viseme:\n                                        this.privSynthesisTurn.onVisemeMetadataReceived(metadata);\n                                        if (metadata.Data.IsLastAnimation) {\n                                            const visemeEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_17__.SpeechSynthesisVisemeEventArgs(metadata.Data.Offset, metadata.Data.VisemeId, this.privSynthesisTurn.getAndClearVisemeAnimation());\n                                            if (!!this.privSpeechSynthesizer.visemeReceived) {\n                                                try {\n                                                    this.privSpeechSynthesizer.visemeReceived(this.privSpeechSynthesizer, visemeEventArgs);\n                                                }\n                                                catch (error) {\n                                                    // Not going to let errors in the event handler\n                                                    // trip things up.\n                                                }\n                                            }\n                                        }\n                                        break;\n                                    case _Exports__WEBPACK_IMPORTED_MODULE_14__.MetadataType.SessionEnd:\n                                        this.privSynthesisTurn.onSessionEnd(metadata);\n                                        break;\n                                }\n                            }\n                            break;\n                        case \"turn.end\":\n                            this.privSynthesisTurn.onServiceTurnEndResponse();\n                            let result;\n                            try {\n                                const audioBuffer = yield this.privSynthesisTurn.getAllReceivedAudioWithHeader();\n                                result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_10__.SpeechSynthesisResult(this.privSynthesisTurn.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_11__.ResultReason.SynthesizingAudioCompleted, audioBuffer, undefined, undefined, this.privSynthesisTurn.audioDuration);\n                                if (!!this.privSuccessCallback) {\n                                    this.privSuccessCallback(result);\n                                }\n                            }\n                            catch (error) {\n                                if (!!this.privErrorCallback) {\n                                    this.privErrorCallback(error);\n                                }\n                            }\n                            if (this.privSpeechSynthesizer.synthesisCompleted) {\n                                try {\n                                    this.privSpeechSynthesizer.synthesisCompleted(this.privSpeechSynthesizer, new _sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.SpeechSynthesisEventArgs(result));\n                                }\n                                catch (e) {\n                                    // Not going to let errors in the event handler\n                                    // trip things up.\n                                }\n                            }\n                            break;\n                        default:\n                            if (!this.processTypeSpecificMessages(connectionMessage)) {\n                                // here are some messages that the derived class has not processed, dispatch them to connect class\n                                if (!!this.privServiceEvents) {\n                                    this.serviceEvents.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_18__.ServiceEvent(connectionMessage.path.toLowerCase(), connectionMessage.textBody));\n                                }\n                            }\n                    }\n                }\n                return this.receiveMessage();\n            }\n            catch (e) {\n                // TODO: What goes here?\n            }\n        });\n    }\n    sendSynthesisContext(connection) {\n        const synthesisContextJson = this.synthesisContext.toJSON();\n        if (synthesisContextJson) {\n            return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_8__.SpeechConnectionMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_7__.MessageType.Text, \"synthesis.context\", this.privSynthesisTurn.requestId, \"application/json\", synthesisContextJson));\n        }\n        return;\n    }\n    connectImpl(isUnAuthorized = false) {\n        if (this.privConnectionPromise != null) {\n            return this.privConnectionPromise.then((connection) => {\n                if (connection.state() === _common_Exports__WEBPACK_IMPORTED_MODULE_19__.ConnectionState.Disconnected) {\n                    this.privConnectionId = null;\n                    this.privConnectionPromise = null;\n                    return this.connectImpl();\n                }\n                return this.privConnectionPromise;\n            }, () => {\n                this.privConnectionId = null;\n                this.privConnectionPromise = null;\n                return this.connectImpl();\n            });\n        }\n        this.privAuthFetchEventId = (0,_common_Exports__WEBPACK_IMPORTED_MODULE_20__.createNoDashGuid)();\n        this.privConnectionId = (0,_common_Exports__WEBPACK_IMPORTED_MODULE_20__.createNoDashGuid)();\n        this.privSynthesisTurn.onPreConnectionStart(this.privAuthFetchEventId);\n        const authPromise = isUnAuthorized ? this.privAuthentication.fetchOnExpiry(this.privAuthFetchEventId) : this.privAuthentication.fetch(this.privAuthFetchEventId);\n        this.privConnectionPromise = authPromise.then((result) => __awaiter(this, void 0, void 0, function* () {\n            this.privSynthesisTurn.onAuthCompleted(false);\n            const connection = this.privConnectionFactory.create(this.privSynthesizerConfig, result, this.privConnectionId);\n            // Attach to the underlying event. No need to hold onto the detach pointers as in the event the connection goes away,\n            // it'll stop sending events.\n            connection.events.attach((event) => {\n                this.connectionEvents.onEvent(event);\n            });\n            const response = yield connection.open();\n            if (response.statusCode === 200) {\n                this.privSynthesisTurn.onConnectionEstablishCompleted(response.statusCode);\n                return Promise.resolve(connection);\n            }\n            else if (response.statusCode === 403 && !isUnAuthorized) {\n                return this.connectImpl(true);\n            }\n            else {\n                this.privSynthesisTurn.onConnectionEstablishCompleted(response.statusCode);\n                return Promise.reject(`Unable to contact server. StatusCode: ${response.statusCode}, ${this.privSynthesizerConfig.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_21__.PropertyId.SpeechServiceConnection_Endpoint)} Reason: ${response.reason}`);\n            }\n        }), (error) => {\n            this.privSynthesisTurn.onAuthCompleted(true);\n            throw new Error(error);\n        });\n        // Attach an empty handler to allow the promise to run in the background while\n        // other startup events happen. It'll eventually be awaited on.\n        // eslint-disable-next-line @typescript-eslint/no-empty-function\n        this.privConnectionPromise.catch(() => { });\n        return this.privConnectionPromise;\n    }\n    sendSpeechServiceConfig(connection, SpeechServiceConfigJson) {\n        if (SpeechServiceConfigJson) {\n            return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_8__.SpeechConnectionMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_7__.MessageType.Text, \"speech.config\", this.privSynthesisTurn.requestId, \"application/json\", SpeechServiceConfigJson));\n        }\n    }\n    sendSsmlMessage(connection, ssml, requestId) {\n        return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_8__.SpeechConnectionMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_7__.MessageType.Text, \"ssml\", requestId, \"application/ssml+xml\", ssml));\n    }\n    fetchConnection() {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (this.privConnectionConfigurationPromise !== undefined) {\n                return this.privConnectionConfigurationPromise.then((connection) => {\n                    if (connection.state() === _common_Exports__WEBPACK_IMPORTED_MODULE_19__.ConnectionState.Disconnected) {\n                        this.privConnectionId = null;\n                        this.privConnectionConfigurationPromise = undefined;\n                        return this.fetchConnection();\n                    }\n                    return this.privConnectionConfigurationPromise;\n                }, () => {\n                    this.privConnectionId = null;\n                    this.privConnectionConfigurationPromise = undefined;\n                    return this.fetchConnection();\n                });\n            }\n            this.privConnectionConfigurationPromise = this.configureConnection();\n            return yield this.privConnectionConfigurationPromise;\n        });\n    }\n    // Takes an established websocket connection to the endpoint and sends speech configuration information.\n    configureConnection() {\n        return __awaiter(this, void 0, void 0, function* () {\n            const connection = yield this.connectImpl();\n            if (this.configConnectionOverride !== undefined) {\n                return this.configConnectionOverride(connection);\n            }\n            yield this.sendSpeechServiceConfig(connection, this.privSynthesizerConfig.SpeechServiceConfig.serialize());\n            return connection;\n        });\n    }\n}\nSynthesisAdapterBase.telemetryDataEnabled = true;\n\n//# sourceMappingURL=SynthesisAdapterBase.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisAdapterBase.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisContext.js":
  /*!******************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisContext.js ***!
    \******************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SynthesisContext\": () => (/* binding */ SynthesisContext)\n/* harmony export */ });\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Represents the JSON used in the synthesis.context message sent to the speech service.\n * The dynamic grammar is always refreshed from the encapsulated dynamic grammar object.\n */\nclass SynthesisContext {\n    constructor(speechSynthesizer) {\n        this.privContext = {};\n        this.privSpeechSynthesizer = speechSynthesizer;\n    }\n    /**\n     * Adds a section to the synthesis.context object.\n     * @param sectionName Name of the section to add.\n     * @param value JSON serializable object that represents the value.\n     */\n    setSection(sectionName, value) {\n        this.privContext[sectionName] = value;\n    }\n    /**\n     * Sets the audio output format for synthesis context generation.\n     * @param format {AudioOutputFormatImpl} the output format\n     */\n    set audioOutputFormat(format) {\n        this.privAudioOutputFormat = format;\n    }\n    toJSON() {\n        const synthesisSection = this.buildSynthesisContext();\n        this.setSection(\"synthesis\", synthesisSection);\n        return JSON.stringify(this.privContext);\n    }\n    buildSynthesisContext() {\n        return {\n            audio: {\n                metadataOptions: {\n                    bookmarkEnabled: (!!this.privSpeechSynthesizer.bookmarkReached),\n                    punctuationBoundaryEnabled: this.privSpeechSynthesizer.properties.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceResponse_RequestPunctuationBoundary, (!!this.privSpeechSynthesizer.wordBoundary)),\n                    sentenceBoundaryEnabled: this.privSpeechSynthesizer.properties.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceResponse_RequestSentenceBoundary, false),\n                    sessionEndEnabled: true,\n                    visemeEnabled: (!!this.privSpeechSynthesizer.visemeReceived),\n                    wordBoundaryEnabled: this.privSpeechSynthesizer.properties.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceResponse_RequestWordBoundary, (!!this.privSpeechSynthesizer.wordBoundary)),\n                },\n                outputFormat: this.privAudioOutputFormat.requestAudioFormatString,\n            },\n            language: {\n                autoDetection: this.privSpeechSynthesizer.autoDetectSourceLanguage\n            }\n        };\n    }\n}\n\n//# sourceMappingURL=SynthesisContext.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisContext.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisEvents.js":
  /*!*****************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisEvents.js ***!
    \*****************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConnectingToSynthesisServiceEvent\": () => (/* binding */ ConnectingToSynthesisServiceEvent),\n/* harmony export */   \"SpeechSynthesisEvent\": () => (/* binding */ SpeechSynthesisEvent),\n/* harmony export */   \"SynthesisStartedEvent\": () => (/* binding */ SynthesisStartedEvent),\n/* harmony export */   \"SynthesisTriggeredEvent\": () => (/* binding */ SynthesisTriggeredEvent)\n/* harmony export */ });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/PlatformEvent.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/* eslint-disable max-classes-per-file */\n\nclass SpeechSynthesisEvent extends _common_Exports__WEBPACK_IMPORTED_MODULE_0__.PlatformEvent {\n    constructor(eventName, requestId, eventType = _common_Exports__WEBPACK_IMPORTED_MODULE_0__.EventType.Info) {\n        super(eventName, eventType);\n        this.privRequestId = requestId;\n    }\n    get requestId() {\n        return this.privRequestId;\n    }\n}\nclass SynthesisTriggeredEvent extends SpeechSynthesisEvent {\n    constructor(requestId, sessionAudioDestinationId, turnAudioDestinationId) {\n        super(\"SynthesisTriggeredEvent\", requestId);\n        this.privSessionAudioDestinationId = sessionAudioDestinationId;\n        this.privTurnAudioDestinationId = turnAudioDestinationId;\n    }\n    get audioSessionDestinationId() {\n        return this.privSessionAudioDestinationId;\n    }\n    get audioTurnDestinationId() {\n        return this.privTurnAudioDestinationId;\n    }\n}\nclass ConnectingToSynthesisServiceEvent extends SpeechSynthesisEvent {\n    constructor(requestId, authFetchEventId) {\n        super(\"ConnectingToSynthesisServiceEvent\", requestId);\n        this.privAuthFetchEventId = authFetchEventId;\n    }\n    get authFetchEventId() {\n        return this.privAuthFetchEventId;\n    }\n}\nclass SynthesisStartedEvent extends SpeechSynthesisEvent {\n    constructor(requestId, authFetchEventId) {\n        super(\"SynthesisStartedEvent\", requestId);\n        this.privAuthFetchEventId = authFetchEventId;\n    }\n    get authFetchEventId() {\n        return this.privAuthFetchEventId;\n    }\n}\n\n//# sourceMappingURL=SynthesisEvents.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisEvents.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisRestAdapter.js":
  /*!**********************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisRestAdapter.js ***!
    \**********************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SynthesisRestAdapter\": () => (/* binding */ SynthesisRestAdapter)\n/* harmony export */ });\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/RestConfigBase.js\");\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/RestMessageAdapter.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./ConnectionFactoryBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js\");\n/* harmony import */ var _HeaderNames__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./HeaderNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js\");\n\n\n\n\n/**\n * Implements methods for speaker recognition classes, sending requests to endpoint\n * and parsing response into expected format\n * @class SynthesisRestAdapter\n */\nclass SynthesisRestAdapter {\n    constructor(config, authentication) {\n        let endpoint = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_Endpoint, undefined);\n        if (!endpoint) {\n            const region = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_Region, \"westus\");\n            const hostSuffix = _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_1__.ConnectionFactoryBase.getHostSuffix(region);\n            endpoint = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_Host, `https://${region}.tts.speech${hostSuffix}`);\n        }\n        this.privUri = `${endpoint}/cognitiveservices/voices/list`;\n        const options = _common_browser_Exports__WEBPACK_IMPORTED_MODULE_2__.RestConfigBase.requestOptions;\n        this.privRestAdapter = new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_3__.RestMessageAdapter(options);\n        this.privAuthentication = authentication;\n    }\n    /**\n     * Sends list voices request to endpoint.\n     * @function\n     * @public\n     * @param connectionId - guid for connectionId\n     * @returns {Promise<IRestResponse>} rest response to status request\n     */\n    getVoicesList(connectionId) {\n        this.privRestAdapter.setHeaders(_HeaderNames__WEBPACK_IMPORTED_MODULE_4__.HeaderNames.ConnectionId, connectionId);\n        return this.privAuthentication.fetch(connectionId).then((authInfo) => {\n            this.privRestAdapter.setHeaders(authInfo.headerName, authInfo.token);\n            return this.privRestAdapter.request(_common_browser_Exports__WEBPACK_IMPORTED_MODULE_3__.RestRequestType.Get, this.privUri);\n        });\n    }\n}\n\n//# sourceMappingURL=SynthesisRestAdapter.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisRestAdapter.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisTurn.js":
  /*!***************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisTurn.js ***!
    \***************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SynthesisTurn\": () => (/* binding */ SynthesisTurn)\n/* harmony export */ });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Events.js\");\n/* harmony import */ var _sdk_Audio_AudioOutputStream__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../sdk/Audio/AudioOutputStream */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputStream.js\");\n/* harmony import */ var _ServiceMessages_SynthesisAudioMetadata__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./ServiceMessages/SynthesisAudioMetadata */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SynthesisAudioMetadata.js\");\n/* harmony import */ var _SynthesisAdapterBase__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./SynthesisAdapterBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisAdapterBase.js\");\n/* harmony import */ var _SynthesisEvents__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./SynthesisEvents */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisEvents.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\n\n\nclass SynthesisTurn {\n    constructor() {\n        this.privIsDisposed = false;\n        this.privIsSynthesizing = false;\n        this.privIsSynthesisEnded = false;\n        this.privBytesReceived = 0;\n        this.privInTurn = false;\n        this.privTextOffset = 0;\n        this.privNextSearchTextIndex = 0;\n        this.privSentenceOffset = 0;\n        this.privNextSearchSentenceIndex = 0;\n        this.privRequestId = (0,_common_Exports__WEBPACK_IMPORTED_MODULE_0__.createNoDashGuid)();\n        this.privTurnDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.Deferred();\n        // We're not in a turn, so resolve.\n        this.privTurnDeferral.resolve();\n    }\n    get requestId() {\n        return this.privRequestId;\n    }\n    get streamId() {\n        return this.privStreamId;\n    }\n    set streamId(value) {\n        this.privStreamId = value;\n    }\n    get audioOutputFormat() {\n        return this.privAudioOutputFormat;\n    }\n    set audioOutputFormat(format) {\n        this.privAudioOutputFormat = format;\n    }\n    get turnCompletionPromise() {\n        return this.privTurnDeferral.promise;\n    }\n    get isSynthesisEnded() {\n        return this.privIsSynthesisEnded;\n    }\n    get isSynthesizing() {\n        return this.privIsSynthesizing;\n    }\n    get currentTextOffset() {\n        return this.privTextOffset;\n    }\n    get currentSentenceOffset() {\n        return this.privSentenceOffset;\n    }\n    // The number of bytes received for current turn\n    get bytesReceived() {\n        return this.privBytesReceived;\n    }\n    get audioDuration() {\n        return this.privAudioDuration;\n    }\n    getAllReceivedAudio() {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (!!this.privReceivedAudio) {\n                return Promise.resolve(this.privReceivedAudio);\n            }\n            if (!this.privIsSynthesisEnded) {\n                return null;\n            }\n            yield this.readAllAudioFromStream();\n            return Promise.resolve(this.privReceivedAudio);\n        });\n    }\n    getAllReceivedAudioWithHeader() {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (!!this.privReceivedAudioWithHeader) {\n                return this.privReceivedAudioWithHeader;\n            }\n            if (!this.privIsSynthesisEnded) {\n                return null;\n            }\n            if (this.audioOutputFormat.hasHeader) {\n                const audio = yield this.getAllReceivedAudio();\n                this.privReceivedAudioWithHeader = _SynthesisAdapterBase__WEBPACK_IMPORTED_MODULE_2__.SynthesisAdapterBase.addHeader(audio, this.audioOutputFormat);\n                return this.privReceivedAudioWithHeader;\n            }\n            else {\n                return this.getAllReceivedAudio();\n            }\n        });\n    }\n    startNewSynthesis(requestId, rawText, isSSML, audioDestination) {\n        this.privIsSynthesisEnded = false;\n        this.privIsSynthesizing = true;\n        this.privRequestId = requestId;\n        this.privRawText = rawText;\n        this.privIsSSML = isSSML;\n        this.privAudioOutputStream = new _sdk_Audio_AudioOutputStream__WEBPACK_IMPORTED_MODULE_3__.PullAudioOutputStreamImpl();\n        this.privAudioOutputStream.format = this.privAudioOutputFormat;\n        this.privReceivedAudio = null;\n        this.privReceivedAudioWithHeader = null;\n        this.privBytesReceived = 0;\n        this.privTextOffset = 0;\n        this.privNextSearchTextIndex = 0;\n        this.privSentenceOffset = 0;\n        this.privNextSearchSentenceIndex = 0;\n        this.privPartialVisemeAnimation = \"\";\n        if (audioDestination !== undefined) {\n            this.privTurnAudioDestination = audioDestination;\n            this.privTurnAudioDestination.format = this.privAudioOutputFormat;\n        }\n        this.onEvent(new _SynthesisEvents__WEBPACK_IMPORTED_MODULE_4__.SynthesisTriggeredEvent(this.requestId, undefined, audioDestination === undefined ? undefined : audioDestination.id()));\n    }\n    onPreConnectionStart(authFetchEventId) {\n        this.privAuthFetchEventId = authFetchEventId;\n        this.onEvent(new _SynthesisEvents__WEBPACK_IMPORTED_MODULE_4__.ConnectingToSynthesisServiceEvent(this.privRequestId, this.privAuthFetchEventId));\n    }\n    onAuthCompleted(isError) {\n        if (isError) {\n            this.onComplete();\n        }\n    }\n    onConnectionEstablishCompleted(statusCode) {\n        if (statusCode === 200) {\n            this.onEvent(new _SynthesisEvents__WEBPACK_IMPORTED_MODULE_4__.SynthesisStartedEvent(this.requestId, this.privAuthFetchEventId));\n            this.privBytesReceived = 0;\n            return;\n        }\n        else if (statusCode === 403) {\n            this.onComplete();\n        }\n    }\n    onServiceResponseMessage(responseJson) {\n        const response = JSON.parse(responseJson);\n        this.streamId = response.audio.streamId;\n    }\n    onServiceTurnEndResponse() {\n        this.privInTurn = false;\n        this.privTurnDeferral.resolve();\n        this.onComplete();\n    }\n    onServiceTurnStartResponse() {\n        if (!!this.privTurnDeferral && !!this.privInTurn) {\n            // What? How are we starting a turn with another not done?\n            this.privTurnDeferral.reject(\"Another turn started before current completed.\");\n            // Avoid UnhandledPromiseRejection if privTurnDeferral is not being awaited\n            // eslint-disable-next-line @typescript-eslint/no-empty-function\n            this.privTurnDeferral.promise.then().catch(() => { });\n        }\n        this.privInTurn = true;\n        this.privTurnDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.Deferred();\n    }\n    onAudioChunkReceived(data) {\n        if (this.isSynthesizing) {\n            this.privAudioOutputStream.write(data);\n            this.privBytesReceived += data.byteLength;\n            if (this.privTurnAudioDestination !== undefined) {\n                this.privTurnAudioDestination.write(data);\n            }\n        }\n    }\n    onTextBoundaryEvent(metadata) {\n        this.updateTextOffset(metadata.Data.text.Text, metadata.Type);\n    }\n    onVisemeMetadataReceived(metadata) {\n        if (metadata.Data.AnimationChunk !== undefined) {\n            this.privPartialVisemeAnimation += metadata.Data.AnimationChunk;\n        }\n    }\n    onSessionEnd(metadata) {\n        this.privAudioDuration = metadata.Data.Offset;\n    }\n    dispose() {\n        if (!this.privIsDisposed) {\n            // we should have completed by now. If we did not its an unknown error.\n            this.privIsDisposed = true;\n        }\n    }\n    onStopSynthesizing() {\n        this.onComplete();\n    }\n    /**\n     * Gets the viseme animation string (merged from animation chunk), and clears the internal\n     * partial animation.\n     */\n    getAndClearVisemeAnimation() {\n        const animation = this.privPartialVisemeAnimation;\n        this.privPartialVisemeAnimation = \"\";\n        return animation;\n    }\n    onEvent(event) {\n        _common_Exports__WEBPACK_IMPORTED_MODULE_5__.Events.instance.onEvent(event);\n    }\n    /**\n     * Check if the text is an XML(SSML) tag\n     * @param text\n     * @private\n     */\n    static isXmlTag(text) {\n        return text.length >= 2 && text[0] === \"<\" && text[text.length - 1] === \">\";\n    }\n    updateTextOffset(text, type) {\n        if (type === _ServiceMessages_SynthesisAudioMetadata__WEBPACK_IMPORTED_MODULE_6__.MetadataType.WordBoundary) {\n            this.privTextOffset = this.privRawText.indexOf(text, this.privNextSearchTextIndex);\n            if (this.privTextOffset >= 0) {\n                this.privNextSearchTextIndex = this.privTextOffset + text.length;\n                if (this.privIsSSML) {\n                    if (this.withinXmlTag(this.privTextOffset) && !SynthesisTurn.isXmlTag(text)) {\n                        this.updateTextOffset(text, type);\n                    }\n                }\n            }\n        }\n        else {\n            this.privSentenceOffset = this.privRawText.indexOf(text, this.privNextSearchSentenceIndex);\n            if (this.privSentenceOffset >= 0) {\n                this.privNextSearchSentenceIndex = this.privSentenceOffset + text.length;\n                if (this.privIsSSML) {\n                    if (this.withinXmlTag(this.privSentenceOffset) && !SynthesisTurn.isXmlTag(text)) {\n                        this.updateTextOffset(text, type);\n                    }\n                }\n            }\n        }\n    }\n    onComplete() {\n        if (this.privIsSynthesizing) {\n            this.privIsSynthesizing = false;\n            this.privIsSynthesisEnded = true;\n            this.privAudioOutputStream.close();\n            this.privInTurn = false;\n            if (this.privTurnAudioDestination !== undefined) {\n                this.privTurnAudioDestination.close();\n                this.privTurnAudioDestination = undefined;\n            }\n        }\n    }\n    readAllAudioFromStream() {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (this.privIsSynthesisEnded) {\n                this.privReceivedAudio = new ArrayBuffer(this.bytesReceived);\n                try {\n                    yield this.privAudioOutputStream.read(this.privReceivedAudio);\n                }\n                catch (e) {\n                    this.privReceivedAudio = new ArrayBuffer(0);\n                }\n            }\n        });\n    }\n    /**\n     * Check if current idx is in XML(SSML) tag\n     * @param idx\n     * @private\n     */\n    withinXmlTag(idx) {\n        return this.privRawText.indexOf(\"<\", idx + 1) > this.privRawText.indexOf(\">\", idx + 1);\n    }\n}\n\n//# sourceMappingURL=SynthesisTurn.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisTurn.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesizerConfig.js":
  /*!*******************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesizerConfig.js ***!
    \*******************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SynthesisServiceType\": () => (/* binding */ SynthesisServiceType),\n/* harmony export */   \"SynthesizerConfig\": () => (/* binding */ SynthesizerConfig)\n/* harmony export */ });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nvar SynthesisServiceType;\n(function (SynthesisServiceType) {\n    SynthesisServiceType[SynthesisServiceType[\"Standard\"] = 0] = \"Standard\";\n    SynthesisServiceType[SynthesisServiceType[\"Custom\"] = 1] = \"Custom\";\n})(SynthesisServiceType || (SynthesisServiceType = {}));\nclass SynthesizerConfig {\n    constructor(speechServiceConfig, parameters) {\n        this.privSynthesisServiceType = SynthesisServiceType.Standard;\n        this.privSpeechServiceConfig = speechServiceConfig ? speechServiceConfig : new _Exports__WEBPACK_IMPORTED_MODULE_0__.SpeechServiceConfig(new _Exports__WEBPACK_IMPORTED_MODULE_0__.Context(null));\n        this.privParameters = parameters;\n    }\n    get parameters() {\n        return this.privParameters;\n    }\n    get synthesisServiceType() {\n        return this.privSynthesisServiceType;\n    }\n    set synthesisServiceType(value) {\n        this.privSynthesisServiceType = value;\n    }\n    get SpeechServiceConfig() {\n        return this.privSpeechServiceConfig;\n    }\n}\n\n//# sourceMappingURL=SynthesizerConfig.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesizerConfig.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranscriberConnectionFactory.js":
  /*!******************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranscriberConnectionFactory.js ***!
    \******************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"TranscriberConnectionFactory\": () => (/* binding */ TranscriberConnectionFactory)\n/* harmony export */ });\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketConnection.js\");\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ProxyInfo.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/OutputFormat.js\");\n/* harmony import */ var _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./ConnectionFactoryBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/WebsocketMessageFormatter.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _HeaderNames__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./HeaderNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js\");\n/* harmony import */ var _QueryParameterNames__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./QueryParameterNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/QueryParameterNames.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\n\n\n\nclass TranscriberConnectionFactory extends _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__.ConnectionFactoryBase {\n    constructor() {\n        super(...arguments);\n        this.multiaudioRelativeUri = \"/speech/recognition/multiaudio\";\n    }\n    create(config, authInfo, connectionId) {\n        let endpoint = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Endpoint, undefined);\n        const region = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Region, \"centralus\");\n        const hostSuffix = _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__.ConnectionFactoryBase.getHostSuffix(region);\n        const hostDefault = \"wss://transcribe.\" + region + \".cts.speech\" + hostSuffix + this.multiaudioRelativeUri;\n        const host = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Host, hostDefault);\n        const queryParams = {};\n        this.setQueryParams(queryParams, config, endpoint);\n        if (!endpoint) {\n            endpoint = host;\n        }\n        const headers = {};\n        if (authInfo.token !== undefined && authInfo.token !== \"\") {\n            headers[authInfo.headerName] = authInfo.token;\n        }\n        headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_2__.HeaderNames.ConnectionId] = connectionId;\n        config.parameters.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Url, endpoint);\n        const enableCompression = config.parameters.getProperty(\"SPEECH-EnableWebsocketCompression\", \"false\") === \"true\";\n        return new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_3__.WebsocketConnection(endpoint, queryParams, headers, new _Exports__WEBPACK_IMPORTED_MODULE_4__.WebsocketMessageFormatter(), _common_browser_Exports__WEBPACK_IMPORTED_MODULE_5__.ProxyInfo.fromRecognizerConfig(config), enableCompression, connectionId);\n    }\n    setQueryParams(queryParams, config, endpointUrl) {\n        const endpointId = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_EndpointId, undefined);\n        const language = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_RecoLanguage, undefined);\n        if (endpointId && !(_QueryParameterNames__WEBPACK_IMPORTED_MODULE_6__.QueryParameterNames.CustomSpeechDeploymentId in queryParams)) {\n            queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_6__.QueryParameterNames.CustomSpeechDeploymentId] = endpointId;\n        }\n        if (language && !(_QueryParameterNames__WEBPACK_IMPORTED_MODULE_6__.QueryParameterNames.Language in queryParams)) {\n            queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_6__.QueryParameterNames.Language] = language;\n        }\n        const wordLevelTimings = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceResponse_RequestWordLevelTimestamps, \"false\").toLowerCase() === \"true\";\n        const detailed = config.parameters.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_7__.OutputFormatPropertyName, _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__.OutputFormat[_sdk_Exports__WEBPACK_IMPORTED_MODULE_8__.OutputFormat.Simple]) !== _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__.OutputFormat[_sdk_Exports__WEBPACK_IMPORTED_MODULE_8__.OutputFormat.Simple];\n        if (wordLevelTimings || detailed) {\n            queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_6__.QueryParameterNames.Format] = _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__.OutputFormat[_sdk_Exports__WEBPACK_IMPORTED_MODULE_8__.OutputFormat.Detailed].toLowerCase();\n        }\n        this.setCommonUrlParams(config, queryParams, endpointUrl);\n    }\n}\n\n//# sourceMappingURL=TranscriberConnectionFactory.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranscriberConnectionFactory.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionConfig.js":
  /*!********************************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionConfig.js ***!
    \********************************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConversationConnectionConfig\": () => (/* binding */ ConversationConnectionConfig)\n/* harmony export */ });\n/* harmony import */ var _common_browser_RestConfigBase__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common.browser/RestConfigBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/RestConfigBase.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nclass ConversationConnectionConfig extends _common_browser_RestConfigBase__WEBPACK_IMPORTED_MODULE_0__.RestConfigBase {\n    static get host() {\n        return ConversationConnectionConfig.privHost;\n    }\n    static get apiVersion() {\n        return ConversationConnectionConfig.privApiVersion;\n    }\n    static get clientAppId() {\n        return ConversationConnectionConfig.privClientAppId;\n    }\n    static get defaultLanguageCode() {\n        return ConversationConnectionConfig.privDefaultLanguageCode;\n    }\n    static get restPath() {\n        return ConversationConnectionConfig.privRestPath;\n    }\n    static get webSocketPath() {\n        return ConversationConnectionConfig.privWebSocketPath;\n    }\n    static get transcriptionEventKeys() {\n        return ConversationConnectionConfig.privTranscriptionEventKeys;\n    }\n}\nConversationConnectionConfig.privHost = \"dev.microsofttranslator.com\";\nConversationConnectionConfig.privRestPath = \"/capito/room\";\nConversationConnectionConfig.privApiVersion = \"2.0\";\nConversationConnectionConfig.privDefaultLanguageCode = \"en-US\";\nConversationConnectionConfig.privClientAppId = \"FC539C22-1767-4F1F-84BC-B4D811114F15\";\nConversationConnectionConfig.privWebSocketPath = \"/capito/translate\";\nConversationConnectionConfig.privTranscriptionEventKeys = [\"iCalUid\", \"callId\", \"organizer\", \"FLAC\", \"MTUri\", \"DifferentiateGuestSpeakers\", \"audiorecording\", \"Threadid\", \"OrganizerMri\", \"OrganizerTenantId\", \"UserToken\"];\n\n//# sourceMappingURL=ConversationConnectionConfig.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionConfig.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionFactory.js":
  /*!*********************************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionFactory.js ***!
    \*********************************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConversationConnectionFactory\": () => (/* binding */ ConversationConnectionFactory)\n/* harmony export */ });\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketConnection.js\");\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ProxyInfo.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js\");\n/* harmony import */ var _sdk_Contracts__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../sdk/Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../ConnectionFactoryBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js\");\n/* harmony import */ var _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ConversationConnectionConfig */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionConfig.js\");\n/* harmony import */ var _ConversationWebsocketMessageFormatter__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./ConversationWebsocketMessageFormatter */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationWebsocketMessageFormatter.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\n\n\n\n\n/**\n * Create a connection to the Conversation Translator websocket for sending instant messages and commands, and for receiving translated messages.\n * The conversation must already have been started or joined.\n */\nclass ConversationConnectionFactory extends _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__.ConnectionFactoryBase {\n    create(config, authInfo, connectionId) {\n        const endpointHost = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.ConversationTranslator_Host, _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_2__.ConversationConnectionConfig.host);\n        const correlationId = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.ConversationTranslator_CorrelationId, (0,_common_Exports__WEBPACK_IMPORTED_MODULE_3__.createGuid)());\n        const endpoint = `wss://${endpointHost}${_ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_2__.ConversationConnectionConfig.webSocketPath}`;\n        const token = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.ConversationTranslator_Token, undefined);\n        _sdk_Contracts__WEBPACK_IMPORTED_MODULE_4__.Contracts.throwIfNullOrUndefined(token, \"token\");\n        const queryParams = {};\n        queryParams[_ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_2__.ConversationConnectionConfig.configParams.apiVersion] = _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_2__.ConversationConnectionConfig.apiVersion;\n        queryParams[_ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_2__.ConversationConnectionConfig.configParams.token] = token;\n        queryParams[_ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_2__.ConversationConnectionConfig.configParams.correlationId] = correlationId;\n        const enableCompression = config.parameters.getProperty(\"SPEECH-EnableWebsocketCompression\", \"false\") === \"true\";\n        return new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_5__.WebsocketConnection(endpoint, queryParams, {}, new _ConversationWebsocketMessageFormatter__WEBPACK_IMPORTED_MODULE_6__.ConversationWebsocketMessageFormatter(), _common_browser_Exports__WEBPACK_IMPORTED_MODULE_7__.ProxyInfo.fromRecognizerConfig(config), enableCompression, connectionId);\n    }\n}\n\n//# sourceMappingURL=ConversationConnectionFactory.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionFactory.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionMessage.js":
  /*!*********************************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionMessage.js ***!
    \*********************************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConversationConnectionMessage\": () => (/* binding */ ConversationConnectionMessage)\n/* harmony export */ });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nclass ConversationConnectionMessage extends _common_Exports__WEBPACK_IMPORTED_MODULE_0__.ConnectionMessage {\n    constructor(messageType, body, headers, id) {\n        super(messageType, body, headers, id);\n        const json = JSON.parse(this.textBody);\n        if (json.type !== undefined) {\n            this.privConversationMessageType = json.type;\n        }\n    }\n    get conversationMessageType() {\n        return this.privConversationMessageType;\n    }\n}\n\n//# sourceMappingURL=ConversationConnectionMessage.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionMessage.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationManager.js":
  /*!***********************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationManager.js ***!
    \***********************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConversationManager\": () => (/* binding */ ConversationManager)\n/* harmony export */ });\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/RestMessageAdapter.js\");\n/* harmony import */ var _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../sdk/Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./ConversationConnectionConfig */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionConfig.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\n\nclass ConversationManager {\n    constructor() {\n        //\n        this.privRequestParams = _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_0__.ConversationConnectionConfig.configParams;\n        this.privErrors = _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_0__.ConversationConnectionConfig.restErrors;\n        this.privHost = _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_0__.ConversationConnectionConfig.host;\n        this.privApiVersion = _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_0__.ConversationConnectionConfig.apiVersion;\n        this.privRestPath = _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_0__.ConversationConnectionConfig.restPath;\n        this.privRestAdapter = new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_1__.RestMessageAdapter({});\n    }\n    /**\n     * Make a POST request to the Conversation Manager service endpoint to create or join a conversation.\n     * @param args\n     * @param conversationCode\n     * @param callback\n     * @param errorCallback\n     */\n    createOrJoin(args, conversationCode, cb, err) {\n        try {\n            _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__.Contracts.throwIfNullOrUndefined(args, \"args\");\n            const languageCode = args.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_RecoLanguage, _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_0__.ConversationConnectionConfig.defaultLanguageCode);\n            const nickname = args.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.ConversationTranslator_Name, \"conversation_host\");\n            const endpointHost = args.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.ConversationTranslator_Host, this.privHost);\n            const correlationId = args.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.ConversationTranslator_CorrelationId);\n            const subscriptionKey = args.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_Key);\n            const subscriptionRegion = args.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_Region);\n            const authToken = args.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceAuthorization_Token);\n            _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__.Contracts.throwIfNullOrWhitespace(languageCode, \"languageCode\");\n            _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__.Contracts.throwIfNullOrWhitespace(nickname, \"nickname\");\n            _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__.Contracts.throwIfNullOrWhitespace(endpointHost, \"endpointHost\");\n            const queryParams = {};\n            queryParams[this.privRequestParams.apiVersion] = this.privApiVersion;\n            queryParams[this.privRequestParams.languageCode] = languageCode;\n            queryParams[this.privRequestParams.nickname] = nickname;\n            const headers = {};\n            if (correlationId) {\n                headers[this.privRequestParams.correlationId] = correlationId;\n            }\n            headers[this.privRequestParams.clientAppId] = _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_0__.ConversationConnectionConfig.clientAppId;\n            if (conversationCode !== undefined) {\n                queryParams[this.privRequestParams.roomId] = conversationCode;\n            }\n            else {\n                _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__.Contracts.throwIfNullOrUndefined(subscriptionRegion, this.privErrors.authInvalidSubscriptionRegion);\n                headers[this.privRequestParams.subscriptionRegion] = subscriptionRegion;\n                if (subscriptionKey) {\n                    headers[this.privRequestParams.subscriptionKey] = subscriptionKey;\n                }\n                else if (authToken) {\n                    headers[this.privRequestParams.authorization] = `Bearer ${authToken}`;\n                }\n                else {\n                    _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__.Contracts.throwIfNullOrUndefined(subscriptionKey, this.privErrors.authInvalidSubscriptionKey);\n                }\n            }\n            const config = {};\n            config.headers = headers;\n            this.privRestAdapter.options = config;\n            const endpoint = `https://${endpointHost}${this.privRestPath}`;\n            // TODO: support a proxy and certificate validation\n            this.privRestAdapter.request(_common_browser_Exports__WEBPACK_IMPORTED_MODULE_1__.RestRequestType.Post, endpoint, queryParams, null).then((response) => {\n                const requestId = _common_browser_Exports__WEBPACK_IMPORTED_MODULE_1__.RestMessageAdapter.extractHeaderValue(this.privRequestParams.requestId, response.headers);\n                if (!response.ok) {\n                    if (!!err) {\n                        // get the error\n                        let errorMessage = this.privErrors.invalidCreateJoinConversationResponse.replace(\"{status}\", response.status.toString());\n                        let errMessageRaw;\n                        try {\n                            errMessageRaw = JSON.parse(response.data);\n                            errorMessage += ` [${errMessageRaw.error.code}: ${errMessageRaw.error.message}]`;\n                        }\n                        catch (e) {\n                            errorMessage += ` [${response.data}]`;\n                        }\n                        if (requestId) {\n                            errorMessage += ` ${requestId}`;\n                        }\n                        err(errorMessage);\n                    }\n                    return;\n                }\n                const conversation = JSON.parse(response.data);\n                if (conversation) {\n                    conversation.requestId = requestId;\n                }\n                if (!!cb) {\n                    try {\n                        cb(conversation);\n                    }\n                    catch (e) {\n                        if (!!err) {\n                            err(e);\n                        }\n                    }\n                    cb = undefined;\n                }\n                // eslint-disable-next-line @typescript-eslint/no-empty-function\n            }).catch(() => { });\n        }\n        catch (error) {\n            if (!!err) {\n                if (error instanceof Error) {\n                    const typedError = error;\n                    err(typedError.name + \": \" + typedError.message);\n                }\n                else {\n                    err(error);\n                }\n            }\n        }\n    }\n    /**\n     * Make a DELETE request to the Conversation Manager service endpoint to leave the conversation.\n     * @param args\n     * @param sessionToken\n     * @param callback\n     */\n    leave(args, sessionToken) {\n        return new Promise((resolve, reject) => {\n            try {\n                _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__.Contracts.throwIfNullOrUndefined(args, this.privErrors.invalidArgs.replace(\"{arg}\", \"config\"));\n                _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__.Contracts.throwIfNullOrWhitespace(sessionToken, this.privErrors.invalidArgs.replace(\"{arg}\", \"token\"));\n                const endpointHost = args.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.ConversationTranslator_Host, this.privHost);\n                const correlationId = args.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.ConversationTranslator_CorrelationId);\n                const queryParams = {};\n                queryParams[this.privRequestParams.apiVersion] = this.privApiVersion;\n                queryParams[this.privRequestParams.sessionToken] = sessionToken;\n                const headers = {};\n                if (correlationId) {\n                    headers[this.privRequestParams.correlationId] = correlationId;\n                }\n                const config = {};\n                config.headers = headers;\n                this.privRestAdapter.options = config;\n                const endpoint = `https://${endpointHost}${this.privRestPath}`;\n                // TODO: support a proxy and certificate validation\n                this.privRestAdapter.request(_common_browser_Exports__WEBPACK_IMPORTED_MODULE_1__.RestRequestType.Delete, endpoint, queryParams, null).then((response) => {\n                    if (!response.ok) {\n                        // ignore errors on delete\n                    }\n                    resolve();\n                    // eslint-disable-next-line @typescript-eslint/no-empty-function\n                }).catch(() => { });\n            }\n            catch (error) {\n                if (error instanceof Error) {\n                    const typedError = error;\n                    reject(typedError.name + \": \" + typedError.message);\n                }\n                else {\n                    reject(error);\n                }\n            }\n        });\n    }\n}\n\n//# sourceMappingURL=ConversationManager.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationManager.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationRequestSession.js":
  /*!******************************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationRequestSession.js ***!
    \******************************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConversationRequestSession\": () => (/* binding */ ConversationRequestSession)\n/* harmony export */ });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n/**\n * Placeholder class for the Conversation Request Session. Based off RequestSession.\n * TODO: define what telemetry is required.\n */\nclass ConversationRequestSession {\n    constructor(sessionId) {\n        this.privIsDisposed = false;\n        this.privDetachables = new Array();\n        this.privSessionId = sessionId;\n        this.privRequestId = (0,_common_Exports__WEBPACK_IMPORTED_MODULE_0__.createNoDashGuid)();\n        this.privRequestCompletionDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.Deferred();\n    }\n    get sessionId() {\n        return this.privSessionId;\n    }\n    get requestId() {\n        return this.privRequestId;\n    }\n    get completionPromise() {\n        return this.privRequestCompletionDeferral.promise;\n    }\n    onPreConnectionStart(authFetchEventId, connectionId) {\n        this.privSessionId = connectionId;\n    }\n    onAuthCompleted(isError) {\n        if (isError) {\n            this.onComplete();\n        }\n    }\n    onConnectionEstablishCompleted(statusCode) {\n        if (statusCode === 200) {\n            return;\n        }\n        else if (statusCode === 403) {\n            this.onComplete();\n        }\n    }\n    onServiceTurnEndResponse(continuousRecognition) {\n        if (!continuousRecognition) {\n            this.onComplete();\n        }\n        else {\n            this.privRequestId = (0,_common_Exports__WEBPACK_IMPORTED_MODULE_0__.createNoDashGuid)();\n        }\n    }\n    dispose() {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (!this.privIsDisposed) {\n                // we should have completed by now. If we did not its an unknown error.\n                this.privIsDisposed = true;\n                for (const detachable of this.privDetachables) {\n                    yield detachable.detach();\n                }\n            }\n        });\n    }\n    onComplete() {\n        //\n    }\n}\n\n//# sourceMappingURL=ConversationRequestSession.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationRequestSession.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationServiceAdapter.js":
  /*!******************************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationServiceAdapter.js ***!
    \******************************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConversationServiceAdapter\": () => (/* binding */ ConversationServiceAdapter)\n/* harmony export */ });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IConnection.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationReason.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationCanceledEventArgs.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ../../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationExpirationEventArgs.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ../../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationResult.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_18__ = __webpack_require__(/*! ../../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Translations.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceRecognizerBase.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/CognitiveTokenAuthentication.js\");\n/* harmony import */ var _ConversationConnectionMessage__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./ConversationConnectionMessage */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionMessage.js\");\n/* harmony import */ var _ConversationRequestSession__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./ConversationRequestSession */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationRequestSession.js\");\n/* harmony import */ var _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./ConversationTranslatorEventArgs */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorEventArgs.js\");\n/* harmony import */ var _ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./ConversationTranslatorInterfaces */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorInterfaces.js\");\n/* harmony import */ var _ServiceMessages_Exports__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./ServiceMessages/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/CommandResponsePayload.js\");\n/* harmony import */ var _ServiceMessages_Exports__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./ServiceMessages/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/ParticipantResponsePayload.js\");\n/* harmony import */ var _ServiceMessages_Exports__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./ServiceMessages/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/TranslationResponsePayload.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\n\n\n\n\n\n/**\n * The service adapter handles sending and receiving messages to the Conversation Translator websocket.\n */\nclass ConversationServiceAdapter extends _Exports__WEBPACK_IMPORTED_MODULE_0__.ServiceRecognizerBase {\n    constructor(authentication, connectionFactory, audioSource, recognizerConfig, conversationServiceConnector) {\n        super(authentication, connectionFactory, audioSource, recognizerConfig, conversationServiceConnector);\n        this.privConnectionConfigPromise = undefined;\n        this.privLastPartialUtteranceId = \"\";\n        this.privConversationServiceConnector = conversationServiceConnector;\n        this.privConversationAuthentication = authentication;\n        this.receiveMessageOverride = () => this.receiveConversationMessageOverride();\n        this.recognizeOverride = () => this.noOp();\n        this.postConnectImplOverride = (connection) => this.conversationConnectImpl(connection);\n        this.configConnectionOverride = () => this.configConnection();\n        this.disconnectOverride = () => this.privDisconnect();\n        this.privConversationRequestSession = new _ConversationRequestSession__WEBPACK_IMPORTED_MODULE_1__.ConversationRequestSession((0,_common_Exports__WEBPACK_IMPORTED_MODULE_2__.createNoDashGuid)());\n        this.privConversationConnectionFactory = connectionFactory;\n        this.privConversationIsDisposed = false;\n    }\n    isDisposed() {\n        return super.isDisposed() || this.privConversationIsDisposed;\n    }\n    dispose(reason) {\n        const _super = Object.create(null, {\n            dispose: { get: () => super.dispose }\n        });\n        return __awaiter(this, void 0, void 0, function* () {\n            this.privConversationIsDisposed = true;\n            if (this.privConnectionConfigPromise !== undefined) {\n                const connection = yield this.privConnectionConfigPromise;\n                yield connection.dispose(reason);\n            }\n            yield _super.dispose.call(this, reason);\n        });\n    }\n    sendMessage(message) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const connection = yield this.fetchConnection();\n            return connection.send(new _ConversationConnectionMessage__WEBPACK_IMPORTED_MODULE_3__.ConversationConnectionMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_4__.MessageType.Text, message));\n        });\n    }\n    sendMessageAsync(message) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const connection = yield this.fetchConnection();\n            yield connection.send(new _ConversationConnectionMessage__WEBPACK_IMPORTED_MODULE_3__.ConversationConnectionMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_4__.MessageType.Text, message));\n        });\n    }\n    privDisconnect() {\n        if (this.terminateMessageLoop) {\n            return;\n        }\n        this.cancelRecognition(this.privConversationRequestSession.sessionId, this.privConversationRequestSession.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.CancellationReason.Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.CancellationErrorCode.NoError, \"Disconnecting\");\n        this.terminateMessageLoop = true;\n        return Promise.resolve();\n    }\n    // eslint-disable-next-line @typescript-eslint/require-await\n    processTypeSpecificMessages() {\n        return __awaiter(this, void 0, void 0, function* () {\n            return true;\n        });\n    }\n    // Cancels recognition.\n    cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {\n        this.terminateMessageLoop = true;\n        const cancelEvent = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_7__.ConversationTranslationCanceledEventArgs(cancellationReason, error, errorCode, undefined, sessionId);\n        try {\n            if (!!this.privConversationServiceConnector.canceled) {\n                this.privConversationServiceConnector.canceled(this.privConversationServiceConnector, cancelEvent);\n            }\n        }\n        catch (_a) {\n            // continue on error\n        }\n    }\n    noOp() {\n        // operation not supported\n        return;\n    }\n    /**\n     * Establishes a websocket connection to the end point.\n     */\n    conversationConnectImpl(connection) {\n        return __awaiter(this, void 0, void 0, function* () {\n            this.privConnectionLoop = this.startMessageLoop();\n            return connection;\n        });\n    }\n    /**\n     * Process incoming websocket messages\n     */\n    receiveConversationMessageOverride() {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (this.isDisposed() || this.terminateMessageLoop) {\n                return Promise.resolve();\n            }\n            // we won't rely on the cascading promises of the connection since we want to continually be available to receive messages\n            const communicationCustodian = new _common_Exports__WEBPACK_IMPORTED_MODULE_8__.Deferred();\n            try {\n                const connection = yield this.fetchConnection();\n                const message = yield connection.read();\n                if (this.isDisposed() || this.terminateMessageLoop) {\n                    // We're done.\n                    communicationCustodian.resolve();\n                    return Promise.resolve();\n                }\n                if (!message) {\n                    return this.receiveConversationMessageOverride();\n                }\n                const sessionId = this.privConversationRequestSession.sessionId;\n                let sendFinal = false;\n                try {\n                    switch (message.conversationMessageType.toLowerCase()) {\n                        case \"info\":\n                        case \"participant_command\":\n                        case \"command\":\n                            const commandPayload = _ServiceMessages_Exports__WEBPACK_IMPORTED_MODULE_9__.CommandResponsePayload.fromJSON(message.textBody);\n                            switch (commandPayload.command.toLowerCase()) {\n                                /**\n                                 * 'ParticpantList' is the first message sent to the user after the websocket connection has opened.\n                                 * The consuming client must wait for this message to arrive\n                                 * before starting to send their own data.\n                                 */\n                                case \"participantlist\":\n                                    const participantsPayload = _ServiceMessages_Exports__WEBPACK_IMPORTED_MODULE_10__.ParticipantsListPayloadResponse.fromJSON(message.textBody);\n                                    const participantsResult = participantsPayload.participants.map((p) => {\n                                        const participant = {\n                                            avatar: p.avatar,\n                                            displayName: p.nickname,\n                                            id: p.participantId,\n                                            isHost: p.ishost,\n                                            isMuted: p.ismuted,\n                                            isUsingTts: p.usetts,\n                                            preferredLanguage: p.locale\n                                        };\n                                        return participant;\n                                    });\n                                    if (!!this.privConversationServiceConnector.participantsListReceived) {\n                                        this.privConversationServiceConnector.participantsListReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_11__.ParticipantsListEventArgs(participantsPayload.roomid, participantsPayload.token, participantsPayload.translateTo, participantsPayload.profanityFilter, participantsPayload.roomProfanityFilter, participantsPayload.roomLocked, participantsPayload.muteAll, participantsResult, sessionId));\n                                    }\n                                    break;\n                                /**\n                                 * 'SetTranslateToLanguages' represents the list of languages being used in the Conversation by all users(?).\n                                 * This is sent at the start of the Conversation\n                                 */\n                                case \"settranslatetolanguages\":\n                                    if (!!this.privConversationServiceConnector.participantUpdateCommandReceived) {\n                                        this.privConversationServiceConnector.participantUpdateCommandReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_11__.ParticipantAttributeEventArgs(commandPayload.participantId, _ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_12__.ConversationTranslatorCommandTypes.setTranslateToLanguages, commandPayload.value, sessionId));\n                                    }\n                                    break;\n                                /**\n                                 * 'SetProfanityFiltering' lets the client set the level of profanity filtering.\n                                 * If sent by the participant the setting will effect only their own profanity level.\n                                 * If sent by the host, the setting will effect all participants including the host.\n                                 * Note: the profanity filters differ from Speech Service (?): 'marked', 'raw', 'removed', 'tagged'\n                                 */\n                                case \"setprofanityfiltering\":\n                                    if (!!this.privConversationServiceConnector.participantUpdateCommandReceived) {\n                                        this.privConversationServiceConnector.participantUpdateCommandReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_11__.ParticipantAttributeEventArgs(commandPayload.participantId, _ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_12__.ConversationTranslatorCommandTypes.setProfanityFiltering, commandPayload.value, sessionId));\n                                    }\n                                    break;\n                                /**\n                                 * 'SetMute' is sent if the participant has been muted by the host.\n                                 * Check the 'participantId' to determine if the current user has been muted.\n                                 */\n                                case \"setmute\":\n                                    if (!!this.privConversationServiceConnector.participantUpdateCommandReceived) {\n                                        this.privConversationServiceConnector.participantUpdateCommandReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_11__.ParticipantAttributeEventArgs(commandPayload.participantId, _ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_12__.ConversationTranslatorCommandTypes.setMute, commandPayload.value, sessionId));\n                                    }\n                                    break;\n                                /**\n                                 * 'SetMuteAll' is sent if the Conversation has been muted by the host.\n                                 */\n                                case \"setmuteall\":\n                                    if (!!this.privConversationServiceConnector.muteAllCommandReceived) {\n                                        this.privConversationServiceConnector.muteAllCommandReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_11__.MuteAllEventArgs(commandPayload.value, sessionId));\n                                    }\n                                    break;\n                                /**\n                                 * 'RoomExpirationWarning' is sent towards the end of the Conversation session to give a timeout warning.\n                                 */\n                                case \"roomexpirationwarning\":\n                                    if (!!this.privConversationServiceConnector.conversationExpiration) {\n                                        this.privConversationServiceConnector.conversationExpiration(this.privConversationServiceConnector, new _sdk_Exports__WEBPACK_IMPORTED_MODULE_13__.ConversationExpirationEventArgs(commandPayload.value, this.privConversationRequestSession.sessionId));\n                                    }\n                                    break;\n                                /**\n                                 * 'SetUseTts' is sent as a confirmation if the user requests TTS to be turned on or off.\n                                 */\n                                case \"setusetts\":\n                                    if (!!this.privConversationServiceConnector.participantUpdateCommandReceived) {\n                                        this.privConversationServiceConnector.participantUpdateCommandReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_11__.ParticipantAttributeEventArgs(commandPayload.participantId, _ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_12__.ConversationTranslatorCommandTypes.setUseTTS, commandPayload.value, sessionId));\n                                    }\n                                    break;\n                                /**\n                                 * 'SetLockState' is set if the host has locked or unlocked the Conversation.\n                                 */\n                                case \"setlockstate\":\n                                    if (!!this.privConversationServiceConnector.lockRoomCommandReceived) {\n                                        this.privConversationServiceConnector.lockRoomCommandReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_11__.LockRoomEventArgs(commandPayload.value, sessionId));\n                                    }\n                                    break;\n                                /**\n                                 * 'ChangeNickname' is received if a user changes their display name.\n                                 * Any cached particpiants list should be updated to reflect the display name.\n                                 */\n                                case \"changenickname\":\n                                    if (!!this.privConversationServiceConnector.participantUpdateCommandReceived) {\n                                        this.privConversationServiceConnector.participantUpdateCommandReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_11__.ParticipantAttributeEventArgs(commandPayload.participantId, _ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_12__.ConversationTranslatorCommandTypes.changeNickname, commandPayload.nickname, sessionId));\n                                    }\n                                    break;\n                                /**\n                                 * 'JoinSession' is sent when a user joins the Conversation.\n                                 */\n                                case \"joinsession\":\n                                    const joinParticipantPayload = _ServiceMessages_Exports__WEBPACK_IMPORTED_MODULE_10__.ParticipantPayloadResponse.fromJSON(message.textBody);\n                                    const joiningParticipant = {\n                                        avatar: joinParticipantPayload.avatar,\n                                        displayName: joinParticipantPayload.nickname,\n                                        id: joinParticipantPayload.participantId,\n                                        isHost: joinParticipantPayload.ishost,\n                                        isMuted: joinParticipantPayload.ismuted,\n                                        isUsingTts: joinParticipantPayload.usetts,\n                                        preferredLanguage: joinParticipantPayload.locale,\n                                    };\n                                    if (!!this.privConversationServiceConnector.participantJoinCommandReceived) {\n                                        this.privConversationServiceConnector.participantJoinCommandReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_11__.ParticipantEventArgs(joiningParticipant, sessionId));\n                                    }\n                                    break;\n                                /**\n                                 * 'LeaveSession' is sent when a user leaves the Conversation'.\n                                 */\n                                case \"leavesession\":\n                                    const leavingParticipant = {\n                                        id: commandPayload.participantId\n                                    };\n                                    if (!!this.privConversationServiceConnector.participantLeaveCommandReceived) {\n                                        this.privConversationServiceConnector.participantLeaveCommandReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_11__.ParticipantEventArgs(leavingParticipant, sessionId));\n                                    }\n                                    break;\n                                /**\n                                 * 'DisconnectSession' is sent when a user is disconnected from the session (e.g. network problem).\n                                 * Check the 'ParticipantId' to check whether the message is for the current user.\n                                 */\n                                case \"disconnectsession\":\n                                    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n                                    const disconnectParticipant = {\n                                        id: commandPayload.participantId\n                                    };\n                                    break;\n                                case \"token\":\n                                    const token = new _Exports__WEBPACK_IMPORTED_MODULE_14__.CognitiveTokenAuthentication(() => {\n                                        const authorizationToken = commandPayload.token;\n                                        return Promise.resolve(authorizationToken);\n                                    }, () => {\n                                        const authorizationToken = commandPayload.token;\n                                        return Promise.resolve(authorizationToken);\n                                    });\n                                    this.authentication = token;\n                                    break;\n                                /**\n                                 * Message not recognized.\n                                 */\n                                default:\n                                    break;\n                            }\n                            break;\n                        /**\n                         * 'partial' (or 'hypothesis') represents a unfinalized speech message.\n                         */\n                        case \"partial\":\n                        /**\n                         * 'final' (or 'phrase') represents a finalized speech message.\n                         */\n                        case \"final\":\n                            const speechPayload = _ServiceMessages_Exports__WEBPACK_IMPORTED_MODULE_15__.SpeechResponsePayload.fromJSON(message.textBody);\n                            const speechResult = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_16__.ConversationTranslationResult(speechPayload.participantId, this.getTranslations(speechPayload.translations), speechPayload.language, undefined, undefined, speechPayload.recognition, undefined, undefined, message.textBody, undefined);\n                            if (speechPayload.isFinal) {\n                                // check the length, sometimes empty finals are returned\n                                if (speechResult.text !== undefined && speechResult.text.length > 0) {\n                                    sendFinal = true;\n                                }\n                                else if (speechPayload.id === this.privLastPartialUtteranceId) {\n                                    // send final as normal. We had a non-empty partial for this same utterance\n                                    // so sending the empty final is important\n                                    sendFinal = true;\n                                }\n                                else {\n                                    // suppress unneeded final\n                                }\n                                if (sendFinal) {\n                                    if (!!this.privConversationServiceConnector.translationReceived) {\n                                        this.privConversationServiceConnector.translationReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_11__.ConversationReceivedTranslationEventArgs(_ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_12__.ConversationTranslatorMessageTypes.final, speechResult, sessionId));\n                                    }\n                                }\n                            }\n                            else if (speechResult.text !== undefined) {\n                                this.privLastPartialUtteranceId = speechPayload.id;\n                                if (!!this.privConversationServiceConnector.translationReceived) {\n                                    this.privConversationServiceConnector.translationReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_11__.ConversationReceivedTranslationEventArgs(_ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_12__.ConversationTranslatorMessageTypes.partial, speechResult, sessionId));\n                                }\n                            }\n                            break;\n                        /**\n                         * \"translated_message\" is a text message or instant message (IM).\n                         */\n                        case \"translated_message\":\n                            const textPayload = _ServiceMessages_Exports__WEBPACK_IMPORTED_MODULE_15__.TextResponsePayload.fromJSON(message.textBody);\n                            const textResult = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_16__.ConversationTranslationResult(textPayload.participantId, this.getTranslations(textPayload.translations), textPayload.language, undefined, undefined, textPayload.originalText, undefined, undefined, undefined, message.textBody, undefined);\n                            if (!!this.privConversationServiceConnector.translationReceived) {\n                                this.privConversationServiceConnector.translationReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_11__.ConversationReceivedTranslationEventArgs(_ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_12__.ConversationTranslatorMessageTypes.instantMessage, textResult, sessionId));\n                            }\n                            break;\n                        default:\n                            // ignore any unsupported message types\n                            break;\n                    }\n                }\n                catch (e) {\n                    // continue\n                }\n                return this.receiveConversationMessageOverride();\n            }\n            catch (e) {\n                this.terminateMessageLoop = true;\n            }\n            return communicationCustodian.promise;\n        });\n    }\n    startMessageLoop() {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (this.isDisposed()) {\n                return Promise.resolve();\n            }\n            this.terminateMessageLoop = false;\n            const messageRetrievalPromise = this.receiveConversationMessageOverride();\n            try {\n                const r = yield messageRetrievalPromise;\n                return r;\n            }\n            catch (error) {\n                this.cancelRecognition(this.privRequestSession ? this.privRequestSession.sessionId : \"\", this.privRequestSession ? this.privRequestSession.requestId : \"\", _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.CancellationReason.Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.CancellationErrorCode.RuntimeError, error);\n                return null;\n            }\n        });\n    }\n    // Takes an established websocket connection to the endpoint\n    configConnection() {\n        if (this.isDisposed()) {\n            return Promise.resolve(undefined);\n        }\n        if (this.privConnectionConfigPromise !== undefined) {\n            return this.privConnectionConfigPromise.then((connection) => {\n                if (connection.state() === _common_Exports__WEBPACK_IMPORTED_MODULE_17__.ConnectionState.Disconnected) {\n                    this.privConnectionId = null;\n                    this.privConnectionConfigPromise = undefined;\n                    return this.configConnection();\n                }\n                return this.privConnectionConfigPromise;\n            }, () => {\n                this.privConnectionId = null;\n                this.privConnectionConfigPromise = undefined;\n                return this.configConnection();\n            });\n        }\n        if (this.terminateMessageLoop) {\n            return Promise.resolve(undefined);\n        }\n        this.privConnectionConfigPromise = this.connectImpl().then((connection) => connection);\n        return this.privConnectionConfigPromise;\n    }\n    getTranslations(serviceResultTranslations) {\n        let translations;\n        if (undefined !== serviceResultTranslations) {\n            translations = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_18__.Translations();\n            for (const translation of serviceResultTranslations) {\n                translations.set(translation.lang, translation.translation);\n            }\n        }\n        return translations;\n    }\n}\n\n//# sourceMappingURL=ConversationServiceAdapter.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationServiceAdapter.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorEventArgs.js":
  /*!***********************************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorEventArgs.js ***!
    \***********************************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConversationReceivedTranslationEventArgs\": () => (/* binding */ ConversationReceivedTranslationEventArgs),\n/* harmony export */   \"LockRoomEventArgs\": () => (/* binding */ LockRoomEventArgs),\n/* harmony export */   \"MuteAllEventArgs\": () => (/* binding */ MuteAllEventArgs),\n/* harmony export */   \"ParticipantAttributeEventArgs\": () => (/* binding */ ParticipantAttributeEventArgs),\n/* harmony export */   \"ParticipantEventArgs\": () => (/* binding */ ParticipantEventArgs),\n/* harmony export */   \"ParticipantsListEventArgs\": () => (/* binding */ ParticipantsListEventArgs)\n/* harmony export */ });\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SessionEventArgs.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/* eslint-disable max-classes-per-file */\n\nclass MuteAllEventArgs extends _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.SessionEventArgs {\n    constructor(isMuted, sessionId) {\n        super(sessionId);\n        this.privIsMuted = isMuted;\n    }\n    get isMuted() {\n        return this.privIsMuted;\n    }\n}\nclass LockRoomEventArgs extends _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.SessionEventArgs {\n    constructor(isLocked, sessionId) {\n        super(sessionId);\n        this.privIsLocked = isLocked;\n    }\n    get isMuted() {\n        return this.privIsLocked;\n    }\n}\nclass ParticipantEventArgs extends _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.SessionEventArgs {\n    constructor(participant, sessionId) {\n        super(sessionId);\n        this.privParticipant = participant;\n    }\n    get participant() {\n        return this.privParticipant;\n    }\n}\nclass ParticipantAttributeEventArgs extends _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.SessionEventArgs {\n    constructor(participantId, key, value, sessionId) {\n        super(sessionId);\n        this.privKey = key;\n        this.privValue = value;\n        this.privParticipantId = participantId;\n    }\n    get value() {\n        return this.privValue;\n    }\n    get key() {\n        return this.privKey;\n    }\n    get id() {\n        return this.privParticipantId;\n    }\n}\nclass ParticipantsListEventArgs extends _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.SessionEventArgs {\n    constructor(conversationId, token, translateTo, profanityFilter, roomProfanityFilter, isRoomLocked, isMuteAll, participants, sessionId) {\n        super(sessionId);\n        this.privRoomId = conversationId;\n        this.privSessionToken = token;\n        this.privTranslateTo = translateTo;\n        this.privProfanityFilter = profanityFilter;\n        this.privRoomProfanityFilter = roomProfanityFilter;\n        this.privIsRoomLocked = isRoomLocked;\n        this.privIsRoomLocked = isMuteAll;\n        this.privParticipants = participants;\n    }\n    get sessionToken() {\n        return this.privSessionToken;\n    }\n    get conversationId() {\n        return this.privRoomId;\n    }\n    get translateTo() {\n        return this.privTranslateTo;\n    }\n    get profanityFilter() {\n        return this.privProfanityFilter;\n    }\n    get roomProfanityFilter() {\n        return this.privRoomProfanityFilter;\n    }\n    get isRoomLocked() {\n        return this.privIsRoomLocked;\n    }\n    get isMuteAll() {\n        return this.privIsMuteAll;\n    }\n    get participants() {\n        return this.privParticipants;\n    }\n}\nclass ConversationReceivedTranslationEventArgs {\n    constructor(command, payload, sessionId) {\n        this.privPayload = payload;\n        this.privCommand = command;\n        this.privSessionId = sessionId;\n    }\n    get payload() {\n        return this.privPayload;\n    }\n    get command() {\n        return this.privCommand;\n    }\n    get sessionId() {\n        return this.privSessionId;\n    }\n}\n\n//# sourceMappingURL=ConversationTranslatorEventArgs.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorEventArgs.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorInterfaces.js":
  /*!************************************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorInterfaces.js ***!
    \************************************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConversationTranslatorCommandTypes\": () => (/* binding */ ConversationTranslatorCommandTypes),\n/* harmony export */   \"ConversationTranslatorMessageTypes\": () => (/* binding */ ConversationTranslatorMessageTypes),\n/* harmony export */   \"InternalParticipants\": () => (/* binding */ InternalParticipants)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/** Users participating in the conversation */\nclass InternalParticipants {\n    constructor(participants = [], meId) {\n        this.participants = participants;\n        this.meId = meId;\n    }\n    /**\n     * Add or update a participant\n     * @param value\n     */\n    addOrUpdateParticipant(value) {\n        if (value === undefined) {\n            return;\n        }\n        const exists = this.getParticipantIndex(value.id);\n        if (exists > -1) {\n            this.participants.splice(exists, 1, value);\n        }\n        else {\n            this.participants.push(value);\n        }\n        // ensure it was added ok\n        return this.getParticipant(value.id);\n    }\n    /**\n     * Find the participant's position in the participants list.\n     * @param id\n     */\n    getParticipantIndex(id) {\n        return this.participants.findIndex((p) => p.id === id);\n    }\n    /**\n     * Find the participant by id.\n     * @param id\n     */\n    getParticipant(id) {\n        return this.participants.find((p) => p.id === id);\n    }\n    /**\n     * Remove a participant from the participants list.\n     */\n    deleteParticipant(id) {\n        this.participants = this.participants.filter((p) => p.id !== id);\n    }\n    /**\n     * Helper to return the conversation host.\n     */\n    get host() {\n        return this.participants.find((p) => p.isHost === true);\n    }\n    /**\n     * Helper to return the current user.\n     */\n    get me() {\n        return this.getParticipant(this.meId);\n    }\n}\n/**\n * List of command message types\n */\nconst ConversationTranslatorMessageTypes = {\n    command: \"command\",\n    final: \"final\",\n    info: \"info\",\n    instantMessage: \"instant_message\",\n    keepAlive: \"keep_alive\",\n    partial: \"partial\",\n    participantCommand: \"participant_command\",\n    translatedMessage: \"translated_message\"\n};\n/**\n * List of command types\n */\nconst ConversationTranslatorCommandTypes = {\n    changeNickname: \"ChangeNickname\",\n    disconnectSession: \"DisconnectSession\",\n    ejectParticipant: \"EjectParticipant\",\n    instant_message: \"instant_message\",\n    joinSession: \"JoinSession\",\n    leaveSession: \"LeaveSession\",\n    participantList: \"ParticipantList\",\n    roomExpirationWarning: \"RoomExpirationWarning\",\n    setLockState: \"SetLockState\",\n    setMute: \"SetMute\",\n    setMuteAll: \"SetMuteAll\",\n    setProfanityFiltering: \"SetProfanityFiltering\",\n    setTranslateToLanguages: \"SetTranslateToLanguages\",\n    setUseTTS: \"SetUseTTS\"\n};\n\n//# sourceMappingURL=ConversationTranslatorInterfaces.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorInterfaces.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorRecognizer.js":
  /*!************************************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorRecognizer.js ***!
    \************************************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConversationRecognizerFactory\": () => (/* binding */ ConversationRecognizerFactory),\n/* harmony export */   \"ConversationTranslatorRecognizer\": () => (/* binding */ ConversationTranslatorRecognizer)\n/* harmony export */ });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Timeout.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Events.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/BackgroundError.js\");\n/* harmony import */ var _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../sdk/Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Recognizer.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Connection.js\");\n/* harmony import */ var _ConversationConnectionFactory__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ConversationConnectionFactory */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionFactory.js\");\n/* harmony import */ var _ConversationServiceAdapter__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./ConversationServiceAdapter */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationServiceAdapter.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n// eslint-disable-next-line max-classes-per-file\n\n\n\n\n\n\nclass ConversationRecognizerFactory {\n    static fromConfig(conversation, speechConfig, audioConfig) {\n        return new ConversationTranslatorRecognizer(conversation, speechConfig, audioConfig);\n    }\n}\n/**\n * Sends messages to the Conversation Translator websocket and listens for incoming events containing websocket messages.\n * Based off the recognizers in the SDK folder.\n */\nclass ConversationTranslatorRecognizer extends _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.Recognizer {\n    constructor(conversation, speechConfig, audioConfig) {\n        const serviceConfigImpl = speechConfig;\n        _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNull(serviceConfigImpl, \"speechConfig\");\n        const conversationImpl = conversation;\n        _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNull(conversationImpl, \"conversationImpl\");\n        super(audioConfig, serviceConfigImpl.properties, new _ConversationConnectionFactory__WEBPACK_IMPORTED_MODULE_2__.ConversationConnectionFactory());\n        this.privConversation = conversationImpl;\n        this.privIsDisposed = false;\n        this.privProperties = serviceConfigImpl.properties.clone();\n        this.privConnection = _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.Connection.fromRecognizer(this);\n        this.privSetTimeout = (typeof (Blob) !== \"undefined\" && typeof (Worker) !== \"undefined\") ? _common_Exports__WEBPACK_IMPORTED_MODULE_4__.Timeout.setTimeout : setTimeout;\n        this.privClearTimeout = (typeof (Blob) !== \"undefined\" && typeof (Worker) !== \"undefined\") ? _common_Exports__WEBPACK_IMPORTED_MODULE_4__.Timeout.clearTimeout : clearTimeout;\n    }\n    set connected(cb) {\n        this.privConnection.connected = cb;\n    }\n    set disconnected(cb) {\n        this.privConnection.disconnected = cb;\n    }\n    /**\n     * Return the speech language used by the recognizer\n     */\n    get speechRecognitionLanguage() {\n        return this.privSpeechRecognitionLanguage;\n    }\n    /**\n     * Return the properties for the recognizer\n     */\n    get properties() {\n        return this.privProperties;\n    }\n    isDisposed() {\n        return this.privIsDisposed;\n    }\n    /**\n     * Connect to the recognizer\n     * @param token\n     */\n    connect(token, cb, err) {\n        try {\n            _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privIsDisposed);\n            _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(token, \"token\");\n            this.privReco.conversationTranslatorToken = token;\n            this.resetConversationTimeout();\n            this.privReco.connectAsync(cb, err);\n        }\n        catch (error) {\n            if (!!err) {\n                if (error instanceof Error) {\n                    const typedError = error;\n                    err(typedError.name + \": \" + typedError.message);\n                }\n                else {\n                    err(error);\n                }\n            }\n        }\n    }\n    /**\n     * Disconnect from the recognizer\n     */\n    disconnect(cb, err) {\n        try {\n            _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privIsDisposed);\n            if (this.privTimeoutToken !== undefined) {\n                // eslint-disable-next-line @typescript-eslint/no-unsafe-argument\n                this.privClearTimeout(this.privTimeoutToken);\n            }\n            this.privReco.disconnect().then(() => {\n                if (!!cb) {\n                    cb();\n                }\n            }, (error) => {\n                if (!!err) {\n                    err(error);\n                }\n            });\n        }\n        catch (error) {\n            if (!!err) {\n                if (error instanceof Error) {\n                    const typedError = error;\n                    err(typedError.name + \": \" + typedError.message);\n                }\n                else {\n                    err(error);\n                }\n            }\n            // Destroy the recognizer.\n            this.dispose(true).catch((reason) => {\n                _common_Exports__WEBPACK_IMPORTED_MODULE_5__.Events.instance.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_6__.BackgroundEvent(reason));\n            });\n        }\n    }\n    /**\n     * Send the mute all participants command to the websocket\n     * @param conversationId\n     * @param participantId\n     * @param isMuted\n     */\n    sendRequest(command, cb, err) {\n        try {\n            _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privIsDisposed);\n            this.sendMessage(command, cb, err);\n        }\n        catch (error) {\n            if (!!err) {\n                if (error instanceof Error) {\n                    const typedError = error;\n                    err(typedError.name + \": \" + typedError.message);\n                }\n                else {\n                    err(error);\n                }\n            }\n            // Destroy the recognizer.\n            this.dispose(true).catch((reason) => {\n                _common_Exports__WEBPACK_IMPORTED_MODULE_5__.Events.instance.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_6__.BackgroundEvent(reason));\n            });\n        }\n    }\n    /**\n     * Close and dispose the recognizer\n     */\n    close() {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (!this.privIsDisposed) {\n                if (!!this.privConnection) {\n                    this.privConnection.closeConnection();\n                    this.privConnection.close();\n                }\n                this.privConnection = undefined;\n                yield this.dispose(true);\n            }\n        });\n    }\n    /**\n     * Dispose the recognizer\n     * @param disposing\n     */\n    dispose(disposing) {\n        const _super = Object.create(null, {\n            dispose: { get: () => super.dispose }\n        });\n        return __awaiter(this, void 0, void 0, function* () {\n            if (this.privIsDisposed) {\n                return;\n            }\n            if (disposing) {\n                if (this.privTimeoutToken !== undefined) {\n                    // eslint-disable-next-line @typescript-eslint/no-unsafe-argument\n                    this.privClearTimeout(this.privTimeoutToken);\n                }\n                this.privIsDisposed = true;\n                if (!!this.privConnection) {\n                    this.privConnection.closeConnection();\n                    this.privConnection.close();\n                    this.privConnection = undefined;\n                }\n                yield _super.dispose.call(this, disposing);\n            }\n        });\n    }\n    /**\n     * Create the config for the recognizer\n     * @param speechConfig\n     */\n    createRecognizerConfig(speechConfig) {\n        return new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_7__.RecognizerConfig(speechConfig, this.privProperties);\n    }\n    /**\n     * Create the service recognizer.\n     * The audio source is redundnant here but is required by the implementation.\n     * @param authentication\n     * @param connectionFactory\n     * @param audioConfig\n     * @param recognizerConfig\n     */\n    createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {\n        const audioSource = audioConfig;\n        return new _ConversationServiceAdapter__WEBPACK_IMPORTED_MODULE_8__.ConversationServiceAdapter(authentication, connectionFactory, audioSource, recognizerConfig, this);\n    }\n    sendMessage(msg, cb, err) {\n        const withAsync = this.privReco;\n        const PromiseToEmptyCallback = (promise, cb, err) => {\n            if (promise !== undefined) {\n                promise.then(() => {\n                    try {\n                        if (!!cb) {\n                            cb();\n                        }\n                    }\n                    catch (e) {\n                        if (!!err) {\n                            err(`'Unhandled error on promise callback: ${e}'`);\n                        }\n                    }\n                }, (reason) => {\n                    try {\n                        if (!!err) {\n                            err(reason);\n                        }\n                        // eslint-disable-next-line no-empty\n                    }\n                    catch (error) { }\n                });\n            }\n            else {\n                if (!!err) {\n                    err(\"Null promise\");\n                }\n            }\n        };\n        PromiseToEmptyCallback(withAsync.sendMessageAsync(msg), cb, err);\n        this.resetConversationTimeout();\n    }\n    resetConversationTimeout() {\n        if (this.privTimeoutToken !== undefined) {\n            // eslint-disable-next-line @typescript-eslint/no-unsafe-argument\n            this.privClearTimeout(this.privTimeoutToken);\n        }\n        this.privTimeoutToken = this.privSetTimeout(() => {\n            this.sendRequest(this.privConversation.getKeepAlive());\n        }, 60000);\n    }\n}\n\n//# sourceMappingURL=ConversationTranslatorRecognizer.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorRecognizer.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationWebsocketMessageFormatter.js":
  /*!*****************************************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationWebsocketMessageFormatter.js ***!
    \*****************************************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConversationWebsocketMessageFormatter\": () => (/* binding */ ConversationWebsocketMessageFormatter)\n/* harmony export */ });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/RawWebsocketMessage.js\");\n/* harmony import */ var _ConversationConnectionMessage__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ConversationConnectionMessage */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionMessage.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n/**\n * Based off WebsocketMessageFormatter. The messages for Conversation Translator have some variations from the Speech messages.\n */\nclass ConversationWebsocketMessageFormatter {\n    /**\n     * Format incoming messages: text (speech partial/final, IM) or binary (tts)\n     */\n    toConnectionMessage(message) {\n        const deferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_0__.Deferred();\n        try {\n            if (message.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_1__.MessageType.Text) {\n                const incomingMessage = new _ConversationConnectionMessage__WEBPACK_IMPORTED_MODULE_2__.ConversationConnectionMessage(message.messageType, message.textContent, {}, message.id);\n                deferral.resolve(incomingMessage);\n            }\n            else if (message.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_1__.MessageType.Binary) {\n                deferral.resolve(new _ConversationConnectionMessage__WEBPACK_IMPORTED_MODULE_2__.ConversationConnectionMessage(message.messageType, message.binaryContent, undefined, message.id));\n            }\n        }\n        catch (e) {\n            deferral.reject(`Error formatting the message. Error: ${e}`);\n        }\n        return deferral.promise;\n    }\n    /**\n     * Format outgoing messages: text (commands or IM)\n     */\n    fromConnectionMessage(message) {\n        const deferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_0__.Deferred();\n        try {\n            if (message.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_1__.MessageType.Text) {\n                const payload = `${message.textBody ? message.textBody : \"\"}`;\n                deferral.resolve(new _common_Exports__WEBPACK_IMPORTED_MODULE_3__.RawWebsocketMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_1__.MessageType.Text, payload, message.id));\n            }\n        }\n        catch (e) {\n            deferral.reject(`Error formatting the message. ${e}`);\n        }\n        return deferral.promise;\n    }\n}\n\n//# sourceMappingURL=ConversationWebsocketMessageFormatter.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationWebsocketMessageFormatter.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/Exports.js":
  /*!***********************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/Exports.js ***!
    \***********************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConversationConnectionConfig\": () => (/* reexport safe */ _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_1__.ConversationConnectionConfig),\n/* harmony export */   \"ConversationManager\": () => (/* reexport safe */ _ConversationManager__WEBPACK_IMPORTED_MODULE_0__.ConversationManager),\n/* harmony export */   \"ConversationReceivedTranslationEventArgs\": () => (/* reexport safe */ _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_4__.ConversationReceivedTranslationEventArgs),\n/* harmony export */   \"ConversationRecognizerFactory\": () => (/* reexport safe */ _ConversationTranslatorRecognizer__WEBPACK_IMPORTED_MODULE_2__.ConversationRecognizerFactory),\n/* harmony export */   \"ConversationTranslatorCommandTypes\": () => (/* reexport safe */ _ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_5__.ConversationTranslatorCommandTypes),\n/* harmony export */   \"ConversationTranslatorMessageTypes\": () => (/* reexport safe */ _ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_5__.ConversationTranslatorMessageTypes),\n/* harmony export */   \"InternalParticipants\": () => (/* reexport safe */ _ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_5__.InternalParticipants),\n/* harmony export */   \"LockRoomEventArgs\": () => (/* reexport safe */ _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_4__.LockRoomEventArgs),\n/* harmony export */   \"MuteAllEventArgs\": () => (/* reexport safe */ _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_4__.MuteAllEventArgs),\n/* harmony export */   \"ParticipantAttributeEventArgs\": () => (/* reexport safe */ _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_4__.ParticipantAttributeEventArgs),\n/* harmony export */   \"ParticipantEventArgs\": () => (/* reexport safe */ _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_4__.ParticipantEventArgs),\n/* harmony export */   \"ParticipantsListEventArgs\": () => (/* reexport safe */ _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_4__.ParticipantsListEventArgs),\n/* harmony export */   \"TranscriberRecognizer\": () => (/* reexport safe */ _TranscriberRecognizer__WEBPACK_IMPORTED_MODULE_3__.TranscriberRecognizer)\n/* harmony export */ });\n/* harmony import */ var _ConversationManager__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./ConversationManager */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationManager.js\");\n/* harmony import */ var _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./ConversationConnectionConfig */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionConfig.js\");\n/* harmony import */ var _ConversationTranslatorRecognizer__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ConversationTranslatorRecognizer */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorRecognizer.js\");\n/* harmony import */ var _TranscriberRecognizer__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./TranscriberRecognizer */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/TranscriberRecognizer.js\");\n/* harmony import */ var _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./ConversationTranslatorEventArgs */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorEventArgs.js\");\n/* harmony import */ var _ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./ConversationTranslatorInterfaces */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorInterfaces.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\n\n\n\n\n//# sourceMappingURL=Exports.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/Exports.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/CommandResponsePayload.js":
  /*!******************************************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/CommandResponsePayload.js ***!
    \******************************************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"CommandResponsePayload\": () => (/* binding */ CommandResponsePayload)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nconst parseCommandResponse = (json) => JSON.parse(json);\nclass CommandResponsePayload {\n    constructor(json) {\n        this.privCommandResponse = parseCommandResponse(json);\n    }\n    get type() {\n        return this.privCommandResponse.type;\n    }\n    get command() {\n        return this.privCommandResponse.command;\n    }\n    get id() {\n        return this.privCommandResponse.id;\n    }\n    get nickname() {\n        return this.privCommandResponse.nickname;\n    }\n    get participantId() {\n        return this.privCommandResponse.participantId;\n    }\n    get roomid() {\n        return this.privCommandResponse.roomid;\n    }\n    get value() {\n        return this.privCommandResponse.value;\n    }\n    get token() {\n        return this.privCommandResponse.token;\n    }\n    static fromJSON(json) {\n        return new CommandResponsePayload(json);\n    }\n}\n\n//# sourceMappingURL=CommandResponsePayload.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/CommandResponsePayload.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/ParticipantResponsePayload.js":
  /*!**********************************************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/ParticipantResponsePayload.js ***!
    \**********************************************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ParticipantPayloadResponse\": () => (/* binding */ ParticipantPayloadResponse),\n/* harmony export */   \"ParticipantsListPayloadResponse\": () => (/* binding */ ParticipantsListPayloadResponse)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nconst parseListResponse = (json) => JSON.parse(json);\nconst parseParticipantResponse = (json) => JSON.parse(json);\nclass ParticipantsListPayloadResponse {\n    constructor(json) {\n        this.privParticipantsPayloadResponse = parseListResponse(json);\n    }\n    get roomid() {\n        return this.privParticipantsPayloadResponse.roomid;\n    }\n    get id() {\n        return this.privParticipantsPayloadResponse.id;\n    }\n    get command() {\n        return this.privParticipantsPayloadResponse.command;\n    }\n    get participants() {\n        return this.privParticipantsPayloadResponse.participants;\n    }\n    get token() {\n        return this.privParticipantsPayloadResponse.token;\n    }\n    get translateTo() {\n        return this.privParticipantsPayloadResponse.translateTo;\n    }\n    get profanityFilter() {\n        return this.privParticipantsPayloadResponse.profanityFilter;\n    }\n    get roomProfanityFilter() {\n        return this.privParticipantsPayloadResponse.roomProfanityFilter;\n    }\n    get roomLocked() {\n        return this.privParticipantsPayloadResponse.roomLocked;\n    }\n    get muteAll() {\n        return this.privParticipantsPayloadResponse.muteAll;\n    }\n    get type() {\n        return this.privParticipantsPayloadResponse.type;\n    }\n    static fromJSON(json) {\n        return new ParticipantsListPayloadResponse(json);\n    }\n}\nclass ParticipantPayloadResponse {\n    constructor(json) {\n        this.privParticipantPayloadResponse = parseParticipantResponse(json);\n    }\n    get nickname() {\n        return this.privParticipantPayloadResponse.nickname;\n    }\n    get locale() {\n        return this.privParticipantPayloadResponse.locale;\n    }\n    get usetts() {\n        return this.privParticipantPayloadResponse.usetts;\n    }\n    get ismuted() {\n        return this.privParticipantPayloadResponse.ismuted;\n    }\n    get ishost() {\n        return this.privParticipantPayloadResponse.ishost;\n    }\n    get participantId() {\n        return this.privParticipantPayloadResponse.participantId;\n    }\n    get avatar() {\n        return this.privParticipantPayloadResponse.avatar;\n    }\n    static fromJSON(json) {\n        return new ParticipantPayloadResponse(json);\n    }\n}\n\n//# sourceMappingURL=ParticipantResponsePayload.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/ParticipantResponsePayload.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/TranslationResponsePayload.js":
  /*!**********************************************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/TranslationResponsePayload.js ***!
    \**********************************************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SpeechResponsePayload\": () => (/* binding */ SpeechResponsePayload),\n/* harmony export */   \"TextResponsePayload\": () => (/* binding */ TextResponsePayload)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nconst parseSpeechResponse = (json) => JSON.parse(json);\nconst parseTextResponse = (json) => JSON.parse(json);\nclass SpeechResponsePayload {\n    constructor(json) {\n        this.privSpeechResponse = parseSpeechResponse(json);\n    }\n    get recognition() {\n        return this.privSpeechResponse.recognition;\n    }\n    get translations() {\n        return this.privSpeechResponse.translations;\n    }\n    get id() {\n        return this.privSpeechResponse.id;\n    }\n    get language() {\n        return this.privSpeechResponse.language;\n    }\n    get nickname() {\n        return this.privSpeechResponse.nickname;\n    }\n    get participantId() {\n        return this.privSpeechResponse.participantId;\n    }\n    get roomid() {\n        return this.privSpeechResponse.roomid;\n    }\n    get timestamp() {\n        return this.privSpeechResponse.timestamp;\n    }\n    get type() {\n        return this.privSpeechResponse.type;\n    }\n    get isFinal() {\n        return this.privSpeechResponse.type === \"final\";\n    }\n    static fromJSON(json) {\n        return new SpeechResponsePayload(json);\n    }\n}\nclass TextResponsePayload {\n    constructor(json) {\n        this.privTextResponse = parseTextResponse(json);\n    }\n    get originalText() {\n        return this.privTextResponse.originalText;\n    }\n    get translations() {\n        return this.privTextResponse.translations;\n    }\n    get id() {\n        return this.privTextResponse.id;\n    }\n    get language() {\n        return this.privTextResponse.language;\n    }\n    get nickname() {\n        return this.privTextResponse.nickname;\n    }\n    get participantId() {\n        return this.privTextResponse.participantId;\n    }\n    get roomid() {\n        return this.privTextResponse.roomid;\n    }\n    get timestamp() {\n        return this.privTextResponse.timestamp;\n    }\n    get type() {\n        return this.privTextResponse.type;\n    }\n    static fromJSON(json) {\n        return new TextResponsePayload(json);\n    }\n}\n\n//# sourceMappingURL=TranslationResponsePayload.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/TranslationResponsePayload.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/TranscriberRecognizer.js":
  /*!*************************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/TranscriberRecognizer.js ***!
    \*************************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"TranscriberRecognizer\": () => (/* binding */ TranscriberRecognizer)\n/* harmony export */ });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js\");\n/* harmony import */ var _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../sdk/Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Recognizer.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranscriberConnectionFactory.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranscriptionServiceRecognizer.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\n\nclass TranscriberRecognizer extends _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.Recognizer {\n    /**\n     * TranscriberRecognizer constructor.\n     * @constructor\n     * @param {SpeechTranslationConfig} speechTranslationConfig - Non-audio configuration associated with the recognizer\n     * @param {AudioConfig} audioConfig - An audio configuration associated with the recognizer\n     */\n    constructor(speechTranslationConfig, audioConfig) {\n        const speechTranslationConfigImpl = speechTranslationConfig;\n        _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNull(speechTranslationConfigImpl, \"speechTranslationConfig\");\n        const audioConfigImpl = audioConfig;\n        _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNull(audioConfigImpl, \"audioConfigImpl\");\n        _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(speechTranslationConfigImpl.speechRecognitionLanguage, _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId[_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_RecoLanguage]);\n        super(audioConfig, speechTranslationConfigImpl.properties, new _Exports__WEBPACK_IMPORTED_MODULE_3__.TranscriberConnectionFactory());\n        this.privDisposedRecognizer = false;\n    }\n    get speechRecognitionLanguage() {\n        _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposedRecognizer);\n        return this.properties.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_RecoLanguage);\n    }\n    get properties() {\n        return this.privProperties;\n    }\n    get authorizationToken() {\n        return this.properties.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceAuthorization_Token);\n    }\n    set authorizationToken(token) {\n        _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(token, \"token\");\n        this.properties.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceAuthorization_Token, token);\n    }\n    set conversation(c) {\n        _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrUndefined(c, \"Conversation\");\n        this.privConversation = c;\n    }\n    getConversationInfo() {\n        _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrUndefined(this.privConversation, \"Conversation\");\n        return this.privConversation.conversationInfo;\n    }\n    startContinuousRecognitionAsync(cb, err) {\n        (0,_common_Exports__WEBPACK_IMPORTED_MODULE_4__.marshalPromiseToCallbacks)(this.startContinuousRecognitionAsyncImpl(_Exports__WEBPACK_IMPORTED_MODULE_5__.RecognitionMode.Conversation), cb, err);\n    }\n    stopContinuousRecognitionAsync(cb, err) {\n        (0,_common_Exports__WEBPACK_IMPORTED_MODULE_4__.marshalPromiseToCallbacks)(this.stopContinuousRecognitionAsyncImpl(), cb, err);\n    }\n    close() {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (!this.privDisposedRecognizer) {\n                yield this.dispose(true);\n            }\n        });\n    }\n    // Push async join/leave conversation message via serviceRecognizer\n    pushConversationEvent(conversationInfo, command) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const reco = (this.privReco);\n            _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrUndefined(reco, \"serviceRecognizer\");\n            yield reco.sendSpeechEventAsync(conversationInfo, command);\n        });\n    }\n    enforceAudioGating() {\n        return __awaiter(this, void 0, void 0, function* () {\n            const audioConfigImpl = this.audioConfig;\n            const format = yield audioConfigImpl.format;\n            const channels = format.channels;\n            if (channels === 1) {\n                if (this.properties.getProperty(\"f0f5debc-f8c9-4892-ac4b-90a7ab359fd2\", \"false\").toLowerCase() !== \"true\") {\n                    throw new Error(\"Single channel audio configuration for ConversationTranscriber is currently under private preview, please contact diarizationrequest@microsoft.com for more details\");\n                }\n            }\n            else if (channels !== 8) {\n                throw new Error(`Unsupported audio configuration: Detected ${channels}-channel audio`);\n            }\n            return;\n        });\n    }\n    connectCallbacks(transcriber) {\n        this.canceled = (s, e) => {\n            if (!!transcriber.canceled) {\n                transcriber.canceled(transcriber, e);\n            }\n        };\n        this.recognizing = (s, e) => {\n            if (!!transcriber.transcribing) {\n                transcriber.transcribing(transcriber, e);\n            }\n        };\n        this.recognized = (s, e) => {\n            if (!!transcriber.transcribed) {\n                transcriber.transcribed(transcriber, e);\n            }\n        };\n        this.sessionStarted = (s, e) => {\n            if (!!transcriber.sessionStarted) {\n                transcriber.sessionStarted(transcriber, e);\n            }\n        };\n        this.sessionStopped = (s, e) => {\n            if (!!transcriber.sessionStopped) {\n                transcriber.sessionStopped(transcriber, e);\n            }\n        };\n    }\n    disconnectCallbacks() {\n        this.canceled = undefined;\n        this.recognizing = undefined;\n        this.recognized = undefined;\n        this.sessionStarted = undefined;\n        this.sessionStopped = undefined;\n    }\n    /**\n     * Disposes any resources held by the object.\n     * @member ConversationTranscriber.prototype.dispose\n     * @function\n     * @public\n     * @param {boolean} disposing - true if disposing the object.\n     */\n    dispose(disposing) {\n        const _super = Object.create(null, {\n            dispose: { get: () => super.dispose }\n        });\n        return __awaiter(this, void 0, void 0, function* () {\n            if (this.privDisposedRecognizer) {\n                return;\n            }\n            if (disposing) {\n                this.privDisposedRecognizer = true;\n                yield this.implRecognizerStop();\n            }\n            yield _super.dispose.call(this, disposing);\n        });\n    }\n    createRecognizerConfig(speechConfig) {\n        return new _Exports__WEBPACK_IMPORTED_MODULE_5__.RecognizerConfig(speechConfig, this.properties);\n    }\n    createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {\n        const configImpl = audioConfig;\n        return new _Exports__WEBPACK_IMPORTED_MODULE_6__.TranscriptionServiceRecognizer(authentication, connectionFactory, configImpl, recognizerConfig, this);\n    }\n}\n\n//# sourceMappingURL=TranscriberRecognizer.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/TranscriberRecognizer.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranscriptionServiceRecognizer.js":
  /*!********************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranscriptionServiceRecognizer.js ***!
    \********************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"TranscriptionServiceRecognizer\": () => (/* binding */ TranscriptionServiceRecognizer)\n/* harmony export */ });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionEventArgs.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConversationTranscriptionCanceledEventArgs.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionResult.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConversationServiceRecognizer.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./SpeechConnectionMessage.Internal */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionMessage.Internal.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\n\n// eslint-disable-next-line max-classes-per-file\nclass TranscriptionServiceRecognizer extends _Exports__WEBPACK_IMPORTED_MODULE_0__.ConversationServiceRecognizer {\n    constructor(authentication, connectionFactory, audioSource, recognizerConfig, transcriber) {\n        super(authentication, connectionFactory, audioSource, recognizerConfig, transcriber);\n        this.privTranscriberRecognizer = transcriber;\n        this.sendPrePayloadJSONOverride = (connection) => this.sendTranscriptionStartJSON(connection);\n        if (this.privRecognizerConfig.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceResponse_RequestWordLevelTimestamps) === \"true\") {\n            this.privSpeechContext.setWordLevelTimings();\n        }\n    }\n    sendSpeechEventAsync(info, command) {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (!!this.privRequestSession.isRecognizing) {\n                const connection = yield this.fetchConnection();\n                yield this.sendSpeechEvent(connection, this.createSpeechEventPayload(info, command));\n            }\n        });\n    }\n    processTypeSpecificMessages(connectionMessage) {\n        return this.processSpeechMessages(connectionMessage);\n    }\n    handleRecognizedCallback(result, offset, sessionId) {\n        try {\n            const event = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeechRecognitionEventArgs(result, offset, sessionId);\n            this.privTranscriberRecognizer.recognized(this.privTranscriberRecognizer, event);\n            if (!!this.privSuccessCallback) {\n                try {\n                    this.privSuccessCallback(result);\n                }\n                catch (e) {\n                    if (!!this.privErrorCallback) {\n                        this.privErrorCallback(e);\n                    }\n                }\n                // Only invoke the call back once.\n                // and if it's successful don't invoke the\n                // error after that.\n                this.privSuccessCallback = undefined;\n                this.privErrorCallback = undefined;\n            }\n            /* eslint-disable no-empty */\n        }\n        catch (error) {\n            // Not going to let errors in the event handler\n            // trip things up.\n        }\n    }\n    handleRecognizingCallback(result, duration, sessionId) {\n        try {\n            const ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeechRecognitionEventArgs(result, duration, sessionId);\n            this.privTranscriberRecognizer.recognizing(this.privTranscriberRecognizer, ev);\n            /* eslint-disable no-empty */\n        }\n        catch (error) {\n            // Not going to let errors in the event handler\n            // trip things up.\n        }\n    }\n    // Cancels recognition.\n    cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {\n        const properties = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyCollection();\n        properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.CancellationErrorCodePropertyName, _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.CancellationErrorCode[errorCode]);\n        if (!!this.privTranscriberRecognizer.canceled) {\n            const cancelEvent = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.ConversationTranscriptionCanceledEventArgs(cancellationReason, error, errorCode, undefined, sessionId);\n            try {\n                this.privTranscriberRecognizer.canceled(this.privTranscriberRecognizer, cancelEvent);\n                /* eslint-disable no-empty */\n            }\n            catch (_a) { }\n        }\n        if (!!this.privSuccessCallback) {\n            const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_7__.SpeechRecognitionResult(requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__.ResultReason.Canceled, undefined, // Text\n            undefined, // Duration\n            undefined, // Offset\n            undefined, // Language\n            undefined, // Language Detection Confidence\n            undefined, // Speaker Id\n            error, undefined, // Json\n            properties);\n            try {\n                this.privSuccessCallback(result);\n                this.privSuccessCallback = undefined;\n                /* eslint-disable no-empty */\n            }\n            catch (_b) { }\n        }\n    }\n    // Encapsulated for derived service recognizers that need to send additional JSON\n    sendTranscriptionStartJSON(connection) {\n        return __awaiter(this, void 0, void 0, function* () {\n            yield this.sendSpeechContext(connection, true);\n            const info = this.privTranscriberRecognizer.getConversationInfo();\n            const payload = this.createSpeechEventPayload(info, \"start\");\n            yield this.sendSpeechEvent(connection, payload);\n            yield this.sendWaveHeader(connection);\n            return;\n        });\n    }\n    sendSpeechEvent(connection, payload) {\n        const speechEventJson = JSON.stringify(payload);\n        if (speechEventJson) {\n            return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_9__.SpeechConnectionMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_10__.MessageType.Text, \"speech.event\", this.privRequestSession.requestId, \"application/json\", speechEventJson));\n        }\n        return;\n    }\n    createSpeechEventPayload(info, command) {\n        const eventDict = { id: \"meeting\", name: command, meeting: info.conversationProperties };\n        eventDict.meeting.id = info.id;\n        eventDict.meeting.attendees = info.participants;\n        eventDict.meeting.record = info.conversationProperties.audiorecording === \"on\" ? \"true\" : \"false\";\n        return eventDict;\n    }\n}\n\n//# sourceMappingURL=TranscriptionServiceRecognizer.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranscriptionServiceRecognizer.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationConnectionFactory.js":
  /*!******************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationConnectionFactory.js ***!
    \******************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"TranslationConnectionFactory\": () => (/* binding */ TranslationConnectionFactory)\n/* harmony export */ });\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketConnection.js\");\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ProxyInfo.js\");\n/* harmony import */ var _common_StringUtils__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../common/StringUtils */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/StringUtils.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./ConnectionFactoryBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/WebsocketMessageFormatter.js\");\n/* harmony import */ var _HeaderNames__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./HeaderNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js\");\n/* harmony import */ var _QueryParameterNames__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./QueryParameterNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/QueryParameterNames.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\n\n\n\n\nclass TranslationConnectionFactory extends _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__.ConnectionFactoryBase {\n    create(config, authInfo, connectionId) {\n        const endpoint = this.getEndpointUrl(config);\n        const queryParams = {};\n        this.setQueryParams(queryParams, config, endpoint);\n        const headers = {};\n        if (authInfo.token !== undefined && authInfo.token !== \"\") {\n            headers[authInfo.headerName] = authInfo.token;\n        }\n        headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_1__.HeaderNames.ConnectionId] = connectionId;\n        config.parameters.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_Url, endpoint);\n        const enableCompression = config.parameters.getProperty(\"SPEECH-EnableWebsocketCompression\", \"false\") === \"true\";\n        return new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_3__.WebsocketConnection(endpoint, queryParams, headers, new _Exports__WEBPACK_IMPORTED_MODULE_4__.WebsocketMessageFormatter(), _common_browser_Exports__WEBPACK_IMPORTED_MODULE_5__.ProxyInfo.fromRecognizerConfig(config), enableCompression, connectionId);\n    }\n    getEndpointUrl(config, returnRegionPlaceholder) {\n        const region = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_Region);\n        const hostSuffix = _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__.ConnectionFactoryBase.getHostSuffix(region);\n        let endpointUrl = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_Endpoint, undefined);\n        if (!endpointUrl) {\n            const host = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_Host, \"wss://{region}.s2s.speech\" + hostSuffix);\n            endpointUrl = host + \"/speech/translation/cognitiveservices/v1\";\n        }\n        if (returnRegionPlaceholder === true) {\n            return endpointUrl;\n        }\n        return _common_StringUtils__WEBPACK_IMPORTED_MODULE_6__.StringUtils.formatString(endpointUrl, { region });\n    }\n    setQueryParams(queryParams, config, endpointUrl) {\n        queryParams.from = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_RecoLanguage);\n        queryParams.to = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_TranslationToLanguages);\n        this.setCommonUrlParams(config, queryParams, endpointUrl);\n        this.setUrlParameter(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceResponse_TranslationRequestStablePartialResult, _QueryParameterNames__WEBPACK_IMPORTED_MODULE_7__.QueryParameterNames.StableTranslation, config, queryParams, endpointUrl);\n        const translationVoice = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_TranslationVoice, undefined);\n        if (translationVoice !== undefined) {\n            queryParams.voice = translationVoice;\n            queryParams.features = \"texttospeech\";\n        }\n    }\n}\n\n//# sourceMappingURL=TranslationConnectionFactory.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationConnectionFactory.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationServiceRecognizer.js":
  /*!******************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationServiceRecognizer.js ***!
    \******************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"TranslationServiceRecognizer\": () => (/* binding */ TranslationServiceRecognizer)\n/* harmony export */ });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_19__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationStatus.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionResult.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionEventArgs.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationSynthesisResult.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationSynthesisEventArgs.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionCanceledEventArgs.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationReason.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_18__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Translations.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConversationServiceRecognizer.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/Enums.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/EnumTranslation.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationHypothesis.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationPhrase.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationSynthesisEnd.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\n// eslint-disable-next-line max-classes-per-file\nclass TranslationServiceRecognizer extends _Exports__WEBPACK_IMPORTED_MODULE_0__.ConversationServiceRecognizer {\n    constructor(authentication, connectionFactory, audioSource, recognizerConfig, translationRecognizer) {\n        super(authentication, connectionFactory, audioSource, recognizerConfig, translationRecognizer);\n        this.privTranslationRecognizer = translationRecognizer;\n        this.connectionEvents.attach((connectionEvent) => {\n            if (connectionEvent.name === \"ConnectionEstablishedEvent\") {\n                this.privTranslationRecognizer.onConnection();\n            }\n            else if (connectionEvent.name === \"ConnectionClosedEvent\") {\n                void this.privTranslationRecognizer.onDisconnection();\n            }\n        });\n    }\n    processTypeSpecificMessages(connectionMessage) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const resultProps = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyCollection();\n            let processed = yield this.processSpeechMessages(connectionMessage);\n            if (processed) {\n                return true;\n            }\n            const handleTranslationPhrase = (translatedPhrase) => __awaiter(this, void 0, void 0, function* () {\n                this.privRequestSession.onPhraseRecognized(this.privRequestSession.currentTurnAudioOffset + translatedPhrase.Offset + translatedPhrase.Duration);\n                if (translatedPhrase.RecognitionStatus === _Exports__WEBPACK_IMPORTED_MODULE_2__.RecognitionStatus.Success) {\n                    // OK, the recognition was successful. How'd the translation do?\n                    const result = this.fireEventForResult(translatedPhrase, resultProps);\n                    if (!!this.privTranslationRecognizer.recognized) {\n                        try {\n                            this.privTranslationRecognizer.recognized(this.privTranslationRecognizer, result);\n                            /* eslint-disable no-empty */\n                        }\n                        catch (error) {\n                            // Not going to let errors in the event handler\n                            // trip things up.\n                        }\n                    }\n                    // report result to promise.\n                    if (!!this.privSuccessCallback) {\n                        try {\n                            this.privSuccessCallback(result.result);\n                        }\n                        catch (e) {\n                            if (!!this.privErrorCallback) {\n                                this.privErrorCallback(e);\n                            }\n                        }\n                        // Only invoke the call back once.\n                        // and if it's successful don't invoke the\n                        // error after that.\n                        this.privSuccessCallback = undefined;\n                        this.privErrorCallback = undefined;\n                    }\n                }\n                else {\n                    const reason = _Exports__WEBPACK_IMPORTED_MODULE_3__.EnumTranslation.implTranslateRecognitionResult(translatedPhrase.RecognitionStatus);\n                    const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.TranslationRecognitionResult(undefined, this.privRequestSession.requestId, reason, translatedPhrase.Text, translatedPhrase.Duration, this.privRequestSession.currentTurnAudioOffset + translatedPhrase.Offset, undefined, connectionMessage.textBody, resultProps);\n                    if (reason === _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.Canceled) {\n                        const cancelReason = _Exports__WEBPACK_IMPORTED_MODULE_3__.EnumTranslation.implTranslateCancelResult(translatedPhrase.RecognitionStatus);\n                        const cancellationErrorCode = _Exports__WEBPACK_IMPORTED_MODULE_3__.EnumTranslation.implTranslateCancelErrorCode(translatedPhrase.RecognitionStatus);\n                        yield this.cancelRecognitionLocal(cancelReason, cancellationErrorCode, _Exports__WEBPACK_IMPORTED_MODULE_3__.EnumTranslation.implTranslateErrorDetails(cancellationErrorCode));\n                    }\n                    else {\n                        if (!(this.privRequestSession.isSpeechEnded && reason === _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.NoMatch && translatedPhrase.RecognitionStatus !== _Exports__WEBPACK_IMPORTED_MODULE_2__.RecognitionStatus.InitialSilenceTimeout)) {\n                            const ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.TranslationRecognitionEventArgs(result, result.offset, this.privRequestSession.sessionId);\n                            if (!!this.privTranslationRecognizer.recognized) {\n                                try {\n                                    this.privTranslationRecognizer.recognized(this.privTranslationRecognizer, ev);\n                                    /* eslint-disable no-empty */\n                                }\n                                catch (error) {\n                                    // Not going to let errors in the event handler\n                                    // trip things up.\n                                }\n                            }\n                        }\n                        // report result to promise.\n                        if (!!this.privSuccessCallback) {\n                            try {\n                                this.privSuccessCallback(result);\n                            }\n                            catch (e) {\n                                if (!!this.privErrorCallback) {\n                                    this.privErrorCallback(e);\n                                }\n                            }\n                            // Only invoke the call back once.\n                            // and if it's successful don't invoke the\n                            // error after that.\n                            this.privSuccessCallback = undefined;\n                            this.privErrorCallback = undefined;\n                        }\n                    }\n                    processed = true;\n                }\n            });\n            if (connectionMessage.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_7__.MessageType.Text) {\n                resultProps.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_8__.PropertyId.SpeechServiceResponse_JsonResult, connectionMessage.textBody);\n            }\n            switch (connectionMessage.path.toLowerCase()) {\n                case \"translation.hypothesis\":\n                    const result = this.fireEventForResult(_Exports__WEBPACK_IMPORTED_MODULE_9__.TranslationHypothesis.fromJSON(connectionMessage.textBody), resultProps);\n                    this.privRequestSession.onHypothesis(this.privRequestSession.currentTurnAudioOffset + result.offset);\n                    if (!!this.privTranslationRecognizer.recognizing) {\n                        try {\n                            this.privTranslationRecognizer.recognizing(this.privTranslationRecognizer, result);\n                            /* eslint-disable no-empty */\n                        }\n                        catch (error) {\n                            // Not going to let errors in the event handler\n                            // trip things up.\n                        }\n                    }\n                    processed = true;\n                    break;\n                case \"translation.response\":\n                    const phrase = JSON.parse(connectionMessage.textBody);\n                    if (!!phrase.SpeechPhrase) {\n                        yield handleTranslationPhrase(_Exports__WEBPACK_IMPORTED_MODULE_10__.TranslationPhrase.fromTranslationResponse(phrase));\n                    }\n                    break;\n                case \"translation.phrase\":\n                    yield handleTranslationPhrase(_Exports__WEBPACK_IMPORTED_MODULE_10__.TranslationPhrase.fromJSON(connectionMessage.textBody));\n                    break;\n                case \"translation.synthesis\":\n                    this.sendSynthesisAudio(connectionMessage.binaryBody, this.privRequestSession.sessionId);\n                    processed = true;\n                    break;\n                case \"translation.synthesis.end\":\n                    const synthEnd = _Exports__WEBPACK_IMPORTED_MODULE_11__.TranslationSynthesisEnd.fromJSON(connectionMessage.textBody);\n                    switch (synthEnd.SynthesisStatus) {\n                        case _Exports__WEBPACK_IMPORTED_MODULE_2__.SynthesisStatus.Error:\n                            if (!!this.privTranslationRecognizer.synthesizing) {\n                                const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_12__.TranslationSynthesisResult(_sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.Canceled, undefined);\n                                const retEvent = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_13__.TranslationSynthesisEventArgs(result, this.privRequestSession.sessionId);\n                                try {\n                                    this.privTranslationRecognizer.synthesizing(this.privTranslationRecognizer, retEvent);\n                                    /* eslint-disable no-empty */\n                                }\n                                catch (error) {\n                                    // Not going to let errors in the event handler\n                                    // trip things up.\n                                }\n                            }\n                            if (!!this.privTranslationRecognizer.canceled) {\n                                // And raise a canceled event to send the rich(er) error message back.\n                                const canceledResult = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_14__.TranslationRecognitionCanceledEventArgs(this.privRequestSession.sessionId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_15__.CancellationReason.Error, synthEnd.FailureReason, _sdk_Exports__WEBPACK_IMPORTED_MODULE_16__.CancellationErrorCode.ServiceError, null);\n                                try {\n                                    this.privTranslationRecognizer.canceled(this.privTranslationRecognizer, canceledResult);\n                                    /* eslint-disable no-empty */\n                                }\n                                catch (error) {\n                                    // Not going to let errors in the event handler\n                                    // trip things up.\n                                }\n                            }\n                            break;\n                        case _Exports__WEBPACK_IMPORTED_MODULE_2__.SynthesisStatus.Success:\n                            this.sendSynthesisAudio(undefined, this.privRequestSession.sessionId);\n                            break;\n                        default:\n                            break;\n                    }\n                    processed = true;\n                    break;\n                default:\n                    break;\n            }\n            return processed;\n        });\n    }\n    // Cancels recognition.\n    cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {\n        const properties = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyCollection();\n        properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_17__.CancellationErrorCodePropertyName, _sdk_Exports__WEBPACK_IMPORTED_MODULE_16__.CancellationErrorCode[errorCode]);\n        if (!!this.privTranslationRecognizer.canceled) {\n            const cancelEvent = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_14__.TranslationRecognitionCanceledEventArgs(sessionId, cancellationReason, error, errorCode, undefined);\n            try {\n                this.privTranslationRecognizer.canceled(this.privTranslationRecognizer, cancelEvent);\n                /* eslint-disable no-empty */\n            }\n            catch (_a) { }\n        }\n        if (!!this.privSuccessCallback) {\n            const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.TranslationRecognitionResult(undefined, // Translations\n            requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.Canceled, undefined, // Text\n            undefined, // Druation\n            undefined, // Offset\n            error, undefined, // Json\n            properties);\n            try {\n                this.privSuccessCallback(result);\n                /* eslint-disable no-empty */\n                this.privSuccessCallback = undefined;\n            }\n            catch (_b) { }\n        }\n    }\n    handleRecognizingCallback(result, duration, sessionId) {\n        try {\n            const ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.TranslationRecognitionEventArgs(_sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.TranslationRecognitionResult.fromSpeechRecognitionResult(result), duration, sessionId);\n            this.privTranslationRecognizer.recognizing(this.privTranslationRecognizer, ev);\n            /* eslint-disable no-empty */\n        }\n        catch (error) {\n            // Not going to let errors in the event handler\n            // trip things up.\n        }\n    }\n    handleRecognizedCallback(result, offset, sessionId) {\n        try {\n            const ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.TranslationRecognitionEventArgs(_sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.TranslationRecognitionResult.fromSpeechRecognitionResult(result), offset, sessionId);\n            this.privTranslationRecognizer.recognized(this.privTranslationRecognizer, ev);\n        }\n        catch (error) {\n            // Not going to let errors in the event handler\n            // trip things up.\n        }\n    }\n    fireEventForResult(serviceResult, properties) {\n        let translations;\n        if (undefined !== serviceResult.Translation.Translations) {\n            translations = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_18__.Translations();\n            for (const translation of serviceResult.Translation.Translations) {\n                translations.set(translation.Language, translation.Text || translation.DisplayText);\n            }\n        }\n        let resultReason;\n        if (serviceResult instanceof _Exports__WEBPACK_IMPORTED_MODULE_10__.TranslationPhrase) {\n            if (!!serviceResult.Translation && serviceResult.Translation.TranslationStatus === _common_Exports__WEBPACK_IMPORTED_MODULE_19__.TranslationStatus.Success) {\n                resultReason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.TranslatedSpeech;\n            }\n            else {\n                resultReason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.RecognizedSpeech;\n            }\n        }\n        else {\n            resultReason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.TranslatingSpeech;\n        }\n        const offset = serviceResult.Offset + this.privRequestSession.currentTurnAudioOffset;\n        const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.TranslationRecognitionResult(translations, this.privRequestSession.requestId, resultReason, serviceResult.Text, serviceResult.Duration, offset, serviceResult.Translation.FailureReason, JSON.stringify(serviceResult), properties);\n        const ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.TranslationRecognitionEventArgs(result, offset, this.privRequestSession.sessionId);\n        return ev;\n    }\n    sendSynthesisAudio(audio, sessionId) {\n        const reason = (undefined === audio) ? _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.SynthesizingAudioCompleted : _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.SynthesizingAudio;\n        const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_12__.TranslationSynthesisResult(reason, audio);\n        const retEvent = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_13__.TranslationSynthesisEventArgs(result, sessionId);\n        if (!!this.privTranslationRecognizer.synthesizing) {\n            try {\n                this.privTranslationRecognizer.synthesizing(this.privTranslationRecognizer, retEvent);\n                /* eslint-disable no-empty */\n            }\n            catch (error) {\n                // Not going to let errors in the event handler\n                // trip things up.\n            }\n        }\n    }\n}\n\n//# sourceMappingURL=TranslationServiceRecognizer.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationServiceRecognizer.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationStatus.js":
  /*!*******************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationStatus.js ***!
    \*******************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"TranslationStatus\": () => (/* binding */ TranslationStatus)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines translation status.\n * @class TranslationStatus\n */\nvar TranslationStatus;\n(function (TranslationStatus) {\n    /**\n     * @member TranslationStatus.Success\n     */\n    TranslationStatus[TranslationStatus[\"Success\"] = 0] = \"Success\";\n    /**\n     * @member TranslationStatus.Error\n     */\n    TranslationStatus[TranslationStatus[\"Error\"] = 1] = \"Error\";\n})(TranslationStatus || (TranslationStatus = {}));\n\n//# sourceMappingURL=TranslationStatus.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationStatus.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/WebsocketMessageFormatter.js":
  /*!***************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/WebsocketMessageFormatter.js ***!
    \***************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"WebsocketMessageFormatter\": () => (/* binding */ WebsocketMessageFormatter)\n/* harmony export */ });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/RawWebsocketMessage.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nconst CRLF = \"\\r\\n\";\nclass WebsocketMessageFormatter {\n    toConnectionMessage(message) {\n        const deferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_0__.Deferred();\n        try {\n            if (message.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_1__.MessageType.Text) {\n                const textMessage = message.textContent;\n                let headers = {};\n                let body = null;\n                if (textMessage) {\n                    const headerBodySplit = textMessage.split(\"\\r\\n\\r\\n\");\n                    if (headerBodySplit && headerBodySplit.length > 0) {\n                        headers = this.parseHeaders(headerBodySplit[0]);\n                        if (headerBodySplit.length > 1) {\n                            body = headerBodySplit[1];\n                        }\n                    }\n                }\n                deferral.resolve(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.ConnectionMessage(message.messageType, body, headers, message.id));\n            }\n            else if (message.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_1__.MessageType.Binary) {\n                const binaryMessage = message.binaryContent;\n                let headers = {};\n                let body = null;\n                if (!binaryMessage || binaryMessage.byteLength < 2) {\n                    throw new Error(\"Invalid binary message format. Header length missing.\");\n                }\n                const dataView = new DataView(binaryMessage);\n                const headerLength = dataView.getInt16(0);\n                if (binaryMessage.byteLength < headerLength + 2) {\n                    throw new Error(\"Invalid binary message format. Header content missing.\");\n                }\n                let headersString = \"\";\n                for (let i = 0; i < headerLength; i++) {\n                    headersString += String.fromCharCode((dataView).getInt8(i + 2));\n                }\n                headers = this.parseHeaders(headersString);\n                if (binaryMessage.byteLength > headerLength + 2) {\n                    body = binaryMessage.slice(2 + headerLength);\n                }\n                deferral.resolve(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.ConnectionMessage(message.messageType, body, headers, message.id));\n            }\n        }\n        catch (e) {\n            deferral.reject(`Error formatting the message. Error: ${e}`);\n        }\n        return deferral.promise;\n    }\n    fromConnectionMessage(message) {\n        const deferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_0__.Deferred();\n        try {\n            if (message.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_1__.MessageType.Text) {\n                const payload = `${this.makeHeaders(message)}${CRLF}${message.textBody ? message.textBody : \"\"}`;\n                deferral.resolve(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.RawWebsocketMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_1__.MessageType.Text, payload, message.id));\n            }\n            else if (message.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_1__.MessageType.Binary) {\n                const headersString = this.makeHeaders(message);\n                const content = message.binaryBody;\n                const headerBuffer = this.stringToArrayBuffer(headersString);\n                const headerInt8Array = new Int8Array(headerBuffer);\n                const headerLength = headerInt8Array.byteLength;\n                const payloadInt8Array = new Int8Array(2 + headerLength + (content ? content.byteLength : 0));\n                payloadInt8Array[0] = ((headerLength >> 8) & 0xff);\n                payloadInt8Array[1] = headerLength & 0xff;\n                payloadInt8Array.set(headerInt8Array, 2);\n                if (content) {\n                    const bodyInt8Array = new Int8Array(content);\n                    payloadInt8Array.set(bodyInt8Array, 2 + headerLength);\n                }\n                const payload = payloadInt8Array.buffer;\n                deferral.resolve(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.RawWebsocketMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_1__.MessageType.Binary, payload, message.id));\n            }\n        }\n        catch (e) {\n            deferral.reject(`Error formatting the message. ${e}`);\n        }\n        return deferral.promise;\n    }\n    makeHeaders(message) {\n        let headersString = \"\";\n        if (message.headers) {\n            for (const header in message.headers) {\n                if (header) {\n                    headersString += `${header}: ${message.headers[header]}${CRLF}`;\n                }\n            }\n        }\n        return headersString;\n    }\n    parseHeaders(headersString) {\n        const headers = {};\n        if (headersString) {\n            const headerMatches = headersString.match(/[^\\r\\n]+/g);\n            if (headers) {\n                for (const header of headerMatches) {\n                    if (header) {\n                        const separatorIndex = header.indexOf(\":\");\n                        const headerName = separatorIndex > 0 ? header.substr(0, separatorIndex).trim().toLowerCase() : header;\n                        const headerValue = separatorIndex > 0 && header.length > (separatorIndex + 1) ?\n                            header.substr(separatorIndex + 1).trim() :\n                            \"\";\n                        headers[headerName] = headerValue;\n                    }\n                }\n            }\n        }\n        return headers;\n    }\n    stringToArrayBuffer(str) {\n        const buffer = new ArrayBuffer(str.length);\n        const view = new DataView(buffer);\n        for (let i = 0; i < str.length; i++) {\n            view.setUint8(i, str.charCodeAt(i));\n        }\n        return buffer;\n    }\n}\n\n//# sourceMappingURL=WebsocketMessageFormatter.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/WebsocketMessageFormatter.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/AudioSourceEvents.js":
  /*!************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/AudioSourceEvents.js ***!
    \************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AudioSourceErrorEvent\": () => (/* binding */ AudioSourceErrorEvent),\n/* harmony export */   \"AudioSourceEvent\": () => (/* binding */ AudioSourceEvent),\n/* harmony export */   \"AudioSourceInitializingEvent\": () => (/* binding */ AudioSourceInitializingEvent),\n/* harmony export */   \"AudioSourceOffEvent\": () => (/* binding */ AudioSourceOffEvent),\n/* harmony export */   \"AudioSourceReadyEvent\": () => (/* binding */ AudioSourceReadyEvent),\n/* harmony export */   \"AudioStreamNodeAttachedEvent\": () => (/* binding */ AudioStreamNodeAttachedEvent),\n/* harmony export */   \"AudioStreamNodeAttachingEvent\": () => (/* binding */ AudioStreamNodeAttachingEvent),\n/* harmony export */   \"AudioStreamNodeDetachedEvent\": () => (/* binding */ AudioStreamNodeDetachedEvent),\n/* harmony export */   \"AudioStreamNodeErrorEvent\": () => (/* binding */ AudioStreamNodeErrorEvent),\n/* harmony export */   \"AudioStreamNodeEvent\": () => (/* binding */ AudioStreamNodeEvent)\n/* harmony export */ });\n/* harmony import */ var _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./PlatformEvent */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/PlatformEvent.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/* eslint-disable max-classes-per-file */\n\nclass AudioSourceEvent extends _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.PlatformEvent {\n    constructor(eventName, audioSourceId, eventType = _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Info) {\n        super(eventName, eventType);\n        this.privAudioSourceId = audioSourceId;\n    }\n    get audioSourceId() {\n        return this.privAudioSourceId;\n    }\n}\nclass AudioSourceInitializingEvent extends AudioSourceEvent {\n    constructor(audioSourceId) {\n        super(\"AudioSourceInitializingEvent\", audioSourceId);\n    }\n}\nclass AudioSourceReadyEvent extends AudioSourceEvent {\n    constructor(audioSourceId) {\n        super(\"AudioSourceReadyEvent\", audioSourceId);\n    }\n}\nclass AudioSourceOffEvent extends AudioSourceEvent {\n    constructor(audioSourceId) {\n        super(\"AudioSourceOffEvent\", audioSourceId);\n    }\n}\nclass AudioSourceErrorEvent extends AudioSourceEvent {\n    constructor(audioSourceId, error) {\n        super(\"AudioSourceErrorEvent\", audioSourceId, _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Error);\n        this.privError = error;\n    }\n    get error() {\n        return this.privError;\n    }\n}\nclass AudioStreamNodeEvent extends AudioSourceEvent {\n    constructor(eventName, audioSourceId, audioNodeId) {\n        super(eventName, audioSourceId);\n        this.privAudioNodeId = audioNodeId;\n    }\n    get audioNodeId() {\n        return this.privAudioNodeId;\n    }\n}\nclass AudioStreamNodeAttachingEvent extends AudioStreamNodeEvent {\n    constructor(audioSourceId, audioNodeId) {\n        super(\"AudioStreamNodeAttachingEvent\", audioSourceId, audioNodeId);\n    }\n}\nclass AudioStreamNodeAttachedEvent extends AudioStreamNodeEvent {\n    constructor(audioSourceId, audioNodeId) {\n        super(\"AudioStreamNodeAttachedEvent\", audioSourceId, audioNodeId);\n    }\n}\nclass AudioStreamNodeDetachedEvent extends AudioStreamNodeEvent {\n    constructor(audioSourceId, audioNodeId) {\n        super(\"AudioStreamNodeDetachedEvent\", audioSourceId, audioNodeId);\n    }\n}\nclass AudioStreamNodeErrorEvent extends AudioStreamNodeEvent {\n    constructor(audioSourceId, audioNodeId, error) {\n        super(\"AudioStreamNodeErrorEvent\", audioSourceId, audioNodeId);\n        this.privError = error;\n    }\n    get error() {\n        return this.privError;\n    }\n}\n\n//# sourceMappingURL=AudioSourceEvents.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/AudioSourceEvents.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/BackgroundError.js":
  /*!**********************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/BackgroundError.js ***!
    \**********************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"BackgroundEvent\": () => (/* binding */ BackgroundEvent)\n/* harmony export */ });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/PlatformEvent.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nclass BackgroundEvent extends _Exports__WEBPACK_IMPORTED_MODULE_0__.PlatformEvent {\n    constructor(error) {\n        super(\"BackgroundEvent\", _Exports__WEBPACK_IMPORTED_MODULE_0__.EventType.Error);\n        this.privError = error;\n    }\n    get error() {\n        return this.privError;\n    }\n}\n\n//# sourceMappingURL=BackgroundError.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/BackgroundError.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ChunkedArrayBufferStream.js":
  /*!*******************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ChunkedArrayBufferStream.js ***!
    \*******************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ChunkedArrayBufferStream\": () => (/* binding */ ChunkedArrayBufferStream)\n/* harmony export */ });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Stream.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nclass ChunkedArrayBufferStream extends _Exports__WEBPACK_IMPORTED_MODULE_0__.Stream {\n    constructor(targetChunkSize, streamId) {\n        super(streamId);\n        this.privTargetChunkSize = targetChunkSize;\n        this.privNextBufferReadyBytes = 0;\n    }\n    writeStreamChunk(chunk) {\n        // No pending write, and the buffer is the right size so write it.\n        if (chunk.isEnd ||\n            (0 === this.privNextBufferReadyBytes && chunk.buffer.byteLength === this.privTargetChunkSize)) {\n            super.writeStreamChunk(chunk);\n            return;\n        }\n        let bytesCopiedFromBuffer = 0;\n        while (bytesCopiedFromBuffer < chunk.buffer.byteLength) {\n            // Fill the next buffer.\n            if (undefined === this.privNextBufferToWrite) {\n                this.privNextBufferToWrite = new ArrayBuffer(this.privTargetChunkSize);\n                this.privNextBufferStartTime = chunk.timeReceived;\n            }\n            // Find out how many bytes we can copy into the read buffer.\n            const bytesToCopy = Math.min(chunk.buffer.byteLength - bytesCopiedFromBuffer, this.privTargetChunkSize - this.privNextBufferReadyBytes);\n            const targetView = new Uint8Array(this.privNextBufferToWrite);\n            const sourceView = new Uint8Array(chunk.buffer.slice(bytesCopiedFromBuffer, bytesToCopy + bytesCopiedFromBuffer));\n            targetView.set(sourceView, this.privNextBufferReadyBytes);\n            this.privNextBufferReadyBytes += bytesToCopy;\n            bytesCopiedFromBuffer += bytesToCopy;\n            // Are we ready to write?\n            if (this.privNextBufferReadyBytes === this.privTargetChunkSize) {\n                super.writeStreamChunk({\n                    buffer: this.privNextBufferToWrite,\n                    isEnd: false,\n                    timeReceived: this.privNextBufferStartTime,\n                });\n                this.privNextBufferReadyBytes = 0;\n                this.privNextBufferToWrite = undefined;\n            }\n        }\n    }\n    close() {\n        // Send whatever is pending, then close the base class.\n        if (0 !== this.privNextBufferReadyBytes && !this.isClosed) {\n            super.writeStreamChunk({\n                buffer: this.privNextBufferToWrite.slice(0, this.privNextBufferReadyBytes),\n                isEnd: false,\n                timeReceived: this.privNextBufferStartTime,\n            });\n        }\n        super.close();\n    }\n}\n\n//# sourceMappingURL=ChunkedArrayBufferStream.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ChunkedArrayBufferStream.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionEvents.js":
  /*!***********************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionEvents.js ***!
    \***********************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConnectionClosedEvent\": () => (/* binding */ ConnectionClosedEvent),\n/* harmony export */   \"ConnectionErrorEvent\": () => (/* binding */ ConnectionErrorEvent),\n/* harmony export */   \"ConnectionEstablishErrorEvent\": () => (/* binding */ ConnectionEstablishErrorEvent),\n/* harmony export */   \"ConnectionEstablishedEvent\": () => (/* binding */ ConnectionEstablishedEvent),\n/* harmony export */   \"ConnectionEvent\": () => (/* binding */ ConnectionEvent),\n/* harmony export */   \"ConnectionMessageReceivedEvent\": () => (/* binding */ ConnectionMessageReceivedEvent),\n/* harmony export */   \"ConnectionMessageSentEvent\": () => (/* binding */ ConnectionMessageSentEvent),\n/* harmony export */   \"ConnectionStartEvent\": () => (/* binding */ ConnectionStartEvent),\n/* harmony export */   \"ServiceEvent\": () => (/* binding */ ServiceEvent)\n/* harmony export */ });\n/* harmony import */ var _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./PlatformEvent */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/PlatformEvent.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nclass ServiceEvent extends _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.PlatformEvent {\n    constructor(eventName, jsonstring, eventType = _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Info) {\n        super(eventName, eventType);\n        this.privJsonResult = jsonstring;\n    }\n    get jsonString() {\n        return this.privJsonResult;\n    }\n}\nclass ConnectionEvent extends _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.PlatformEvent {\n    constructor(eventName, connectionId, eventType = _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Info) {\n        super(eventName, eventType);\n        this.privConnectionId = connectionId;\n    }\n    get connectionId() {\n        return this.privConnectionId;\n    }\n}\nclass ConnectionStartEvent extends ConnectionEvent {\n    constructor(connectionId, uri, headers) {\n        super(\"ConnectionStartEvent\", connectionId);\n        this.privUri = uri;\n        this.privHeaders = headers;\n    }\n    get uri() {\n        return this.privUri;\n    }\n    get headers() {\n        return this.privHeaders;\n    }\n}\nclass ConnectionEstablishedEvent extends ConnectionEvent {\n    constructor(connectionId) {\n        super(\"ConnectionEstablishedEvent\", connectionId);\n    }\n}\nclass ConnectionClosedEvent extends ConnectionEvent {\n    constructor(connectionId, statusCode, reason) {\n        super(\"ConnectionClosedEvent\", connectionId, _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Debug);\n        this.privReason = reason;\n        this.privStatusCode = statusCode;\n    }\n    get reason() {\n        return this.privReason;\n    }\n    get statusCode() {\n        return this.privStatusCode;\n    }\n}\nclass ConnectionErrorEvent extends ConnectionEvent {\n    constructor(connectionId, message, type) {\n        super(\"ConnectionErrorEvent\", connectionId, _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Debug);\n        this.privMessage = message;\n        this.privType = type;\n    }\n    get message() {\n        return this.privMessage;\n    }\n    get type() {\n        return this.privType;\n    }\n}\nclass ConnectionEstablishErrorEvent extends ConnectionEvent {\n    constructor(connectionId, statuscode, reason) {\n        super(\"ConnectionEstablishErrorEvent\", connectionId, _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Error);\n        this.privStatusCode = statuscode;\n        this.privReason = reason;\n    }\n    get reason() {\n        return this.privReason;\n    }\n    get statusCode() {\n        return this.privStatusCode;\n    }\n}\nclass ConnectionMessageReceivedEvent extends ConnectionEvent {\n    constructor(connectionId, networkReceivedTimeISO, message) {\n        super(\"ConnectionMessageReceivedEvent\", connectionId);\n        this.privNetworkReceivedTime = networkReceivedTimeISO;\n        this.privMessage = message;\n    }\n    get networkReceivedTime() {\n        return this.privNetworkReceivedTime;\n    }\n    get message() {\n        return this.privMessage;\n    }\n}\nclass ConnectionMessageSentEvent extends ConnectionEvent {\n    constructor(connectionId, networkSentTimeISO, message) {\n        super(\"ConnectionMessageSentEvent\", connectionId);\n        this.privNetworkSentTime = networkSentTimeISO;\n        this.privMessage = message;\n    }\n    get networkSentTime() {\n        return this.privNetworkSentTime;\n    }\n    get message() {\n        return this.privMessage;\n    }\n}\n\n//# sourceMappingURL=ConnectionEvents.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionEvents.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js":
  /*!************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js ***!
    \************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConnectionMessage\": () => (/* binding */ ConnectionMessage),\n/* harmony export */   \"MessageType\": () => (/* binding */ MessageType)\n/* harmony export */ });\n/* harmony import */ var _Error__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Error */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js\");\n/* harmony import */ var _Guid__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Guid */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js\");\n/* eslint-disable @typescript-eslint/no-unsafe-return */\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\nvar MessageType;\n(function (MessageType) {\n    MessageType[MessageType[\"Text\"] = 0] = \"Text\";\n    MessageType[MessageType[\"Binary\"] = 1] = \"Binary\";\n})(MessageType || (MessageType = {}));\nclass ConnectionMessage {\n    constructor(messageType, body, headers, id) {\n        this.privBody = null;\n        if (messageType === MessageType.Text && body && !(typeof (body) === \"string\")) {\n            throw new _Error__WEBPACK_IMPORTED_MODULE_0__.InvalidOperationError(\"Payload must be a string\");\n        }\n        if (messageType === MessageType.Binary && body && !(body instanceof ArrayBuffer)) {\n            throw new _Error__WEBPACK_IMPORTED_MODULE_0__.InvalidOperationError(\"Payload must be ArrayBuffer\");\n        }\n        this.privMessageType = messageType;\n        // eslint-disable-next-line @typescript-eslint/no-unsafe-assignment\n        this.privBody = body;\n        this.privHeaders = headers ? headers : {};\n        this.privId = id ? id : (0,_Guid__WEBPACK_IMPORTED_MODULE_1__.createNoDashGuid)();\n        switch (this.messageType) {\n            case MessageType.Binary:\n                this.privSize = this.binaryBody !== null ? this.binaryBody.byteLength : 0;\n                break;\n            case MessageType.Text:\n                this.privSize = this.textBody.length;\n        }\n    }\n    get messageType() {\n        return this.privMessageType;\n    }\n    get headers() {\n        return this.privHeaders;\n    }\n    get body() {\n        return this.privBody;\n    }\n    get textBody() {\n        if (this.privMessageType === MessageType.Binary) {\n            throw new _Error__WEBPACK_IMPORTED_MODULE_0__.InvalidOperationError(\"Not supported for binary message\");\n        }\n        return this.privBody;\n    }\n    get binaryBody() {\n        if (this.privMessageType === MessageType.Text) {\n            throw new _Error__WEBPACK_IMPORTED_MODULE_0__.InvalidOperationError(\"Not supported for text message\");\n        }\n        return this.privBody;\n    }\n    get id() {\n        return this.privId;\n    }\n}\n\n//# sourceMappingURL=ConnectionMessage.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionOpenResponse.js":
  /*!*****************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionOpenResponse.js ***!
    \*****************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConnectionOpenResponse\": () => (/* binding */ ConnectionOpenResponse)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nclass ConnectionOpenResponse {\n    constructor(statusCode, reason) {\n        this.privStatusCode = statusCode;\n        this.privReason = reason;\n    }\n    get statusCode() {\n        return this.privStatusCode;\n    }\n    get reason() {\n        return this.privReason;\n    }\n}\n\n//# sourceMappingURL=ConnectionOpenResponse.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionOpenResponse.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/DialogEvents.js":
  /*!*******************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/DialogEvents.js ***!
    \*******************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"DialogEvent\": () => (/* binding */ DialogEvent),\n/* harmony export */   \"SendingAgentContextMessageEvent\": () => (/* binding */ SendingAgentContextMessageEvent)\n/* harmony export */ });\n/* harmony import */ var _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./PlatformEvent */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/PlatformEvent.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nclass DialogEvent extends _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.PlatformEvent {\n    constructor(eventName, eventType = _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Info) {\n        super(eventName, eventType);\n    }\n}\nclass SendingAgentContextMessageEvent extends DialogEvent {\n    constructor(agentConfig) {\n        super(\"SendingAgentContextMessageEvent\");\n        this.privAgentConfig = agentConfig;\n    }\n    get agentConfig() {\n        return this.privAgentConfig;\n    }\n}\n\n//# sourceMappingURL=DialogEvents.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/DialogEvents.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js":
  /*!************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js ***!
    \************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ArgumentNullError\": () => (/* binding */ ArgumentNullError),\n/* harmony export */   \"InvalidOperationError\": () => (/* binding */ InvalidOperationError),\n/* harmony export */   \"ObjectDisposedError\": () => (/* binding */ ObjectDisposedError)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/* eslint-disable max-classes-per-file */\n/**\n * The error that is thrown when an argument passed in is null.\n *\n * @export\n * @class ArgumentNullError\n * @extends {Error}\n */\nclass ArgumentNullError extends Error {\n    /**\n     * Creates an instance of ArgumentNullError.\n     *\n     * @param {string} argumentName - Name of the argument that is null\n     *\n     * @memberOf ArgumentNullError\n     */\n    constructor(argumentName) {\n        super(argumentName);\n        this.name = \"ArgumentNull\";\n        this.message = argumentName;\n    }\n}\n/**\n * The error that is thrown when an invalid operation is performed in the code.\n *\n * @export\n * @class InvalidOperationError\n * @extends {Error}\n */\nclass InvalidOperationError extends Error {\n    /**\n     * Creates an instance of InvalidOperationError.\n     *\n     * @param {string} error - The error\n     *\n     * @memberOf InvalidOperationError\n     */\n    constructor(error) {\n        super(error);\n        this.name = \"InvalidOperation\";\n        this.message = error;\n    }\n}\n/**\n * The error that is thrown when an object is disposed.\n *\n * @export\n * @class ObjectDisposedError\n * @extends {Error}\n */\nclass ObjectDisposedError extends Error {\n    /**\n     * Creates an instance of ObjectDisposedError.\n     *\n     * @param {string} objectName - The object that is disposed\n     * @param {string} error - The error\n     *\n     * @memberOf ObjectDisposedError\n     */\n    constructor(objectName, error) {\n        super(error);\n        this.name = objectName + \"ObjectDisposed\";\n        this.message = error;\n    }\n}\n\n//# sourceMappingURL=Error.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/EventSource.js":
  /*!******************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/EventSource.js ***!
    \******************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"EventSource\": () => (/* binding */ EventSource)\n/* harmony export */ });\n/* harmony import */ var _Error__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Error */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js\");\n/* harmony import */ var _Guid__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Guid */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\nclass EventSource {\n    constructor(metadata) {\n        this.privEventListeners = {};\n        this.privIsDisposed = false;\n        this.privConsoleListener = undefined;\n        this.privMetadata = metadata;\n    }\n    onEvent(event) {\n        if (this.isDisposed()) {\n            throw (new _Error__WEBPACK_IMPORTED_MODULE_0__.ObjectDisposedError(\"EventSource\"));\n        }\n        if (this.metadata) {\n            for (const paramName in this.metadata) {\n                if (paramName) {\n                    if (event.metadata) {\n                        if (!event.metadata[paramName]) {\n                            event.metadata[paramName] = this.metadata[paramName];\n                        }\n                    }\n                }\n            }\n        }\n        for (const eventId in this.privEventListeners) {\n            if (eventId && this.privEventListeners[eventId]) {\n                this.privEventListeners[eventId](event);\n            }\n        }\n    }\n    attach(onEventCallback) {\n        const id = (0,_Guid__WEBPACK_IMPORTED_MODULE_1__.createNoDashGuid)();\n        this.privEventListeners[id] = onEventCallback;\n        return {\n            detach: () => {\n                delete this.privEventListeners[id];\n                return Promise.resolve();\n            },\n        };\n    }\n    attachListener(listener) {\n        return this.attach((e) => listener.onEvent(e));\n    }\n    attachConsoleListener(listener) {\n        if (!!this.privConsoleListener) {\n            void this.privConsoleListener.detach(); // Detach implementation for eventListeners is synchronous\n        }\n        this.privConsoleListener = this.attach((e) => listener.onEvent(e));\n        return this.privConsoleListener;\n    }\n    isDisposed() {\n        return this.privIsDisposed;\n    }\n    dispose() {\n        this.privEventListeners = null;\n        this.privIsDisposed = true;\n    }\n    get metadata() {\n        return this.privMetadata;\n    }\n}\n\n//# sourceMappingURL=EventSource.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/EventSource.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Events.js":
  /*!*************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Events.js ***!
    \*************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Events\": () => (/* binding */ Events)\n/* harmony export */ });\n/* harmony import */ var _Error__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Error */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js\");\n/* harmony import */ var _EventSource__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./EventSource */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/EventSource.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\nclass Events {\n    static setEventSource(eventSource) {\n        if (!eventSource) {\n            throw new _Error__WEBPACK_IMPORTED_MODULE_0__.ArgumentNullError(\"eventSource\");\n        }\n        Events.privInstance = eventSource;\n    }\n    static get instance() {\n        return Events.privInstance;\n    }\n}\nEvents.privInstance = new _EventSource__WEBPACK_IMPORTED_MODULE_1__.EventSource();\n\n//# sourceMappingURL=Events.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Events.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js":
  /*!***********************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js ***!
    \***********************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createGuid\": () => (/* binding */ createGuid),\n/* harmony export */   \"createNoDashGuid\": () => (/* binding */ createNoDashGuid)\n/* harmony export */ });\n/* harmony import */ var uuid__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! uuid */ \"./node_modules/uuid/dist/esm-browser/v4.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nconst createGuid = () => (0,uuid__WEBPACK_IMPORTED_MODULE_0__[\"default\"])();\nconst createNoDashGuid = () => createGuid().replace(new RegExp(\"-\", \"g\"), \"\").toUpperCase();\n\n\n//# sourceMappingURL=Guid.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IConnection.js":
  /*!******************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IConnection.js ***!
    \******************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConnectionState\": () => (/* binding */ ConnectionState)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar ConnectionState;\n(function (ConnectionState) {\n    ConnectionState[ConnectionState[\"None\"] = 0] = \"None\";\n    ConnectionState[ConnectionState[\"Connected\"] = 1] = \"Connected\";\n    ConnectionState[ConnectionState[\"Connecting\"] = 2] = \"Connecting\";\n    ConnectionState[ConnectionState[\"Disconnected\"] = 3] = \"Disconnected\";\n})(ConnectionState || (ConnectionState = {}));\n\n//# sourceMappingURL=IConnection.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IConnection.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/List.js":
  /*!***********************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/List.js ***!
    \***********************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"List\": () => (/* binding */ List)\n/* harmony export */ });\n/* harmony import */ var _Error__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Error */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nclass List {\n    constructor(list) {\n        this.privSubscriptionIdCounter = 0;\n        this.privAddSubscriptions = {};\n        this.privRemoveSubscriptions = {};\n        this.privDisposedSubscriptions = {};\n        this.privDisposeReason = null;\n        this.privList = [];\n        // copy the list rather than taking as is.\n        if (list) {\n            for (const item of list) {\n                this.privList.push(item);\n            }\n        }\n    }\n    get(itemIndex) {\n        this.throwIfDisposed();\n        return this.privList[itemIndex];\n    }\n    first() {\n        return this.get(0);\n    }\n    last() {\n        return this.get(this.length() - 1);\n    }\n    add(item) {\n        this.throwIfDisposed();\n        this.insertAt(this.privList.length, item);\n    }\n    insertAt(index, item) {\n        this.throwIfDisposed();\n        if (index === 0) {\n            this.privList.unshift(item);\n        }\n        else if (index === this.privList.length) {\n            this.privList.push(item);\n        }\n        else {\n            this.privList.splice(index, 0, item);\n        }\n        this.triggerSubscriptions(this.privAddSubscriptions);\n    }\n    removeFirst() {\n        this.throwIfDisposed();\n        return this.removeAt(0);\n    }\n    removeLast() {\n        this.throwIfDisposed();\n        return this.removeAt(this.length() - 1);\n    }\n    removeAt(index) {\n        this.throwIfDisposed();\n        return this.remove(index, 1)[0];\n    }\n    remove(index, count) {\n        this.throwIfDisposed();\n        const removedElements = this.privList.splice(index, count);\n        this.triggerSubscriptions(this.privRemoveSubscriptions);\n        return removedElements;\n    }\n    clear() {\n        this.throwIfDisposed();\n        this.remove(0, this.length());\n    }\n    length() {\n        this.throwIfDisposed();\n        return this.privList.length;\n    }\n    onAdded(addedCallback) {\n        this.throwIfDisposed();\n        const subscriptionId = this.privSubscriptionIdCounter++;\n        this.privAddSubscriptions[subscriptionId] = addedCallback;\n        return {\n            detach: () => {\n                delete this.privAddSubscriptions[subscriptionId];\n                return Promise.resolve();\n            },\n        };\n    }\n    onRemoved(removedCallback) {\n        this.throwIfDisposed();\n        const subscriptionId = this.privSubscriptionIdCounter++;\n        this.privRemoveSubscriptions[subscriptionId] = removedCallback;\n        return {\n            detach: () => {\n                delete this.privRemoveSubscriptions[subscriptionId];\n                return Promise.resolve();\n            },\n        };\n    }\n    onDisposed(disposedCallback) {\n        this.throwIfDisposed();\n        const subscriptionId = this.privSubscriptionIdCounter++;\n        this.privDisposedSubscriptions[subscriptionId] = disposedCallback;\n        return {\n            detach: () => {\n                delete this.privDisposedSubscriptions[subscriptionId];\n                return Promise.resolve();\n            },\n        };\n    }\n    join(seperator) {\n        this.throwIfDisposed();\n        return this.privList.join(seperator);\n    }\n    toArray() {\n        const cloneCopy = Array();\n        this.privList.forEach((val) => {\n            cloneCopy.push(val);\n        });\n        return cloneCopy;\n    }\n    any(callback) {\n        this.throwIfDisposed();\n        if (callback) {\n            return this.where(callback).length() > 0;\n        }\n        else {\n            return this.length() > 0;\n        }\n    }\n    all(callback) {\n        this.throwIfDisposed();\n        return this.where(callback).length() === this.length();\n    }\n    forEach(callback) {\n        this.throwIfDisposed();\n        for (let i = 0; i < this.length(); i++) {\n            callback(this.privList[i], i);\n        }\n    }\n    select(callback) {\n        this.throwIfDisposed();\n        const selectList = [];\n        for (let i = 0; i < this.privList.length; i++) {\n            selectList.push(callback(this.privList[i], i));\n        }\n        return new List(selectList);\n    }\n    where(callback) {\n        this.throwIfDisposed();\n        const filteredList = new List();\n        for (let i = 0; i < this.privList.length; i++) {\n            if (callback(this.privList[i], i)) {\n                filteredList.add(this.privList[i]);\n            }\n        }\n        return filteredList;\n    }\n    orderBy(compareFn) {\n        this.throwIfDisposed();\n        const clonedArray = this.toArray();\n        const orderedArray = clonedArray.sort(compareFn);\n        return new List(orderedArray);\n    }\n    orderByDesc(compareFn) {\n        this.throwIfDisposed();\n        return this.orderBy((a, b) => compareFn(b, a));\n    }\n    clone() {\n        this.throwIfDisposed();\n        return new List(this.toArray());\n    }\n    concat(list) {\n        this.throwIfDisposed();\n        return new List(this.privList.concat(list.toArray()));\n    }\n    concatArray(array) {\n        this.throwIfDisposed();\n        return new List(this.privList.concat(array));\n    }\n    isDisposed() {\n        return this.privList == null;\n    }\n    dispose(reason) {\n        if (!this.isDisposed()) {\n            this.privDisposeReason = reason;\n            this.privList = null;\n            this.privAddSubscriptions = null;\n            this.privRemoveSubscriptions = null;\n            this.triggerSubscriptions(this.privDisposedSubscriptions);\n        }\n    }\n    throwIfDisposed() {\n        if (this.isDisposed()) {\n            throw new _Error__WEBPACK_IMPORTED_MODULE_0__.ObjectDisposedError(\"List\", this.privDisposeReason);\n        }\n    }\n    triggerSubscriptions(subscriptions) {\n        if (subscriptions) {\n            for (const subscriptionId in subscriptions) {\n                if (subscriptionId) {\n                    subscriptions[subscriptionId]();\n                }\n            }\n        }\n    }\n}\n\n//# sourceMappingURL=List.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/List.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/OCSPEvents.js":
  /*!*****************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/OCSPEvents.js ***!
    \*****************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"OCSPCacheEntryExpiredEvent\": () => (/* binding */ OCSPCacheEntryExpiredEvent),\n/* harmony export */   \"OCSPCacheEntryNeedsRefreshEvent\": () => (/* binding */ OCSPCacheEntryNeedsRefreshEvent),\n/* harmony export */   \"OCSPCacheFetchErrorEvent\": () => (/* binding */ OCSPCacheFetchErrorEvent),\n/* harmony export */   \"OCSPCacheHitEvent\": () => (/* binding */ OCSPCacheHitEvent),\n/* harmony export */   \"OCSPCacheMissEvent\": () => (/* binding */ OCSPCacheMissEvent),\n/* harmony export */   \"OCSPCacheUpdateCompleteEvent\": () => (/* binding */ OCSPCacheUpdateCompleteEvent),\n/* harmony export */   \"OCSPCacheUpdateErrorEvent\": () => (/* binding */ OCSPCacheUpdateErrorEvent),\n/* harmony export */   \"OCSPCacheUpdateNeededEvent\": () => (/* binding */ OCSPCacheUpdateNeededEvent),\n/* harmony export */   \"OCSPDiskCacheHitEvent\": () => (/* binding */ OCSPDiskCacheHitEvent),\n/* harmony export */   \"OCSPDiskCacheStoreEvent\": () => (/* binding */ OCSPDiskCacheStoreEvent),\n/* harmony export */   \"OCSPEvent\": () => (/* binding */ OCSPEvent),\n/* harmony export */   \"OCSPMemoryCacheHitEvent\": () => (/* binding */ OCSPMemoryCacheHitEvent),\n/* harmony export */   \"OCSPMemoryCacheStoreEvent\": () => (/* binding */ OCSPMemoryCacheStoreEvent),\n/* harmony export */   \"OCSPResponseRetrievedEvent\": () => (/* binding */ OCSPResponseRetrievedEvent),\n/* harmony export */   \"OCSPStapleReceivedEvent\": () => (/* binding */ OCSPStapleReceivedEvent),\n/* harmony export */   \"OCSPVerificationFailedEvent\": () => (/* binding */ OCSPVerificationFailedEvent),\n/* harmony export */   \"OCSPWSUpgradeStartedEvent\": () => (/* binding */ OCSPWSUpgradeStartedEvent)\n/* harmony export */ });\n/* harmony import */ var _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./PlatformEvent */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/PlatformEvent.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/* eslint-disable max-classes-per-file */\n\nclass OCSPEvent extends _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.PlatformEvent {\n    constructor(eventName, eventType, signature) {\n        super(eventName, eventType);\n        this.privSignature = signature;\n    }\n}\nclass OCSPMemoryCacheHitEvent extends OCSPEvent {\n    constructor(signature) {\n        super(\"OCSPMemoryCacheHitEvent\", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Debug, signature);\n    }\n}\nclass OCSPCacheMissEvent extends OCSPEvent {\n    constructor(signature) {\n        super(\"OCSPCacheMissEvent\", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Debug, signature);\n    }\n}\nclass OCSPDiskCacheHitEvent extends OCSPEvent {\n    constructor(signature) {\n        super(\"OCSPDiskCacheHitEvent\", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Debug, signature);\n    }\n}\nclass OCSPCacheUpdateNeededEvent extends OCSPEvent {\n    constructor(signature) {\n        super(\"OCSPCacheUpdateNeededEvent\", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Debug, signature);\n    }\n}\nclass OCSPMemoryCacheStoreEvent extends OCSPEvent {\n    constructor(signature) {\n        super(\"OCSPMemoryCacheStoreEvent\", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Debug, signature);\n    }\n}\nclass OCSPDiskCacheStoreEvent extends OCSPEvent {\n    constructor(signature) {\n        super(\"OCSPDiskCacheStoreEvent\", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Debug, signature);\n    }\n}\nclass OCSPCacheUpdateCompleteEvent extends OCSPEvent {\n    constructor(signature) {\n        super(\"OCSPCacheUpdateCompleteEvent\", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Debug, signature);\n    }\n}\nclass OCSPStapleReceivedEvent extends OCSPEvent {\n    constructor() {\n        super(\"OCSPStapleReceivedEvent\", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Debug, \"\");\n    }\n}\nclass OCSPWSUpgradeStartedEvent extends OCSPEvent {\n    constructor(serialNumber) {\n        super(\"OCSPWSUpgradeStartedEvent\", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Debug, serialNumber);\n    }\n}\nclass OCSPCacheEntryExpiredEvent extends OCSPEvent {\n    constructor(serialNumber, expireTime) {\n        super(\"OCSPCacheEntryExpiredEvent\", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Debug, serialNumber);\n        this.privExpireTime = expireTime;\n    }\n}\nclass OCSPCacheEntryNeedsRefreshEvent extends OCSPEvent {\n    constructor(serialNumber, startTime, expireTime) {\n        super(\"OCSPCacheEntryNeedsRefreshEvent\", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Debug, serialNumber);\n        this.privExpireTime = expireTime;\n        this.privStartTime = startTime;\n    }\n}\nclass OCSPCacheHitEvent extends OCSPEvent {\n    constructor(serialNumber, startTime, expireTime) {\n        super(\"OCSPCacheHitEvent\", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Debug, serialNumber);\n        this.privExpireTime = expireTime;\n        this.privExpireTimeString = new Date(expireTime).toLocaleDateString();\n        this.privStartTime = startTime;\n        this.privStartTimeString = new Date(startTime).toLocaleTimeString();\n    }\n}\nclass OCSPVerificationFailedEvent extends OCSPEvent {\n    constructor(serialNumber, error) {\n        super(\"OCSPVerificationFailedEvent\", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Debug, serialNumber);\n        this.privError = error;\n    }\n}\nclass OCSPCacheFetchErrorEvent extends OCSPEvent {\n    constructor(serialNumber, error) {\n        super(\"OCSPCacheFetchErrorEvent\", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Debug, serialNumber);\n        this.privError = error;\n    }\n}\nclass OCSPResponseRetrievedEvent extends OCSPEvent {\n    constructor(serialNumber) {\n        super(\"OCSPResponseRetrievedEvent\", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Debug, serialNumber);\n    }\n}\nclass OCSPCacheUpdateErrorEvent extends OCSPEvent {\n    constructor(serialNumber, error) {\n        super(\"OCSPCacheUpdateErrorEvent\", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Debug, serialNumber);\n        this.privError = error;\n    }\n}\n\n//# sourceMappingURL=OCSPEvents.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/OCSPEvents.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/PlatformEvent.js":
  /*!********************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/PlatformEvent.js ***!
    \********************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"EventType\": () => (/* binding */ EventType),\n/* harmony export */   \"PlatformEvent\": () => (/* binding */ PlatformEvent)\n/* harmony export */ });\n/* harmony import */ var _Guid__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Guid */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nvar EventType;\n(function (EventType) {\n    EventType[EventType[\"Debug\"] = 0] = \"Debug\";\n    EventType[EventType[\"Info\"] = 1] = \"Info\";\n    EventType[EventType[\"Warning\"] = 2] = \"Warning\";\n    EventType[EventType[\"Error\"] = 3] = \"Error\";\n    EventType[EventType[\"None\"] = 4] = \"None\";\n})(EventType || (EventType = {}));\nclass PlatformEvent {\n    constructor(eventName, eventType) {\n        this.privName = eventName;\n        this.privEventId = (0,_Guid__WEBPACK_IMPORTED_MODULE_0__.createNoDashGuid)();\n        this.privEventTime = new Date().toISOString();\n        this.privEventType = eventType;\n        this.privMetadata = {};\n    }\n    get name() {\n        return this.privName;\n    }\n    get eventId() {\n        return this.privEventId;\n    }\n    get eventTime() {\n        return this.privEventTime;\n    }\n    get eventType() {\n        return this.privEventType;\n    }\n    get metadata() {\n        return this.privMetadata;\n    }\n}\n\n//# sourceMappingURL=PlatformEvent.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/PlatformEvent.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js":
  /*!**************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js ***!
    \**************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Deferred\": () => (/* binding */ Deferred),\n/* harmony export */   \"PromiseResult\": () => (/* binding */ PromiseResult),\n/* harmony export */   \"PromiseResultEventSource\": () => (/* binding */ PromiseResultEventSource),\n/* harmony export */   \"PromiseState\": () => (/* binding */ PromiseState),\n/* harmony export */   \"Sink\": () => (/* binding */ Sink),\n/* harmony export */   \"marshalPromiseToCallbacks\": () => (/* binding */ marshalPromiseToCallbacks)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/* eslint-disable max-classes-per-file, @typescript-eslint/typedef */\nvar PromiseState;\n(function (PromiseState) {\n    PromiseState[PromiseState[\"None\"] = 0] = \"None\";\n    PromiseState[PromiseState[\"Resolved\"] = 1] = \"Resolved\";\n    PromiseState[PromiseState[\"Rejected\"] = 2] = \"Rejected\";\n})(PromiseState || (PromiseState = {}));\nclass PromiseResult {\n    constructor(promiseResultEventSource) {\n        this.throwIfError = () => {\n            if (this.isError) {\n                throw this.error;\n            }\n        };\n        promiseResultEventSource.on((result) => {\n            if (!this.privIsCompleted) {\n                this.privIsCompleted = true;\n                this.privIsError = false;\n                this.privResult = result;\n            }\n        }, (error) => {\n            if (!this.privIsCompleted) {\n                this.privIsCompleted = true;\n                this.privIsError = true;\n                this.privError = error;\n            }\n        });\n    }\n    get isCompleted() {\n        return this.privIsCompleted;\n    }\n    get isError() {\n        return this.privIsError;\n    }\n    get error() {\n        return this.privError;\n    }\n    get result() {\n        return this.privResult;\n    }\n}\nclass PromiseResultEventSource {\n    constructor() {\n        this.setResult = (result) => {\n            this.privOnSetResult(result);\n        };\n        this.setError = (error) => {\n            this.privOnSetError(error);\n        };\n        this.on = (onSetResult, onSetError) => {\n            this.privOnSetResult = onSetResult;\n            this.privOnSetError = onSetError;\n        };\n    }\n}\nclass Deferred {\n    constructor() {\n        this.resolve = (result) => {\n            this.privResolve(result);\n            return this;\n        };\n        this.reject = (error) => {\n            this.privReject(error);\n            return this;\n        };\n        // eslint-disable-next-line @typescript-eslint/explicit-function-return-type\n        this.privPromise = new Promise((resolve, reject) => {\n            this.privResolve = resolve;\n            this.privReject = reject;\n        });\n    }\n    get promise() {\n        return this.privPromise;\n    }\n}\nclass Sink {\n    constructor() {\n        this.privState = PromiseState.None;\n        this.privPromiseResult = null;\n        this.privPromiseResultEvents = null;\n        this.privSuccessHandlers = [];\n        this.privErrorHandlers = [];\n        this.privPromiseResultEvents = new PromiseResultEventSource();\n        this.privPromiseResult = new PromiseResult(this.privPromiseResultEvents);\n    }\n    get state() {\n        return this.privState;\n    }\n    get result() {\n        return this.privPromiseResult;\n    }\n    resolve(result) {\n        if (this.privState !== PromiseState.None) {\n            throw new Error(\"'Cannot resolve a completed promise'\");\n        }\n        this.privState = PromiseState.Resolved;\n        this.privPromiseResultEvents.setResult(result);\n        for (let i = 0; i < this.privSuccessHandlers.length; i++) {\n            this.executeSuccessCallback(result, this.privSuccessHandlers[i], this.privErrorHandlers[i]);\n        }\n        this.detachHandlers();\n    }\n    reject(error) {\n        if (this.privState !== PromiseState.None) {\n            throw new Error(\"'Cannot reject a completed promise'\");\n        }\n        this.privState = PromiseState.Rejected;\n        this.privPromiseResultEvents.setError(error);\n        for (const errorHandler of this.privErrorHandlers) {\n            this.executeErrorCallback(error, errorHandler);\n        }\n        this.detachHandlers();\n    }\n    on(successCallback, errorCallback) {\n        if (successCallback == null) {\n            // eslint-disable-next-line @typescript-eslint/no-empty-function\n            successCallback = () => { };\n        }\n        if (this.privState === PromiseState.None) {\n            this.privSuccessHandlers.push(successCallback);\n            this.privErrorHandlers.push(errorCallback);\n        }\n        else {\n            if (this.privState === PromiseState.Resolved) {\n                this.executeSuccessCallback(this.privPromiseResult.result, successCallback, errorCallback);\n            }\n            else if (this.privState === PromiseState.Rejected) {\n                this.executeErrorCallback(this.privPromiseResult.error, errorCallback);\n            }\n            this.detachHandlers();\n        }\n    }\n    executeSuccessCallback(result, successCallback, errorCallback) {\n        try {\n            successCallback(result);\n        }\n        catch (e) {\n            this.executeErrorCallback(`'Unhandled callback error: ${e}'`, errorCallback);\n        }\n    }\n    executeErrorCallback(error, errorCallback) {\n        if (errorCallback) {\n            try {\n                errorCallback(error);\n            }\n            catch (e) {\n                throw new Error(`'Unhandled callback error: ${e}. InnerError: ${error}'`);\n            }\n        }\n        else {\n            throw new Error(`'Unhandled error: ${error}'`);\n        }\n    }\n    detachHandlers() {\n        this.privErrorHandlers = [];\n        this.privSuccessHandlers = [];\n    }\n}\n// eslint-disable-next-line prefer-arrow/prefer-arrow-functions\nfunction marshalPromiseToCallbacks(promise, cb, err) {\n    promise.then((val) => {\n        try {\n            if (!!cb) {\n                cb(val);\n            }\n        }\n        catch (error) {\n            if (!!err) {\n                try {\n                    if (error instanceof Error) {\n                        const typedError = error;\n                        err(typedError.name + \": \" + typedError.message);\n                    }\n                    else {\n                        err(error);\n                    }\n                    // eslint-disable-next-line no-empty\n                }\n                catch (error) { }\n            }\n        }\n    }, (error) => {\n        if (!!err) {\n            try {\n                if (error instanceof Error) {\n                    const typedError = error;\n                    err(typedError.name + \": \" + typedError.message);\n                }\n                else {\n                    err(error);\n                }\n                // eslint-disable-next-line no-empty\n            }\n            catch (error) { }\n        }\n    });\n}\n\n//# sourceMappingURL=Promise.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Queue.js":
  /*!************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Queue.js ***!
    \************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Queue\": () => (/* binding */ Queue)\n/* harmony export */ });\n/* harmony import */ var _Error__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Error */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js\");\n/* harmony import */ var _List__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./List */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/List.js\");\n/* harmony import */ var _Promise__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Promise */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\nvar SubscriberType;\n(function (SubscriberType) {\n    SubscriberType[SubscriberType[\"Dequeue\"] = 0] = \"Dequeue\";\n    SubscriberType[SubscriberType[\"Peek\"] = 1] = \"Peek\";\n})(SubscriberType || (SubscriberType = {}));\nclass Queue {\n    constructor(list) {\n        this.privPromiseStore = new _List__WEBPACK_IMPORTED_MODULE_0__.List();\n        this.privIsDrainInProgress = false;\n        this.privIsDisposing = false;\n        this.privDisposeReason = null;\n        this.privList = list ? list : new _List__WEBPACK_IMPORTED_MODULE_0__.List();\n        this.privDetachables = [];\n        this.privSubscribers = new _List__WEBPACK_IMPORTED_MODULE_0__.List();\n        this.privDetachables.push(this.privList.onAdded(() => this.drain()));\n    }\n    enqueue(item) {\n        this.throwIfDispose();\n        this.enqueueFromPromise(new Promise((resolve) => resolve(item)));\n    }\n    enqueueFromPromise(promise) {\n        this.throwIfDispose();\n        promise.then((val) => {\n            this.privList.add(val);\n            // eslint-disable-next-line @typescript-eslint/no-empty-function\n        }, () => { });\n    }\n    dequeue() {\n        this.throwIfDispose();\n        const deferredSubscriber = new _Promise__WEBPACK_IMPORTED_MODULE_1__.Deferred();\n        if (this.privSubscribers) {\n            this.privSubscribers.add({ deferral: deferredSubscriber, type: SubscriberType.Dequeue });\n            this.drain();\n        }\n        return deferredSubscriber.promise;\n    }\n    peek() {\n        this.throwIfDispose();\n        const deferredSubscriber = new _Promise__WEBPACK_IMPORTED_MODULE_1__.Deferred();\n        const subs = this.privSubscribers;\n        if (subs) {\n            this.privSubscribers.add({ deferral: deferredSubscriber, type: SubscriberType.Peek });\n            this.drain();\n        }\n        return deferredSubscriber.promise;\n    }\n    length() {\n        this.throwIfDispose();\n        return this.privList.length();\n    }\n    isDisposed() {\n        return this.privSubscribers == null;\n    }\n    drainAndDispose(pendingItemProcessor, reason) {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (!this.isDisposed() && !this.privIsDisposing) {\n                this.privDisposeReason = reason;\n                this.privIsDisposing = true;\n                const subs = this.privSubscribers;\n                if (subs) {\n                    while (subs.length() > 0) {\n                        const subscriber = subs.removeFirst();\n                        // TODO: this needs work (Resolve(null) instead?).\n                        subscriber.deferral.resolve(undefined);\n                        // subscriber.deferral.reject(\"Disposed\");\n                    }\n                    // note: this block assumes cooperative multitasking, i.e.,\n                    // between the if-statement and the assignment there are no\n                    // thread switches.\n                    // Reason is that between the initial const = this.; and this\n                    // point there is the derral.resolve() operation that might have\n                    // caused recursive calls to the Queue, especially, calling\n                    // Dispose() on the queue alredy (which would reset the var\n                    // here to null!).\n                    // That should generally hold true for javascript...\n                    if (this.privSubscribers === subs) {\n                        this.privSubscribers = subs;\n                    }\n                }\n                for (const detachable of this.privDetachables) {\n                    yield detachable.detach();\n                }\n                if (this.privPromiseStore.length() > 0 && pendingItemProcessor) {\n                    const promiseArray = [];\n                    this.privPromiseStore.toArray().forEach((wrapper) => {\n                        promiseArray.push(wrapper);\n                    });\n                    return Promise.all(promiseArray).finally(() => {\n                        this.privSubscribers = null;\n                        this.privList.forEach((item) => {\n                            pendingItemProcessor(item);\n                        });\n                        this.privList = null;\n                        return;\n                    }).then();\n                }\n                else {\n                    this.privSubscribers = null;\n                    this.privList = null;\n                }\n            }\n        });\n    }\n    dispose(reason) {\n        return __awaiter(this, void 0, void 0, function* () {\n            yield this.drainAndDispose(null, reason);\n        });\n    }\n    drain() {\n        if (!this.privIsDrainInProgress && !this.privIsDisposing) {\n            this.privIsDrainInProgress = true;\n            const subs = this.privSubscribers;\n            const lists = this.privList;\n            if (subs && lists) {\n                while (lists.length() > 0 && subs.length() > 0 && !this.privIsDisposing) {\n                    const subscriber = subs.removeFirst();\n                    if (subscriber.type === SubscriberType.Peek) {\n                        subscriber.deferral.resolve(lists.first());\n                    }\n                    else {\n                        const dequeuedItem = lists.removeFirst();\n                        subscriber.deferral.resolve(dequeuedItem);\n                    }\n                }\n                // note: this block assumes cooperative multitasking, i.e.,\n                // between the if-statement and the assignment there are no\n                // thread switches.\n                // Reason is that between the initial const = this.; and this\n                // point there is the derral.resolve() operation that might have\n                // caused recursive calls to the Queue, especially, calling\n                // Dispose() on the queue alredy (which would reset the var\n                // here to null!).\n                // That should generally hold true for javascript...\n                if (this.privSubscribers === subs) {\n                    this.privSubscribers = subs;\n                }\n                // note: this block assumes cooperative multitasking, i.e.,\n                // between the if-statement and the assignment there are no\n                // thread switches.\n                // Reason is that between the initial const = this.; and this\n                // point there is the derral.resolve() operation that might have\n                // caused recursive calls to the Queue, especially, calling\n                // Dispose() on the queue alredy (which would reset the var\n                // here to null!).\n                // That should generally hold true for javascript...\n                if (this.privList === lists) {\n                    this.privList = lists;\n                }\n            }\n            this.privIsDrainInProgress = false;\n        }\n    }\n    throwIfDispose() {\n        if (this.isDisposed()) {\n            if (this.privDisposeReason) {\n                throw new _Error__WEBPACK_IMPORTED_MODULE_2__.InvalidOperationError(this.privDisposeReason);\n            }\n            throw new _Error__WEBPACK_IMPORTED_MODULE_2__.ObjectDisposedError(\"Queue\");\n        }\n        else if (this.privIsDisposing) {\n            throw new _Error__WEBPACK_IMPORTED_MODULE_2__.InvalidOperationError(\"Queue disposing\");\n        }\n    }\n}\n\n//# sourceMappingURL=Queue.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Queue.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/RawWebsocketMessage.js":
  /*!**************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/RawWebsocketMessage.js ***!
    \**************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"RawWebsocketMessage\": () => (/* binding */ RawWebsocketMessage)\n/* harmony export */ });\n/* harmony import */ var _ConnectionMessage__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./ConnectionMessage */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js\");\n/* harmony import */ var _Error__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Error */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js\");\n/* harmony import */ var _Guid__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Guid */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js\");\n/* eslint-disable @typescript-eslint/no-unsafe-assignment */\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\nclass RawWebsocketMessage {\n    constructor(messageType, payload, id) {\n        this.privPayload = null;\n        if (!payload) {\n            throw new _Error__WEBPACK_IMPORTED_MODULE_0__.ArgumentNullError(\"payload\");\n        }\n        // eslint-disable-next-line @typescript-eslint/no-unsafe-member-access\n        if (messageType === _ConnectionMessage__WEBPACK_IMPORTED_MODULE_1__.MessageType.Binary && payload.__proto__.constructor.name !== \"ArrayBuffer\") {\n            throw new _Error__WEBPACK_IMPORTED_MODULE_0__.InvalidOperationError(\"Payload must be ArrayBuffer\");\n        }\n        if (messageType === _ConnectionMessage__WEBPACK_IMPORTED_MODULE_1__.MessageType.Text && !(typeof (payload) === \"string\")) {\n            throw new _Error__WEBPACK_IMPORTED_MODULE_0__.InvalidOperationError(\"Payload must be a string\");\n        }\n        this.privMessageType = messageType;\n        this.privPayload = payload;\n        this.privId = id ? id : (0,_Guid__WEBPACK_IMPORTED_MODULE_2__.createNoDashGuid)();\n    }\n    get messageType() {\n        return this.privMessageType;\n    }\n    get payload() {\n        // eslint-disable-next-line @typescript-eslint/no-unsafe-return\n        return this.privPayload;\n    }\n    get textContent() {\n        if (this.privMessageType === _ConnectionMessage__WEBPACK_IMPORTED_MODULE_1__.MessageType.Binary) {\n            throw new _Error__WEBPACK_IMPORTED_MODULE_0__.InvalidOperationError(\"Not supported for binary message\");\n        }\n        return this.privPayload;\n    }\n    get binaryContent() {\n        if (this.privMessageType === _ConnectionMessage__WEBPACK_IMPORTED_MODULE_1__.MessageType.Text) {\n            throw new _Error__WEBPACK_IMPORTED_MODULE_0__.InvalidOperationError(\"Not supported for text message\");\n        }\n        return this.privPayload;\n    }\n    get id() {\n        return this.privId;\n    }\n}\n\n//# sourceMappingURL=RawWebsocketMessage.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/RawWebsocketMessage.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/RiffPcmEncoder.js":
  /*!*********************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/RiffPcmEncoder.js ***!
    \*********************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"RiffPcmEncoder\": () => (/* binding */ RiffPcmEncoder)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nclass RiffPcmEncoder {\n    constructor(actualSampleRate, desiredSampleRate) {\n        this.privActualSampleRate = actualSampleRate;\n        this.privDesiredSampleRate = desiredSampleRate;\n    }\n    encode(actualAudioFrame) {\n        const audioFrame = this.downSampleAudioFrame(actualAudioFrame, this.privActualSampleRate, this.privDesiredSampleRate);\n        if (!audioFrame) {\n            return null;\n        }\n        const audioLength = audioFrame.length * 2;\n        const buffer = new ArrayBuffer(audioLength);\n        const view = new DataView(buffer);\n        this.floatTo16BitPCM(view, 0, audioFrame);\n        return buffer;\n    }\n    setString(view, offset, str) {\n        for (let i = 0; i < str.length; i++) {\n            view.setUint8(offset + i, str.charCodeAt(i));\n        }\n    }\n    floatTo16BitPCM(view, offset, input) {\n        for (let i = 0; i < input.length; i++, offset += 2) {\n            const s = Math.max(-1, Math.min(1, input[i]));\n            view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true);\n        }\n    }\n    downSampleAudioFrame(srcFrame, srcRate, dstRate) {\n        if (!srcFrame) {\n            return null;\n        }\n        if (dstRate === srcRate || dstRate > srcRate) {\n            return srcFrame;\n        }\n        const ratio = srcRate / dstRate;\n        const dstLength = Math.round(srcFrame.length / ratio);\n        const dstFrame = new Float32Array(dstLength);\n        let srcOffset = 0;\n        let dstOffset = 0;\n        while (dstOffset < dstLength) {\n            const nextSrcOffset = Math.round((dstOffset + 1) * ratio);\n            let accum = 0;\n            let count = 0;\n            while (srcOffset < nextSrcOffset && srcOffset < srcFrame.length) {\n                accum += srcFrame[srcOffset++];\n                count++;\n            }\n            dstFrame[dstOffset++] = accum / count;\n        }\n        return dstFrame;\n    }\n}\n\n//# sourceMappingURL=RiffPcmEncoder.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/RiffPcmEncoder.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Stream.js":
  /*!*************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Stream.js ***!
    \*************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Stream\": () => (/* binding */ Stream)\n/* harmony export */ });\n/* harmony import */ var _Error__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Error */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js\");\n/* harmony import */ var _Guid__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Guid */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js\");\n/* harmony import */ var _Queue__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Queue */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Queue.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\nclass Stream {\n    constructor(streamId) {\n        this.privIsWriteEnded = false;\n        this.privIsReadEnded = false;\n        this.privId = streamId ? streamId : (0,_Guid__WEBPACK_IMPORTED_MODULE_0__.createNoDashGuid)();\n        this.privReaderQueue = new _Queue__WEBPACK_IMPORTED_MODULE_1__.Queue();\n    }\n    get isClosed() {\n        return this.privIsWriteEnded;\n    }\n    get isReadEnded() {\n        return this.privIsReadEnded;\n    }\n    get id() {\n        return this.privId;\n    }\n    close() {\n        if (!this.privIsWriteEnded) {\n            this.writeStreamChunk({\n                buffer: null,\n                isEnd: true,\n                timeReceived: Date.now(),\n            });\n            this.privIsWriteEnded = true;\n        }\n    }\n    writeStreamChunk(streamChunk) {\n        this.throwIfClosed();\n        if (!this.privReaderQueue.isDisposed()) {\n            try {\n                this.privReaderQueue.enqueue(streamChunk);\n            }\n            catch (e) {\n                // Do nothing\n            }\n        }\n    }\n    read() {\n        if (this.privIsReadEnded) {\n            throw new _Error__WEBPACK_IMPORTED_MODULE_2__.InvalidOperationError(\"Stream read has already finished\");\n        }\n        return this.privReaderQueue\n            .dequeue()\n            .then((streamChunk) => __awaiter(this, void 0, void 0, function* () {\n            if (streamChunk === undefined || streamChunk.isEnd) {\n                yield this.privReaderQueue.dispose(\"End of stream reached\");\n            }\n            return streamChunk;\n        }));\n    }\n    readEnded() {\n        if (!this.privIsReadEnded) {\n            this.privIsReadEnded = true;\n            this.privReaderQueue = new _Queue__WEBPACK_IMPORTED_MODULE_1__.Queue();\n        }\n    }\n    throwIfClosed() {\n        if (this.privIsWriteEnded) {\n            throw new _Error__WEBPACK_IMPORTED_MODULE_2__.InvalidOperationError(\"Stream closed\");\n        }\n    }\n}\n\n//# sourceMappingURL=Stream.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Stream.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/StringUtils.js":
  /*!******************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/StringUtils.js ***!
    \******************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"StringUtils\": () => (/* binding */ StringUtils)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * String helper functions\n */\nclass StringUtils {\n    /**\n     * Formats a string by replacing the named {keys} in the string with the values contained in the replacement dictionary.\n     * @param format The format string that contains the parts to replace surrounded by {}. For example: \"wss://{region}.cts.speech.microsoft.com\".\n     * If your string needs to contain a { or } you can use the {{ and }} escape sequences respectively.\n     * @param replacements The dictionary of replacements. If a replacement is not found, it is replaced with an empty string\n     * @returns The formatted string. If you pass in a null or undefined format string, an empty string will be returned\n     */\n    static formatString(format, replacements) {\n        if (!format) {\n            return \"\";\n        }\n        if (!replacements) {\n            return format;\n        }\n        let formatted = \"\";\n        let key = \"\";\n        const appendToFormatted = (str) => {\n            formatted += str;\n        };\n        const appendToKey = (str) => {\n            key += str;\n        };\n        let appendFunc = appendToFormatted;\n        for (let i = 0; i < format.length; i++) {\n            const c = format[i];\n            const next = i + 1 < format.length ? format[i + 1] : \"\";\n            switch (c) {\n                case \"{\":\n                    if (next === \"{\") {\n                        appendFunc(\"{\");\n                        i++;\n                    }\n                    else {\n                        appendFunc = appendToKey;\n                    }\n                    break;\n                case \"}\":\n                    if (next === \"}\") {\n                        appendFunc(\"}\");\n                        i++;\n                    }\n                    else {\n                        if (replacements.hasOwnProperty(key)) {\n                            formatted += replacements[key];\n                        }\n                        appendFunc = appendToFormatted;\n                        key = \"\";\n                    }\n                    break;\n                default:\n                    appendFunc(c);\n                    break;\n            }\n        }\n        return formatted;\n    }\n}\n\n//# sourceMappingURL=StringUtils.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/StringUtils.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Timeout.js":
  /*!**************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Timeout.js ***!
    \**************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Timeout\": () => (/* binding */ Timeout)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nclass Timeout {\n    static load() {\n        // Prefilling the Maps with a function indexed by zero is necessary to be compliant with the specification.\n        const scheduledTimeoutFunctions = new Map([[0, () => { }]]); // eslint-disable-line @typescript-eslint/no-empty-function\n        const unhandledRequests = new Map();\n        // eslint-disable-next-line\n        const workerScript = `!function(e){var t={};function n(r){if(t[r])return t[r].exports;var o=t[r]={i:r,l:!1,exports:{}};return e[r].call(o.exports,o,o.exports,n),o.l=!0,o.exports}n.m=e,n.c=t,n.d=function(e,t,r){n.o(e,t)||Object.defineProperty(e,t,{enumerable:!0,get:r})},n.r=function(e){\"undefined\"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:\"Module\"}),Object.defineProperty(e,\"__esModule\",{value:!0})},n.t=function(e,t){if(1&t&&(e=n(e)),8&t)return e;if(4&t&&\"object\"==typeof e&&e&&e.__esModule)return e;var r=Object.create(null);if(n.r(r),Object.defineProperty(r,\"default\",{enumerable:!0,value:e}),2&t&&\"string\"!=typeof e)for(var o in e)n.d(r,o,function(t){return e[t]}.bind(null,o));return r},n.n=function(e){var t=e&&e.__esModule?function(){return e.default}:function(){return e};return n.d(t,\"a\",t),t},n.o=function(e,t){return Object.prototype.hasOwnProperty.call(e,t)},n.p=\"\",n(n.s=14)}([function(e,t,n){\"use strict\";n.d(t,\"a\",(function(){return i})),n.d(t,\"b\",(function(){return u})),n.d(t,\"c\",(function(){return a})),n.d(t,\"d\",(function(){return d}));const r=new Map,o=new Map,i=e=>{const t=r.get(e);if(void 0===t)throw new Error('There is no interval scheduled with the given id \"'.concat(e,'\".'));clearTimeout(t),r.delete(e)},u=e=>{const t=o.get(e);if(void 0===t)throw new Error('There is no timeout scheduled with the given id \"'.concat(e,'\".'));clearTimeout(t),o.delete(e)},f=(e,t)=>{let n,r;if(\"performance\"in self){const o=performance.now();n=o,r=e-Math.max(0,o-t)}else n=Date.now(),r=e;return{expected:n+r,remainingDelay:r}},c=(e,t,n,r)=>{const o=\"performance\"in self?performance.now():Date.now();o>n?postMessage({id:null,method:\"call\",params:{timerId:t}}):e.set(t,setTimeout(c,n-o,e,t,n))},a=(e,t,n)=>{const{expected:o,remainingDelay:i}=f(e,n);r.set(t,setTimeout(c,i,r,t,o))},d=(e,t,n)=>{const{expected:r,remainingDelay:i}=f(e,n);o.set(t,setTimeout(c,i,o,t,r))}},function(e,t,n){\"use strict\";n.r(t);var r=n(2);for(var o in r)\"default\"!==o&&function(e){n.d(t,e,(function(){return r[e]}))}(o);var i=n(3);for(var o in i)\"default\"!==o&&function(e){n.d(t,e,(function(){return i[e]}))}(o);var u=n(4);for(var o in u)\"default\"!==o&&function(e){n.d(t,e,(function(){return u[e]}))}(o);var f=n(5);for(var o in f)\"default\"!==o&&function(e){n.d(t,e,(function(){return f[e]}))}(o);var c=n(6);for(var o in c)\"default\"!==o&&function(e){n.d(t,e,(function(){return c[e]}))}(o);var a=n(7);for(var o in a)\"default\"!==o&&function(e){n.d(t,e,(function(){return a[e]}))}(o);var d=n(8);for(var o in d)\"default\"!==o&&function(e){n.d(t,e,(function(){return d[e]}))}(o);var s=n(9);for(var o in s)\"default\"!==o&&function(e){n.d(t,e,(function(){return s[e]}))}(o)},function(e,t){},function(e,t){},function(e,t){},function(e,t){},function(e,t){},function(e,t){},function(e,t){},function(e,t){},function(e,t,n){\"use strict\";n.r(t);var r=n(11);for(var o in r)\"default\"!==o&&function(e){n.d(t,e,(function(){return r[e]}))}(o);var i=n(12);for(var o in i)\"default\"!==o&&function(e){n.d(t,e,(function(){return i[e]}))}(o);var u=n(13);for(var o in u)\"default\"!==o&&function(e){n.d(t,e,(function(){return u[e]}))}(o)},function(e,t){},function(e,t){},function(e,t){},function(e,t,n){\"use strict\";n.r(t);var r=n(0),o=n(1);for(var i in o)\"default\"!==i&&function(e){n.d(t,e,(function(){return o[e]}))}(i);var u=n(10);for(var i in u)\"default\"!==i&&function(e){n.d(t,e,(function(){return u[e]}))}(i);addEventListener(\"message\",({data:e})=>{try{if(\"clear\"===e.method){const{id:t,params:{timerId:n}}=e;Object(r.b)(n),postMessage({error:null,id:t})}else{if(\"set\"!==e.method)throw new Error('The given method \"'.concat(e.method,'\" is not supported'));{const{params:{delay:t,now:n,timerId:o}}=e;Object(r.d)(t,o,n)}}}catch(t){postMessage({error:{message:t.message},id:e.id,result:null})}})}]);`;\n        const workerUrl = \"data:text/javascript;base64,\" + btoa(workerScript);\n        const worker = new Worker(workerUrl);\n        worker.addEventListener(\"message\", ({ data }) => {\n            if (Timeout.isCallNotification(data)) {\n                const { params: { timerId } } = data;\n                const idOrFunc = scheduledTimeoutFunctions.get(timerId);\n                if (typeof idOrFunc === \"number\") {\n                    const unhandledTimerId = unhandledRequests.get(idOrFunc);\n                    if (unhandledTimerId === undefined ||\n                        unhandledTimerId !== timerId) {\n                        throw new Error(\"The timer is in an undefined state.\");\n                    }\n                }\n                else if (typeof idOrFunc !== \"undefined\") {\n                    idOrFunc();\n                    // A timeout can be safely deleted because it is only called once.\n                    scheduledTimeoutFunctions.delete(timerId);\n                }\n                else {\n                    throw new Error(\"The timer is in an undefined state.\");\n                }\n            }\n            else if (Timeout.isClearResponse(data)) {\n                const { id } = data;\n                const unhandledTimerId = unhandledRequests.get(id);\n                if (unhandledTimerId === undefined) {\n                    throw new Error(\"The timer is in an undefined state.\");\n                }\n                unhandledRequests.delete(id);\n                scheduledTimeoutFunctions.delete(unhandledTimerId);\n            }\n            else {\n                const { error: { message } } = data;\n                throw new Error(message);\n            }\n        });\n        const clearTimeout = (timerId) => {\n            const id = Math.random();\n            unhandledRequests.set(id, timerId);\n            scheduledTimeoutFunctions.set(timerId, id);\n            worker.postMessage({\n                id,\n                method: \"clear\",\n                params: { timerId }\n            });\n        };\n        const setTimeout = (func, delay) => {\n            const timerId = Math.random();\n            scheduledTimeoutFunctions.set(timerId, func);\n            worker.postMessage({\n                id: null,\n                method: \"set\",\n                params: {\n                    delay,\n                    now: performance.now(),\n                    timerId\n                }\n            });\n            return timerId;\n        };\n        return {\n            clearTimeout,\n            setTimeout\n        };\n    }\n    static loadWorkerTimers() {\n        return () => {\n            if (Timeout.workerTimers !== null) {\n                return Timeout.workerTimers;\n            }\n            Timeout.workerTimers = Timeout.load();\n            return Timeout.workerTimers;\n        };\n    }\n    static isCallNotification(message) {\n        return message.method !== undefined && message.method === \"call\";\n    }\n    static isClearResponse(message) {\n        return message.error === null && typeof message.id === \"number\";\n    }\n}\nTimeout.workerTimers = null;\nTimeout.clearTimeout = (timerId) => Timeout.timers().clearTimeout(timerId);\nTimeout.setTimeout = (func, delay) => Timeout.timers().setTimeout(func, delay);\nTimeout.timers = Timeout.loadWorkerTimers();\n\n//# sourceMappingURL=Timeout.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Timeout.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ActivityReceivedEventArgs.js":
  /*!*****************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ActivityReceivedEventArgs.js ***!
    \*****************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ActivityReceivedEventArgs\": () => (/* binding */ ActivityReceivedEventArgs)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines contents of received message/events.\n * @class ActivityReceivedEventArgs\n */\nclass ActivityReceivedEventArgs {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {any} activity - The activity..\n     */\n    constructor(activity, audioStream) {\n        this.privActivity = activity;\n        this.privAudioStream = audioStream;\n    }\n    /**\n     * Gets the received activity\n     * @member ActivityReceivedEventArgs.prototype.activity\n     * @function\n     * @public\n     * @returns {any} the received activity.\n     */\n    get activity() {\n        return this.privActivity;\n    }\n    get audioStream() {\n        return this.privAudioStream;\n    }\n}\n\n//# sourceMappingURL=ActivityReceivedEventArgs.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ActivityReceivedEventArgs.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioConfig.js":
  /*!*********************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioConfig.js ***!
    \*********************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AudioConfig\": () => (/* binding */ AudioConfig),\n/* harmony export */   \"AudioConfigImpl\": () => (/* binding */ AudioConfigImpl),\n/* harmony export */   \"AudioOutputConfigImpl\": () => (/* binding */ AudioOutputConfigImpl)\n/* harmony export */ });\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/PCMRecorder.js\");\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/MicAudioSource.js\");\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/FileAudioSource.js\");\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/PullAudioInputStreamCallback.js\");\n/* harmony import */ var _AudioInputStream__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./AudioInputStream */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioInputStream.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/SpeakerAudioDestination.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/PushAudioOutputStreamCallback.js\");\n/* harmony import */ var _AudioOutputStream__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./AudioOutputStream */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputStream.js\");\n/* harmony import */ var _AudioFileWriter__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./AudioFileWriter */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioFileWriter.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\n\n\n\n/**\n * Represents audio input configuration used for specifying what type of input to use (microphone, file, stream).\n * @class AudioConfig\n * Updated in version 1.11.0\n */\nclass AudioConfig {\n    /**\n     * Creates an AudioConfig object representing the default microphone on the system.\n     * @member AudioConfig.fromDefaultMicrophoneInput\n     * @function\n     * @public\n     * @returns {AudioConfig} The audio input configuration being created.\n     */\n    static fromDefaultMicrophoneInput() {\n        const pcmRecorder = new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__.PcmRecorder(true);\n        return new AudioConfigImpl(new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_1__.MicAudioSource(pcmRecorder));\n    }\n    /**\n     * Creates an AudioConfig object representing a microphone with the specified device ID.\n     * @member AudioConfig.fromMicrophoneInput\n     * @function\n     * @public\n     * @param {string | undefined} deviceId - Specifies the device ID of the microphone to be used.\n     * Default microphone is used the value is omitted.\n     * @returns {AudioConfig} The audio input configuration being created.\n     */\n    static fromMicrophoneInput(deviceId) {\n        const pcmRecorder = new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__.PcmRecorder(true);\n        return new AudioConfigImpl(new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_1__.MicAudioSource(pcmRecorder, deviceId));\n    }\n    /**\n     * Creates an AudioConfig object representing the specified file.\n     * @member AudioConfig.fromWavFileInput\n     * @function\n     * @public\n     * @param {File} fileName - Specifies the audio input file. Currently, only WAV / PCM is supported.\n     * @returns {AudioConfig} The audio input configuration being created.\n     */\n    static fromWavFileInput(file, name = \"unnamedBuffer.wav\") {\n        return new AudioConfigImpl(new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_2__.FileAudioSource(file, name));\n    }\n    /**\n     * Creates an AudioConfig object representing the specified stream.\n     * @member AudioConfig.fromStreamInput\n     * @function\n     * @public\n     * @param {AudioInputStream | PullAudioInputStreamCallback | MediaStream} audioStream - Specifies the custom audio input\n     * stream. Currently, only WAV / PCM is supported.\n     * @returns {AudioConfig} The audio input configuration being created.\n     */\n    static fromStreamInput(audioStream) {\n        if (audioStream instanceof _Exports__WEBPACK_IMPORTED_MODULE_3__.PullAudioInputStreamCallback) {\n            return new AudioConfigImpl(new _AudioInputStream__WEBPACK_IMPORTED_MODULE_4__.PullAudioInputStreamImpl(audioStream));\n        }\n        if (audioStream instanceof _AudioInputStream__WEBPACK_IMPORTED_MODULE_4__.AudioInputStream) {\n            return new AudioConfigImpl(audioStream);\n        }\n        if (typeof MediaStream !== \"undefined\" && audioStream instanceof MediaStream) {\n            const pcmRecorder = new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__.PcmRecorder(false);\n            return new AudioConfigImpl(new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_1__.MicAudioSource(pcmRecorder, null, null, audioStream));\n        }\n        throw new Error(\"Not Supported Type\");\n    }\n    /**\n     * Creates an AudioConfig object representing the default speaker.\n     * @member AudioConfig.fromDefaultSpeakerOutput\n     * @function\n     * @public\n     * @returns {AudioConfig} The audio output configuration being created.\n     * Added in version 1.11.0\n     */\n    static fromDefaultSpeakerOutput() {\n        return new AudioOutputConfigImpl(new _Exports__WEBPACK_IMPORTED_MODULE_5__.SpeakerAudioDestination());\n    }\n    /**\n     * Creates an AudioConfig object representing the custom IPlayer object.\n     * You can use the IPlayer object to control pause, resume, etc.\n     * @member AudioConfig.fromSpeakerOutput\n     * @function\n     * @public\n     * @param {IPlayer} player - the IPlayer object for playback.\n     * @returns {AudioConfig} The audio output configuration being created.\n     * Added in version 1.12.0\n     */\n    static fromSpeakerOutput(player) {\n        if (player === undefined) {\n            return AudioConfig.fromDefaultSpeakerOutput();\n        }\n        if (player instanceof _Exports__WEBPACK_IMPORTED_MODULE_5__.SpeakerAudioDestination) {\n            return new AudioOutputConfigImpl(player);\n        }\n        throw new Error(\"Not Supported Type\");\n    }\n    /**\n     * Creates an AudioConfig object representing a specified output audio file\n     * @member AudioConfig.fromAudioFileOutput\n     * @function\n     * @public\n     * @param {PathLike} filename - the filename of the output audio file\n     * @returns {AudioConfig} The audio output configuration being created.\n     * Added in version 1.11.0\n     */\n    static fromAudioFileOutput(filename) {\n        return new AudioOutputConfigImpl(new _AudioFileWriter__WEBPACK_IMPORTED_MODULE_6__.AudioFileWriter(filename));\n    }\n    /**\n     * Creates an AudioConfig object representing a specified audio output stream\n     * @member AudioConfig.fromStreamOutput\n     * @function\n     * @public\n     * @param {AudioOutputStream | PushAudioOutputStreamCallback} audioStream - Specifies the custom audio output\n     * stream.\n     * @returns {AudioConfig} The audio output configuration being created.\n     * Added in version 1.11.0\n     */\n    static fromStreamOutput(audioStream) {\n        if (audioStream instanceof _Exports__WEBPACK_IMPORTED_MODULE_7__.PushAudioOutputStreamCallback) {\n            return new AudioOutputConfigImpl(new _AudioOutputStream__WEBPACK_IMPORTED_MODULE_8__.PushAudioOutputStreamImpl(audioStream));\n        }\n        if (audioStream instanceof _AudioOutputStream__WEBPACK_IMPORTED_MODULE_8__.PushAudioOutputStream) {\n            return new AudioOutputConfigImpl(audioStream);\n        }\n        if (audioStream instanceof _AudioOutputStream__WEBPACK_IMPORTED_MODULE_8__.PullAudioOutputStream) {\n            return new AudioOutputConfigImpl(audioStream);\n        }\n        throw new Error(\"Not Supported Type\");\n    }\n}\n/**\n * Represents audio input stream used for custom audio input configurations.\n * @private\n * @class AudioConfigImpl\n */\nclass AudioConfigImpl extends AudioConfig {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {IAudioSource} source - An audio source.\n     */\n    constructor(source) {\n        super();\n        this.privSource = source;\n    }\n    /**\n     * Format information for the audio\n     */\n    get format() {\n        return this.privSource.format;\n    }\n    /**\n     * @member AudioConfigImpl.prototype.close\n     * @function\n     * @public\n     */\n    close(cb, err) {\n        this.privSource.turnOff().then(() => {\n            if (!!cb) {\n                cb();\n            }\n        }, (error) => {\n            if (!!err) {\n                err(error);\n            }\n        });\n    }\n    /**\n     * @member AudioConfigImpl.prototype.id\n     * @function\n     * @public\n     */\n    id() {\n        return this.privSource.id();\n    }\n    /**\n     * @member AudioConfigImpl.prototype.blob\n     * @function\n     * @public\n     */\n    get blob() {\n        return this.privSource.blob;\n    }\n    /**\n     * @member AudioConfigImpl.prototype.turnOn\n     * @function\n     * @public\n     * @returns {Promise<void>} A promise.\n     */\n    turnOn() {\n        return this.privSource.turnOn();\n    }\n    /**\n     * @member AudioConfigImpl.prototype.attach\n     * @function\n     * @public\n     * @param {string} audioNodeId - The audio node id.\n     * @returns {Promise<IAudioStreamNode>} A promise.\n     */\n    attach(audioNodeId) {\n        return this.privSource.attach(audioNodeId);\n    }\n    /**\n     * @member AudioConfigImpl.prototype.detach\n     * @function\n     * @public\n     * @param {string} audioNodeId - The audio node id.\n     */\n    detach(audioNodeId) {\n        return this.privSource.detach(audioNodeId);\n    }\n    /**\n     * @member AudioConfigImpl.prototype.turnOff\n     * @function\n     * @public\n     * @returns {Promise<void>} A promise.\n     */\n    turnOff() {\n        return this.privSource.turnOff();\n    }\n    /**\n     * @member AudioConfigImpl.prototype.events\n     * @function\n     * @public\n     * @returns {EventSource<AudioSourceEvent>} An event source for audio events.\n     */\n    get events() {\n        return this.privSource.events;\n    }\n    setProperty(name, value) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_9__.Contracts.throwIfNull(value, \"value\");\n        if (undefined !== this.privSource.setProperty) {\n            this.privSource.setProperty(name, value);\n        }\n        else {\n            throw new Error(\"This AudioConfig instance does not support setting properties.\");\n        }\n    }\n    getProperty(name, def) {\n        if (undefined !== this.privSource.getProperty) {\n            return this.privSource.getProperty(name, def);\n        }\n        else {\n            throw new Error(\"This AudioConfig instance does not support getting properties.\");\n        }\n        return def;\n    }\n    get deviceInfo() {\n        return this.privSource.deviceInfo;\n    }\n}\nclass AudioOutputConfigImpl extends AudioConfig {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {IAudioDestination} destination - An audio destination.\n     */\n    constructor(destination) {\n        super();\n        this.privDestination = destination;\n    }\n    set format(format) {\n        this.privDestination.format = format;\n    }\n    write(buffer) {\n        this.privDestination.write(buffer);\n    }\n    close() {\n        this.privDestination.close();\n    }\n    id() {\n        return this.privDestination.id();\n    }\n    setProperty() {\n        throw new Error(\"This AudioConfig instance does not support setting properties.\");\n    }\n    getProperty() {\n        throw new Error(\"This AudioConfig instance does not support getting properties.\");\n    }\n}\n\n//# sourceMappingURL=AudioConfig.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioConfig.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioFileWriter.js":
  /*!*************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioFileWriter.js ***!
    \*************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AudioFileWriter\": () => (/* binding */ AudioFileWriter)\n/* harmony export */ });\n/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! fs */ \"?9463\");\n/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(fs__WEBPACK_IMPORTED_MODULE_0__);\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\nclass AudioFileWriter {\n    constructor(filename) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrUndefined(fs__WEBPACK_IMPORTED_MODULE_0__.openSync, \"\\nFile System access not available, please use Push or PullAudioOutputStream\");\n        this.privFd = fs__WEBPACK_IMPORTED_MODULE_0__.openSync(filename, \"w\");\n    }\n    set format(format) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNotUndefined(this.privAudioFormat, \"format is already set\");\n        this.privAudioFormat = format;\n        let headerOffset = 0;\n        if (this.privAudioFormat.hasHeader) {\n            headerOffset = this.privAudioFormat.header.byteLength;\n        }\n        if (this.privFd !== undefined) {\n            this.privWriteStream = fs__WEBPACK_IMPORTED_MODULE_0__.createWriteStream(\"\", { fd: this.privFd, start: headerOffset, autoClose: false });\n        }\n    }\n    write(buffer) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrUndefined(this.privAudioFormat, \"must set format before writing.\");\n        if (this.privWriteStream !== undefined) {\n            this.privWriteStream.write(new Uint8Array(buffer.slice(0)));\n        }\n    }\n    close() {\n        if (this.privFd !== undefined) {\n            this.privWriteStream.on(\"finish\", () => {\n                if (this.privAudioFormat.hasHeader) {\n                    this.privAudioFormat.updateHeader(this.privWriteStream.bytesWritten);\n                    fs__WEBPACK_IMPORTED_MODULE_0__.writeSync(this.privFd, new Int8Array(this.privAudioFormat.header), 0, this.privAudioFormat.header.byteLength, 0);\n                }\n                fs__WEBPACK_IMPORTED_MODULE_0__.closeSync(this.privFd);\n                this.privFd = undefined;\n            });\n            this.privWriteStream.end();\n        }\n    }\n    id() {\n        return this.privId;\n    }\n}\n\n//# sourceMappingURL=AudioFileWriter.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioFileWriter.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioInputStream.js":
  /*!**************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioInputStream.js ***!
    \**************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AudioInputStream\": () => (/* binding */ AudioInputStream),\n/* harmony export */   \"PullAudioInputStream\": () => (/* binding */ PullAudioInputStream),\n/* harmony export */   \"PullAudioInputStreamImpl\": () => (/* binding */ PullAudioInputStreamImpl),\n/* harmony export */   \"PushAudioInputStream\": () => (/* binding */ PushAudioInputStream),\n/* harmony export */   \"PushAudioInputStreamImpl\": () => (/* binding */ PushAudioInputStreamImpl)\n/* harmony export */ });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/EventSource.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ChunkedArrayBufferStream.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/AudioSourceEvents.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Events.js\");\n/* harmony import */ var _common_Guid__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../common/Guid */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js\");\n/* harmony import */ var _AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./AudioStreamFormat */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioStreamFormat.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n/* eslint-disable max-classes-per-file */\n\n\n\n\n\n/**\n * Represents audio input stream used for custom audio input configurations.\n * @class AudioInputStream\n */\nclass AudioInputStream {\n    /**\n     * Creates and initializes an instance.\n     * @constructor\n     */\n    constructor() {\n        return;\n    }\n    /**\n     * Creates a memory backed PushAudioInputStream with the specified audio format.\n     * @member AudioInputStream.createPushStream\n     * @function\n     * @public\n     * @param {AudioStreamFormat} format - The audio data format in which audio will be\n     * written to the push audio stream's write() method (Required if format is not 16 kHz 16bit mono PCM).\n     * @returns {PushAudioInputStream} The audio input stream being created.\n     */\n    static createPushStream(format) {\n        return PushAudioInputStream.create(format);\n    }\n    /**\n     * Creates a PullAudioInputStream that delegates to the specified callback interface for read()\n     * and close() methods.\n     * @member AudioInputStream.createPullStream\n     * @function\n     * @public\n     * @param {PullAudioInputStreamCallback} callback - The custom audio input object, derived from\n     * PullAudioInputStreamCallback\n     * @param {AudioStreamFormat} format - The audio data format in which audio will be returned from\n     * the callback's read() method (Required if format is not 16 kHz 16bit mono PCM).\n     * @returns {PullAudioInputStream} The audio input stream being created.\n     */\n    static createPullStream(callback, format) {\n        return PullAudioInputStream.create(callback, format);\n        // throw new Error(\"Oops\");\n    }\n}\n/**\n * Represents memory backed push audio input stream used for custom audio input configurations.\n * @class PushAudioInputStream\n */\nclass PushAudioInputStream extends AudioInputStream {\n    /**\n     * Creates a memory backed PushAudioInputStream with the specified audio format.\n     * @member PushAudioInputStream.create\n     * @function\n     * @public\n     * @param {AudioStreamFormat} format - The audio data format in which audio will be written to the\n     * push audio stream's write() method (Required if format is not 16 kHz 16bit mono PCM).\n     * @returns {PushAudioInputStream} The push audio input stream being created.\n     */\n    static create(format) {\n        return new PushAudioInputStreamImpl(format);\n    }\n}\n/**\n * Represents memory backed push audio input stream used for custom audio input configurations.\n * @private\n * @class PushAudioInputStreamImpl\n */\nclass PushAudioInputStreamImpl extends PushAudioInputStream {\n    /**\n     * Creates and initalizes an instance with the given values.\n     * @constructor\n     * @param {AudioStreamFormat} format - The audio stream format.\n     */\n    constructor(format) {\n        super();\n        if (format === undefined) {\n            this.privFormat = _AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioStreamFormatImpl.getDefaultInputFormat();\n        }\n        else {\n            this.privFormat = format;\n        }\n        this.privEvents = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.EventSource();\n        this.privId = (0,_common_Guid__WEBPACK_IMPORTED_MODULE_2__.createNoDashGuid)();\n        this.privStream = new _common_Exports__WEBPACK_IMPORTED_MODULE_3__.ChunkedArrayBufferStream(this.privFormat.avgBytesPerSec / 10);\n    }\n    /**\n     * Format information for the audio\n     */\n    get format() {\n        return Promise.resolve(this.privFormat);\n    }\n    /**\n     * Writes the audio data specified by making an internal copy of the data.\n     * @member PushAudioInputStreamImpl.prototype.write\n     * @function\n     * @public\n     * @param {ArrayBuffer} dataBuffer - The audio buffer of which this function will make a copy.\n     */\n    write(dataBuffer) {\n        this.privStream.writeStreamChunk({\n            buffer: dataBuffer,\n            isEnd: false,\n            timeReceived: Date.now()\n        });\n    }\n    /**\n     * Closes the stream.\n     * @member PushAudioInputStreamImpl.prototype.close\n     * @function\n     * @public\n     */\n    close() {\n        this.privStream.close();\n    }\n    id() {\n        return this.privId;\n    }\n    get blob() {\n        return this.attach(\"id\").then((audioNode) => {\n            const data = [];\n            let bufferData = Buffer.from(\"\");\n            const readCycle = () => audioNode.read().then((audioStreamChunk) => {\n                if (!audioStreamChunk || audioStreamChunk.isEnd) {\n                    if (typeof (XMLHttpRequest) !== \"undefined\" && typeof (Blob) !== \"undefined\") {\n                        return Promise.resolve(new Blob(data));\n                    }\n                    else {\n                        return Promise.resolve(Buffer.from(bufferData));\n                    }\n                }\n                else {\n                    if (typeof (Blob) !== \"undefined\") {\n                        data.push(audioStreamChunk.buffer);\n                    }\n                    else {\n                        bufferData = Buffer.concat([bufferData, this.toBuffer(audioStreamChunk.buffer)]);\n                    }\n                    return readCycle();\n                }\n            });\n            return readCycle();\n        });\n    }\n    turnOn() {\n        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_4__.AudioSourceInitializingEvent(this.privId)); // no stream id\n        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_4__.AudioSourceReadyEvent(this.privId));\n        return;\n    }\n    attach(audioNodeId) {\n        return __awaiter(this, void 0, void 0, function* () {\n            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_4__.AudioStreamNodeAttachingEvent(this.privId, audioNodeId));\n            yield this.turnOn();\n            const stream = this.privStream;\n            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_4__.AudioStreamNodeAttachedEvent(this.privId, audioNodeId));\n            return {\n                detach: () => __awaiter(this, void 0, void 0, function* () {\n                    this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_4__.AudioStreamNodeDetachedEvent(this.privId, audioNodeId));\n                    return this.turnOff();\n                }),\n                id: () => audioNodeId,\n                read: () => stream.read(),\n            };\n        });\n    }\n    detach(audioNodeId) {\n        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_4__.AudioStreamNodeDetachedEvent(this.privId, audioNodeId));\n    }\n    turnOff() {\n        return;\n    }\n    get events() {\n        return this.privEvents;\n    }\n    get deviceInfo() {\n        return Promise.resolve({\n            bitspersample: this.privFormat.bitsPerSample,\n            channelcount: this.privFormat.channels,\n            connectivity: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.connectivity.Unknown,\n            manufacturer: \"Speech SDK\",\n            model: \"PushStream\",\n            samplerate: this.privFormat.samplesPerSec,\n            type: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.type.Stream,\n        });\n    }\n    onEvent(event) {\n        this.privEvents.onEvent(event);\n        _common_Exports__WEBPACK_IMPORTED_MODULE_6__.Events.instance.onEvent(event);\n    }\n    toBuffer(arrayBuffer) {\n        const buf = Buffer.alloc(arrayBuffer.byteLength);\n        const view = new Uint8Array(arrayBuffer);\n        for (let i = 0; i < buf.length; ++i) {\n            buf[i] = view[i];\n        }\n        return buf;\n    }\n}\n/*\n * Represents audio input stream used for custom audio input configurations.\n * @class PullAudioInputStream\n */\nclass PullAudioInputStream extends AudioInputStream {\n    /**\n     * Creates and initializes and instance.\n     * @constructor\n     */\n    constructor() {\n        super();\n    }\n    /**\n     * Creates a PullAudioInputStream that delegates to the specified callback interface for\n     * read() and close() methods, using the default format (16 kHz 16bit mono PCM).\n     * @member PullAudioInputStream.create\n     * @function\n     * @public\n     * @param {PullAudioInputStreamCallback} callback - The custom audio input object,\n     * derived from PullAudioInputStreamCustomCallback\n     * @param {AudioStreamFormat} format - The audio data format in which audio will be\n     * returned from the callback's read() method (Required if format is not 16 kHz 16bit mono PCM).\n     * @returns {PullAudioInputStream} The push audio input stream being created.\n     */\n    static create(callback, format) {\n        return new PullAudioInputStreamImpl(callback, format);\n    }\n}\n/**\n * Represents audio input stream used for custom audio input configurations.\n * @private\n * @class PullAudioInputStreamImpl\n */\nclass PullAudioInputStreamImpl extends PullAudioInputStream {\n    /**\n     * Creates a PullAudioInputStream that delegates to the specified callback interface for\n     * read() and close() methods, using the default format (16 kHz 16bit mono PCM).\n     * @constructor\n     * @param {PullAudioInputStreamCallback} callback - The custom audio input object,\n     * derived from PullAudioInputStreamCustomCallback\n     * @param {AudioStreamFormat} format - The audio data format in which audio will be\n     * returned from the callback's read() method (Required if format is not 16 kHz 16bit mono PCM).\n     */\n    constructor(callback, format) {\n        super();\n        if (undefined === format) {\n            this.privFormat = _AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioStreamFormat.getDefaultInputFormat();\n        }\n        else {\n            this.privFormat = format;\n        }\n        this.privEvents = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.EventSource();\n        this.privId = (0,_common_Guid__WEBPACK_IMPORTED_MODULE_2__.createNoDashGuid)();\n        this.privCallback = callback;\n        this.privIsClosed = false;\n        this.privBufferSize = this.privFormat.avgBytesPerSec / 10;\n    }\n    /**\n     * Format information for the audio\n     */\n    get format() {\n        return Promise.resolve(this.privFormat);\n    }\n    /**\n     * Closes the stream.\n     * @member PullAudioInputStreamImpl.prototype.close\n     * @function\n     * @public\n     */\n    close() {\n        this.privIsClosed = true;\n        this.privCallback.close();\n    }\n    id() {\n        return this.privId;\n    }\n    get blob() {\n        return Promise.reject(\"Not implemented\");\n    }\n    turnOn() {\n        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_4__.AudioSourceInitializingEvent(this.privId)); // no stream id\n        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_4__.AudioSourceReadyEvent(this.privId));\n        return;\n    }\n    attach(audioNodeId) {\n        return __awaiter(this, void 0, void 0, function* () {\n            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_4__.AudioStreamNodeAttachingEvent(this.privId, audioNodeId));\n            yield this.turnOn();\n            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_4__.AudioStreamNodeAttachedEvent(this.privId, audioNodeId));\n            return {\n                detach: () => {\n                    this.privCallback.close();\n                    this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_4__.AudioStreamNodeDetachedEvent(this.privId, audioNodeId));\n                    return this.turnOff();\n                },\n                id: () => audioNodeId,\n                read: () => {\n                    let totalBytes = 0;\n                    let transmitBuff;\n                    // Until we have the minimum number of bytes to send in a transmission, keep asking for more.\n                    while (totalBytes < this.privBufferSize) {\n                        // Sizing the read buffer to the delta between the perfect size and what's left means we won't ever get too much\n                        // data back.\n                        const readBuff = new ArrayBuffer(this.privBufferSize - totalBytes);\n                        const pulledBytes = this.privCallback.read(readBuff);\n                        // If there is no return buffer yet defined, set the return buffer to the that was just populated.\n                        // This was, if we have enough data there's no copy penalty, but if we don't we have a buffer that's the\n                        // preferred size allocated.\n                        if (undefined === transmitBuff) {\n                            transmitBuff = readBuff;\n                        }\n                        else {\n                            // Not the first bite at the apple, so fill the return buffer with the data we got back.\n                            const intView = new Int8Array(transmitBuff);\n                            intView.set(new Int8Array(readBuff), totalBytes);\n                        }\n                        // If there are no bytes to read, just break out and be done.\n                        if (0 === pulledBytes) {\n                            break;\n                        }\n                        totalBytes += pulledBytes;\n                    }\n                    return Promise.resolve({\n                        buffer: transmitBuff.slice(0, totalBytes),\n                        isEnd: this.privIsClosed || totalBytes === 0,\n                        timeReceived: Date.now(),\n                    });\n                },\n            };\n        });\n    }\n    detach(audioNodeId) {\n        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_4__.AudioStreamNodeDetachedEvent(this.privId, audioNodeId));\n    }\n    turnOff() {\n        return;\n    }\n    get events() {\n        return this.privEvents;\n    }\n    get deviceInfo() {\n        return Promise.resolve({\n            bitspersample: this.privFormat.bitsPerSample,\n            channelcount: this.privFormat.channels,\n            connectivity: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.connectivity.Unknown,\n            manufacturer: \"Speech SDK\",\n            model: \"PullStream\",\n            samplerate: this.privFormat.samplesPerSec,\n            type: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.type.Stream,\n        });\n    }\n    onEvent(event) {\n        this.privEvents.onEvent(event);\n        _common_Exports__WEBPACK_IMPORTED_MODULE_6__.Events.instance.onEvent(event);\n    }\n}\n\n//# sourceMappingURL=AudioInputStream.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioInputStream.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputFormat.js":
  /*!***************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputFormat.js ***!
    \***************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AudioOutputFormatImpl\": () => (/* binding */ AudioOutputFormatImpl)\n/* harmony export */ });\n/* harmony import */ var _SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../SpeechSynthesisOutputFormat */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisOutputFormat.js\");\n/* harmony import */ var _AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./AudioStreamFormat */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioStreamFormat.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n/**\n * @private\n * @class AudioOutputFormatImpl\n * Updated in version 1.17.0\n */\n// eslint-disable-next-line max-classes-per-file\nclass AudioOutputFormatImpl extends _AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioStreamFormatImpl {\n    /**\n     * Creates an instance with the given values.\n     * @constructor\n     * @param formatTag\n     * @param {number} channels - Number of channels.\n     * @param {number} samplesPerSec - Samples per second.\n     * @param {number} avgBytesPerSec - Average bytes per second.\n     * @param {number} blockAlign - Block alignment.\n     * @param {number} bitsPerSample - Bits per sample.\n     * @param {string} audioFormatString - Audio format string\n     * @param {string} requestAudioFormatString - Audio format string sent to service.\n     * @param {boolean} hasHeader - If the format has header or not.\n     */\n    constructor(formatTag, channels, samplesPerSec, avgBytesPerSec, blockAlign, bitsPerSample, audioFormatString, requestAudioFormatString, hasHeader) {\n        super(samplesPerSec, bitsPerSample, channels, formatTag);\n        this.formatTag = formatTag;\n        this.avgBytesPerSec = avgBytesPerSec;\n        this.blockAlign = blockAlign;\n        this.priAudioFormatString = audioFormatString;\n        this.priRequestAudioFormatString = requestAudioFormatString;\n        this.priHasHeader = hasHeader;\n    }\n    static fromSpeechSynthesisOutputFormat(speechSynthesisOutputFormat) {\n        if (speechSynthesisOutputFormat === undefined) {\n            return AudioOutputFormatImpl.getDefaultOutputFormat();\n        }\n        return AudioOutputFormatImpl.fromSpeechSynthesisOutputFormatString(AudioOutputFormatImpl.SpeechSynthesisOutputFormatToString[speechSynthesisOutputFormat]);\n    }\n    static fromSpeechSynthesisOutputFormatString(speechSynthesisOutputFormatString) {\n        switch (speechSynthesisOutputFormatString) {\n            case \"raw-8khz-8bit-mono-mulaw\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.MuLaw, 1, 8000, 8000, 1, 8, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"riff-16khz-16kbps-mono-siren\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.Siren, 1, 16000, 2000, 40, 0, speechSynthesisOutputFormatString, \"audio-16khz-16kbps-mono-siren\", true);\n            case \"audio-16khz-16kbps-mono-siren\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.Siren, 1, 16000, 2000, 40, 0, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"audio-16khz-32kbitrate-mono-mp3\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.MP3, 1, 16000, 32 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"audio-16khz-128kbitrate-mono-mp3\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.MP3, 1, 16000, 128 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"audio-16khz-64kbitrate-mono-mp3\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.MP3, 1, 16000, 64 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"audio-24khz-48kbitrate-mono-mp3\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.MP3, 1, 24000, 48 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"audio-24khz-96kbitrate-mono-mp3\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.MP3, 1, 24000, 96 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"audio-24khz-160kbitrate-mono-mp3\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.MP3, 1, 24000, 160 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"raw-16khz-16bit-mono-truesilk\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.SILKSkype, 1, 16000, 32000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"riff-8khz-16bit-mono-pcm\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.PCM, 1, 8000, 16000, 2, 16, speechSynthesisOutputFormatString, \"raw-8khz-16bit-mono-pcm\", true);\n            case \"riff-24khz-16bit-mono-pcm\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.PCM, 1, 24000, 48000, 2, 16, speechSynthesisOutputFormatString, \"raw-24khz-16bit-mono-pcm\", true);\n            case \"riff-8khz-8bit-mono-mulaw\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.MuLaw, 1, 8000, 8000, 1, 8, speechSynthesisOutputFormatString, \"raw-8khz-8bit-mono-mulaw\", true);\n            case \"raw-16khz-16bit-mono-pcm\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.PCM, 1, 16000, 32000, 2, 16, speechSynthesisOutputFormatString, \"raw-16khz-16bit-mono-pcm\", false);\n            case \"raw-24khz-16bit-mono-pcm\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.PCM, 1, 24000, 48000, 2, 16, speechSynthesisOutputFormatString, \"raw-24khz-16bit-mono-pcm\", false);\n            case \"raw-8khz-16bit-mono-pcm\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.PCM, 1, 8000, 16000, 2, 16, speechSynthesisOutputFormatString, \"raw-8khz-16bit-mono-pcm\", false);\n            case \"ogg-16khz-16bit-mono-opus\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.OGG_OPUS, 1, 16000, 8192, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"ogg-24khz-16bit-mono-opus\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.OGG_OPUS, 1, 24000, 8192, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"raw-48khz-16bit-mono-pcm\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.PCM, 1, 48000, 96000, 2, 16, speechSynthesisOutputFormatString, \"raw-48khz-16bit-mono-pcm\", false);\n            case \"riff-48khz-16bit-mono-pcm\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.PCM, 1, 48000, 96000, 2, 16, speechSynthesisOutputFormatString, \"raw-48khz-16bit-mono-pcm\", true);\n            case \"audio-48khz-96kbitrate-mono-mp3\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.MP3, 1, 48000, 96 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"audio-48khz-192kbitrate-mono-mp3\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.MP3, 1, 48000, 192 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"ogg-48khz-16bit-mono-opus\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.OGG_OPUS, 1, 48000, 12000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"webm-16khz-16bit-mono-opus\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.WEBM_OPUS, 1, 16000, 4000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"webm-24khz-16bit-mono-opus\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.WEBM_OPUS, 1, 24000, 6000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"webm-24khz-16bit-24kbps-mono-opus\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.WEBM_OPUS, 1, 24000, 3000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"audio-16khz-16bit-32kbps-mono-opus\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.OPUS, 1, 16000, 4000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"audio-24khz-16bit-48kbps-mono-opus\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.OPUS, 1, 24000, 6000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"audio-24khz-16bit-24kbps-mono-opus\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.OPUS, 1, 24000, 3000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"audio-24khz-16bit-mono-flac\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.FLAC, 1, 24000, 24000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"audio-48khz-16bit-mono-flac\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.FLAC, 1, 48000, 30000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"raw-24khz-16bit-mono-truesilk\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.SILKSkype, 1, 24000, 48000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"raw-8khz-8bit-mono-alaw\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.ALaw, 1, 8000, 8000, 1, 8, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"riff-8khz-8bit-mono-alaw\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.ALaw, 1, 8000, 8000, 1, 8, speechSynthesisOutputFormatString, \"raw-8khz-8bit-mono-alaw\", true);\n            case \"raw-22050hz-16bit-mono-pcm\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.PCM, 1, 22050, 44100, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"riff-22050hz-16bit-mono-pcm\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.PCM, 1, 22050, 44100, 2, 16, speechSynthesisOutputFormatString, \"raw-22050hz-16bit-mono-pcm\", true);\n            case \"raw-44100hz-16bit-mono-pcm\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.PCM, 1, 44100, 88200, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"riff-44100hz-16bit-mono-pcm\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.PCM, 1, 44100, 88200, 2, 16, speechSynthesisOutputFormatString, \"raw-44100hz-16bit-mono-pcm\", true);\n            case \"riff-16khz-16bit-mono-pcm\":\n            default:\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.PCM, 1, 16000, 32000, 2, 16, \"riff-16khz-16bit-mono-pcm\", \"raw-16khz-16bit-mono-pcm\", true);\n        }\n    }\n    static getDefaultOutputFormat() {\n        return AudioOutputFormatImpl.fromSpeechSynthesisOutputFormatString((typeof window !== \"undefined\") ? \"audio-24khz-48kbitrate-mono-mp3\" : \"riff-16khz-16bit-mono-pcm\");\n    }\n    /**\n     * Specifies if this audio output format has a header\n     * @boolean AudioOutputFormatImpl.prototype.hasHeader\n     * @function\n     * @public\n     */\n    get hasHeader() {\n        return this.priHasHeader;\n    }\n    /**\n     * Specifies the header of this format\n     * @ArrayBuffer AudioOutputFormatImpl.prototype.header\n     * @function\n     * @public\n     */\n    get header() {\n        if (this.hasHeader) {\n            return this.privHeader;\n        }\n        return undefined;\n    }\n    /**\n     * Updates the header based on the audio length\n     * @member AudioOutputFormatImpl.updateHeader\n     * @function\n     * @public\n     * @param {number} audioLength - the audio length\n     */\n    updateHeader(audioLength) {\n        if (this.priHasHeader) {\n            const view = new DataView(this.privHeader);\n            view.setUint32(4, audioLength + this.privHeader.byteLength - 8, true);\n            view.setUint32(40, audioLength, true);\n        }\n    }\n    /**\n     * Specifies the audio format string to be sent to the service\n     * @string AudioOutputFormatImpl.prototype.requestAudioFormatString\n     * @function\n     * @public\n     */\n    get requestAudioFormatString() {\n        return this.priRequestAudioFormatString;\n    }\n}\nAudioOutputFormatImpl.SpeechSynthesisOutputFormatToString = {\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Raw8Khz8BitMonoMULaw]: \"raw-8khz-8bit-mono-mulaw\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Riff16Khz16KbpsMonoSiren]: \"riff-16khz-16kbps-mono-siren\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Audio16Khz16KbpsMonoSiren]: \"audio-16khz-16kbps-mono-siren\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Audio16Khz32KBitRateMonoMp3]: \"audio-16khz-32kbitrate-mono-mp3\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Audio16Khz128KBitRateMonoMp3]: \"audio-16khz-128kbitrate-mono-mp3\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Audio16Khz64KBitRateMonoMp3]: \"audio-16khz-64kbitrate-mono-mp3\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Audio24Khz48KBitRateMonoMp3]: \"audio-24khz-48kbitrate-mono-mp3\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Audio24Khz96KBitRateMonoMp3]: \"audio-24khz-96kbitrate-mono-mp3\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Audio24Khz160KBitRateMonoMp3]: \"audio-24khz-160kbitrate-mono-mp3\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Raw16Khz16BitMonoTrueSilk]: \"raw-16khz-16bit-mono-truesilk\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Riff16Khz16BitMonoPcm]: \"riff-16khz-16bit-mono-pcm\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Riff8Khz16BitMonoPcm]: \"riff-8khz-16bit-mono-pcm\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Riff24Khz16BitMonoPcm]: \"riff-24khz-16bit-mono-pcm\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Riff8Khz8BitMonoMULaw]: \"riff-8khz-8bit-mono-mulaw\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Raw16Khz16BitMonoPcm]: \"raw-16khz-16bit-mono-pcm\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Raw24Khz16BitMonoPcm]: \"raw-24khz-16bit-mono-pcm\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Raw8Khz16BitMonoPcm]: \"raw-8khz-16bit-mono-pcm\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Ogg16Khz16BitMonoOpus]: \"ogg-16khz-16bit-mono-opus\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Ogg24Khz16BitMonoOpus]: \"ogg-24khz-16bit-mono-opus\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Raw48Khz16BitMonoPcm]: \"raw-48khz-16bit-mono-pcm\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Riff48Khz16BitMonoPcm]: \"riff-48khz-16bit-mono-pcm\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Audio48Khz96KBitRateMonoMp3]: \"audio-48khz-96kbitrate-mono-mp3\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Audio48Khz192KBitRateMonoMp3]: \"audio-48khz-192kbitrate-mono-mp3\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Ogg48Khz16BitMonoOpus]: \"ogg-48khz-16bit-mono-opus\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Webm16Khz16BitMonoOpus]: \"webm-16khz-16bit-mono-opus\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Webm24Khz16BitMonoOpus]: \"webm-24khz-16bit-mono-opus\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Webm24Khz16Bit24KbpsMonoOpus]: \"webm-24khz-16bit-24kbps-mono-opus\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Raw24Khz16BitMonoTrueSilk]: \"raw-24khz-16bit-mono-truesilk\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Raw8Khz8BitMonoALaw]: \"raw-8khz-8bit-mono-alaw\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Riff8Khz8BitMonoALaw]: \"riff-8khz-8bit-mono-alaw\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Audio16Khz16Bit32KbpsMonoOpus]: \"audio-16khz-16bit-32kbps-mono-opus\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Audio24Khz16Bit48KbpsMonoOpus]: \"audio-24khz-16bit-48kbps-mono-opus\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Audio24Khz16Bit24KbpsMonoOpus]: \"audio-24khz-16bit-24kbps-mono-opus\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Raw22050Hz16BitMonoPcm]: \"raw-22050hz-16bit-mono-pcm\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Riff22050Hz16BitMonoPcm]: \"riff-22050hz-16bit-mono-pcm\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Raw44100Hz16BitMonoPcm]: \"raw-44100hz-16bit-mono-pcm\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Riff44100Hz16BitMonoPcm]: \"riff-44100hz-16bit-mono-pcm\",\n};\n\n//# sourceMappingURL=AudioOutputFormat.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputFormat.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputStream.js":
  /*!***************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputStream.js ***!
    \***************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AudioOutputStream\": () => (/* binding */ AudioOutputStream),\n/* harmony export */   \"PullAudioOutputStream\": () => (/* binding */ PullAudioOutputStream),\n/* harmony export */   \"PullAudioOutputStreamImpl\": () => (/* binding */ PullAudioOutputStreamImpl),\n/* harmony export */   \"PushAudioOutputStream\": () => (/* binding */ PushAudioOutputStream),\n/* harmony export */   \"PushAudioOutputStreamImpl\": () => (/* binding */ PushAudioOutputStreamImpl)\n/* harmony export */ });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Stream.js\");\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _AudioOutputFormat__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./AudioOutputFormat */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputFormat.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n/* eslint-disable max-classes-per-file */\n\n\n\n/**\n * Represents audio output stream used for custom audio output configurations.\n * @class AudioOutputStream\n */\nclass AudioOutputStream {\n    /**\n     * Creates and initializes an instance.\n     * @constructor\n     */\n    constructor() {\n        return;\n    }\n    /**\n     * Creates a memory backed PullAudioOutputStream with the specified audio format.\n     * @member AudioOutputStream.createPullStream\n     * @function\n     * @public\n     * @returns {PullAudioOutputStream} The audio output stream being created.\n     */\n    static createPullStream() {\n        return PullAudioOutputStream.create();\n    }\n}\n/**\n * Represents memory backed push audio output stream used for custom audio output configurations.\n * @class PullAudioOutputStream\n */\nclass PullAudioOutputStream extends AudioOutputStream {\n    /**\n     * Creates a memory backed PullAudioOutputStream with the specified audio format.\n     * @member PullAudioOutputStream.create\n     * @function\n     * @public\n     * @returns {PullAudioOutputStream} The push audio output stream being created.\n     */\n    static create() {\n        return new PullAudioOutputStreamImpl();\n    }\n}\n/**\n * Represents memory backed push audio output stream used for custom audio output configurations.\n * @private\n * @class PullAudioOutputStreamImpl\n */\nclass PullAudioOutputStreamImpl extends PullAudioOutputStream {\n    /**\n     * Creates and initializes an instance with the given values.\n     * @constructor\n     */\n    constructor() {\n        super();\n        this.privId = (0,_common_Exports__WEBPACK_IMPORTED_MODULE_0__.createNoDashGuid)();\n        this.privStream = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.Stream();\n    }\n    /**\n     * Sets the format information to the stream. For internal use only.\n     * @param {AudioStreamFormat} format - the format to be set.\n     */\n    set format(format) {\n        if (format === undefined || format === null) {\n            this.privFormat = _AudioOutputFormat__WEBPACK_IMPORTED_MODULE_2__.AudioOutputFormatImpl.getDefaultOutputFormat();\n        }\n        this.privFormat = format;\n    }\n    /**\n     * Format information for the audio\n     */\n    get format() {\n        return this.privFormat;\n    }\n    /**\n     * Checks if the stream is closed\n     * @member PullAudioOutputStreamImpl.prototype.isClosed\n     * @property\n     * @public\n     */\n    get isClosed() {\n        return this.privStream.isClosed;\n    }\n    /**\n     * Gets the id of the stream\n     * @member PullAudioOutputStreamImpl.prototype.id\n     * @property\n     * @public\n     */\n    id() {\n        return this.privId;\n    }\n    /**\n     * Reads audio data from the internal buffer.\n     * @member PullAudioOutputStreamImpl.prototype.read\n     * @function\n     * @public\n     * @param {ArrayBuffer} dataBuffer - An ArrayBuffer to store the read data.\n     * @returns {Promise<number>} - Audio buffer length has been read.\n     */\n    read(dataBuffer) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const intView = new Int8Array(dataBuffer);\n            let totalBytes = 0;\n            if (this.privLastChunkView !== undefined) {\n                if (this.privLastChunkView.length > dataBuffer.byteLength) {\n                    intView.set(this.privLastChunkView.slice(0, dataBuffer.byteLength));\n                    this.privLastChunkView = this.privLastChunkView.slice(dataBuffer.byteLength);\n                    return Promise.resolve(dataBuffer.byteLength);\n                }\n                intView.set(this.privLastChunkView);\n                totalBytes = this.privLastChunkView.length;\n                this.privLastChunkView = undefined;\n            }\n            // Until we have the minimum number of bytes to send in a transmission, keep asking for more.\n            while (totalBytes < dataBuffer.byteLength && !this.privStream.isReadEnded) {\n                const chunk = yield this.privStream.read();\n                if (chunk !== undefined && !chunk.isEnd) {\n                    let tmpBuffer;\n                    if (chunk.buffer.byteLength > dataBuffer.byteLength - totalBytes) {\n                        tmpBuffer = chunk.buffer.slice(0, dataBuffer.byteLength - totalBytes);\n                        this.privLastChunkView = new Int8Array(chunk.buffer.slice(dataBuffer.byteLength - totalBytes));\n                    }\n                    else {\n                        tmpBuffer = chunk.buffer;\n                    }\n                    intView.set(new Int8Array(tmpBuffer), totalBytes);\n                    totalBytes += tmpBuffer.byteLength;\n                }\n                else {\n                    this.privStream.readEnded();\n                }\n            }\n            return totalBytes;\n        });\n    }\n    /**\n     * Writes the audio data specified by making an internal copy of the data.\n     * @member PullAudioOutputStreamImpl.prototype.write\n     * @function\n     * @public\n     * @param {ArrayBuffer} dataBuffer - The audio buffer of which this function will make a copy.\n     */\n    write(dataBuffer) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_3__.Contracts.throwIfNullOrUndefined(this.privStream, \"must set format before writing\");\n        this.privStream.writeStreamChunk({\n            buffer: dataBuffer,\n            isEnd: false,\n            timeReceived: Date.now()\n        });\n    }\n    /**\n     * Closes the stream.\n     * @member PullAudioOutputStreamImpl.prototype.close\n     * @function\n     * @public\n     */\n    close() {\n        this.privStream.close();\n    }\n}\n/*\n * Represents audio output stream used for custom audio output configurations.\n * @class PushAudioOutputStream\n */\nclass PushAudioOutputStream extends AudioOutputStream {\n    /**\n     * Creates and initializes and instance.\n     * @constructor\n     */\n    constructor() {\n        super();\n    }\n    /**\n     * Creates a PushAudioOutputStream that delegates to the specified callback interface for\n     * write() and close() methods.\n     * @member PushAudioOutputStream.create\n     * @function\n     * @public\n     * @param {PushAudioOutputStreamCallback} callback - The custom audio output object,\n     * derived from PushAudioOutputStreamCallback\n     * @returns {PushAudioOutputStream} The push audio output stream being created.\n     */\n    static create(callback) {\n        return new PushAudioOutputStreamImpl(callback);\n    }\n}\n/**\n * Represents audio output stream used for custom audio output configurations.\n * @private\n * @class PushAudioOutputStreamImpl\n */\nclass PushAudioOutputStreamImpl extends PushAudioOutputStream {\n    /**\n     * Creates a PushAudioOutputStream that delegates to the specified callback interface for\n     * read() and close() methods.\n     * @constructor\n     * @param {PushAudioOutputStreamCallback} callback - The custom audio output object,\n     * derived from PushAudioOutputStreamCallback\n     */\n    constructor(callback) {\n        super();\n        this.privId = (0,_common_Exports__WEBPACK_IMPORTED_MODULE_0__.createNoDashGuid)();\n        this.privCallback = callback;\n    }\n    // eslint-disable-next-line @typescript-eslint/no-empty-function\n    set format(format) { }\n    write(buffer) {\n        if (!!this.privCallback.write) {\n            this.privCallback.write(buffer);\n        }\n    }\n    close() {\n        if (!!this.privCallback.close) {\n            this.privCallback.close();\n        }\n    }\n    id() {\n        return this.privId;\n    }\n}\n\n//# sourceMappingURL=AudioOutputStream.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputStream.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioStreamFormat.js":
  /*!***************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioStreamFormat.js ***!
    \***************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AudioFormatTag\": () => (/* binding */ AudioFormatTag),\n/* harmony export */   \"AudioStreamFormat\": () => (/* binding */ AudioStreamFormat),\n/* harmony export */   \"AudioStreamFormatImpl\": () => (/* binding */ AudioStreamFormatImpl)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n// eslint-disable-next-line max-classes-per-file\nvar AudioFormatTag;\n(function (AudioFormatTag) {\n    AudioFormatTag[AudioFormatTag[\"PCM\"] = 1] = \"PCM\";\n    AudioFormatTag[AudioFormatTag[\"MuLaw\"] = 2] = \"MuLaw\";\n    AudioFormatTag[AudioFormatTag[\"Siren\"] = 3] = \"Siren\";\n    AudioFormatTag[AudioFormatTag[\"MP3\"] = 4] = \"MP3\";\n    AudioFormatTag[AudioFormatTag[\"SILKSkype\"] = 5] = \"SILKSkype\";\n    AudioFormatTag[AudioFormatTag[\"OGG_OPUS\"] = 6] = \"OGG_OPUS\";\n    AudioFormatTag[AudioFormatTag[\"WEBM_OPUS\"] = 7] = \"WEBM_OPUS\";\n    AudioFormatTag[AudioFormatTag[\"ALaw\"] = 8] = \"ALaw\";\n    AudioFormatTag[AudioFormatTag[\"FLAC\"] = 9] = \"FLAC\";\n    AudioFormatTag[AudioFormatTag[\"OPUS\"] = 10] = \"OPUS\";\n})(AudioFormatTag || (AudioFormatTag = {}));\n/**\n * Represents audio stream format used for custom audio input configurations.\n * @class AudioStreamFormat\n */\nclass AudioStreamFormat {\n    /**\n     * Creates an audio stream format object representing the default audio stream\n     * format (16KHz 16bit mono PCM).\n     * @member AudioStreamFormat.getDefaultInputFormat\n     * @function\n     * @public\n     * @returns {AudioStreamFormat} The audio stream format being created.\n     */\n    static getDefaultInputFormat() {\n        return AudioStreamFormatImpl.getDefaultInputFormat();\n    }\n    /**\n     * Creates an audio stream format object with the specified format characteristics.\n     * @member AudioStreamFormat.getWaveFormat\n     * @function\n     * @public\n     * @param {number} samplesPerSecond - Sample rate, in samples per second (Hertz).\n     * @param {number} bitsPerSample - Bits per sample, typically 16.\n     * @param {number} channels - Number of channels in the waveform-audio data. Monaural data\n     * uses one channel and stereo data uses two channels.\n     * @param {AudioFormatTag} format - Audio format (PCM, alaw or mulaw).\n     * @returns {AudioStreamFormat} The audio stream format being created.\n     */\n    static getWaveFormat(samplesPerSecond, bitsPerSample, channels, format) {\n        return new AudioStreamFormatImpl(samplesPerSecond, bitsPerSample, channels, format);\n    }\n    /**\n     * Creates an audio stream format object with the specified pcm waveformat characteristics.\n     * @member AudioStreamFormat.getWaveFormatPCM\n     * @function\n     * @public\n     * @param {number} samplesPerSecond - Sample rate, in samples per second (Hertz).\n     * @param {number} bitsPerSample - Bits per sample, typically 16.\n     * @param {number} channels - Number of channels in the waveform-audio data. Monaural data\n     * uses one channel and stereo data uses two channels.\n     * @returns {AudioStreamFormat} The audio stream format being created.\n     */\n    static getWaveFormatPCM(samplesPerSecond, bitsPerSample, channels) {\n        return new AudioStreamFormatImpl(samplesPerSecond, bitsPerSample, channels);\n    }\n}\n/**\n * @private\n * @class AudioStreamFormatImpl\n */\nclass AudioStreamFormatImpl extends AudioStreamFormat {\n    /**\n     * Creates an instance with the given values.\n     * @constructor\n     * @param {number} samplesPerSec - Samples per second.\n     * @param {number} bitsPerSample - Bits per sample.\n     * @param {number} channels - Number of channels.\n     * @param {AudioFormatTag} format - Audio format (PCM, alaw or mulaw).\n     */\n    constructor(samplesPerSec = 16000, bitsPerSample = 16, channels = 1, format = AudioFormatTag.PCM) {\n        super();\n        let isWavFormat = true;\n        /* 1 for PCM; 6 for alaw; 7 for mulaw */\n        switch (format) {\n            case AudioFormatTag.PCM:\n                this.formatTag = 1;\n                break;\n            case AudioFormatTag.ALaw:\n                this.formatTag = 6;\n                break;\n            case AudioFormatTag.MuLaw:\n                this.formatTag = 7;\n                break;\n            default:\n                isWavFormat = false;\n        }\n        this.bitsPerSample = bitsPerSample;\n        this.samplesPerSec = samplesPerSec;\n        this.channels = channels;\n        this.avgBytesPerSec = this.samplesPerSec * this.channels * (this.bitsPerSample / 8);\n        this.blockAlign = this.channels * Math.max(this.bitsPerSample, 8);\n        if (isWavFormat) {\n            this.privHeader = new ArrayBuffer(44);\n            // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/DataView\n            const view = new DataView(this.privHeader);\n            /* RIFF identifier */\n            this.setString(view, 0, \"RIFF\");\n            /* file length */\n            view.setUint32(4, 0, true);\n            /* RIFF type & Format */\n            this.setString(view, 8, \"WAVEfmt \");\n            /* format chunk length */\n            view.setUint32(16, 16, true);\n            /* audio format */\n            view.setUint16(20, this.formatTag, true);\n            /* channel count */\n            view.setUint16(22, this.channels, true);\n            /* sample rate */\n            view.setUint32(24, this.samplesPerSec, true);\n            /* byte rate (sample rate * block align) */\n            view.setUint32(28, this.avgBytesPerSec, true);\n            /* block align (channel count * bytes per sample) */\n            view.setUint16(32, this.channels * (this.bitsPerSample / 8), true);\n            /* bits per sample */\n            view.setUint16(34, this.bitsPerSample, true);\n            /* data chunk identifier */\n            this.setString(view, 36, \"data\");\n            /* data chunk length */\n            view.setUint32(40, 0, true);\n        }\n    }\n    /**\n     * Retrieves the default input format.\n     * @member AudioStreamFormatImpl.getDefaultInputFormat\n     * @function\n     * @public\n     * @returns {AudioStreamFormatImpl} The default input format.\n     */\n    static getDefaultInputFormat() {\n        return new AudioStreamFormatImpl();\n    }\n    /**\n     * Creates an audio context appropriate to current browser\n     * @member AudioStreamFormatImpl.getAudioContext\n     * @function\n     * @public\n     * @returns {AudioContext} An audio context instance\n     */\n    /* eslint-disable */\n    static getAudioContext(sampleRate) {\n        // Workaround for Speech SDK bug in Safari.\n        const AudioContext = window.AudioContext // our preferred impl\n            || window.webkitAudioContext // fallback, mostly when on Safari\n            || false; // could not find.\n        // https://developer.mozilla.org/en-US/docs/Web/API/AudioContext\n        if (!!AudioContext) {\n            if (sampleRate !== undefined && navigator.mediaDevices.getSupportedConstraints().sampleRate) {\n                return new AudioContext({ sampleRate });\n            }\n            else {\n                return new AudioContext();\n            }\n        }\n        else {\n            throw new Error(\"Browser does not support Web Audio API (AudioContext is not available).\");\n        }\n    }\n    /* eslint-enable */\n    /**\n     * Closes the configuration object.\n     * @member AudioStreamFormatImpl.prototype.close\n     * @function\n     * @public\n     */\n    close() {\n        return;\n    }\n    get header() {\n        return this.privHeader;\n    }\n    setString(view, offset, str) {\n        for (let i = 0; i < str.length; i++) {\n            view.setUint8(offset + i, str.charCodeAt(i));\n        }\n    }\n}\n\n//# sourceMappingURL=AudioStreamFormat.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioStreamFormat.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/PullAudioInputStreamCallback.js":
  /*!**************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/PullAudioInputStreamCallback.js ***!
    \**************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"PullAudioInputStreamCallback\": () => (/* binding */ PullAudioInputStreamCallback)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * An abstract base class that defines callback methods (read() and close()) for\n * custom audio input streams).\n * @class PullAudioInputStreamCallback\n */\nclass PullAudioInputStreamCallback {\n}\n\n//# sourceMappingURL=PullAudioInputStreamCallback.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/PullAudioInputStreamCallback.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/PushAudioOutputStreamCallback.js":
  /*!***************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/PushAudioOutputStreamCallback.js ***!
    \***************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"PushAudioOutputStreamCallback\": () => (/* binding */ PushAudioOutputStreamCallback)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * An abstract base class that defines callback methods (write() and close()) for\n * custom audio output streams).\n * @class PushAudioOutputStreamCallback\n */\nclass PushAudioOutputStreamCallback {\n}\n\n//# sourceMappingURL=PushAudioOutputStreamCallback.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/PushAudioOutputStreamCallback.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/SpeakerAudioDestination.js":
  /*!*********************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/SpeakerAudioDestination.js ***!
    \*********************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SpeakerAudioDestination\": () => (/* binding */ SpeakerAudioDestination)\n/* harmony export */ });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisAdapterBase.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Events.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/BackgroundError.js\");\n/* harmony import */ var _AudioOutputStream__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./AudioOutputStream */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputStream.js\");\n/* harmony import */ var _AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./AudioStreamFormat */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioStreamFormat.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\n\nconst MediaDurationPlaceholderSeconds = 60 * 30;\nconst AudioFormatToMimeType = {\n    [_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.PCM]: \"audio/wav\",\n    [_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.MuLaw]: \"audio/x-wav\",\n    [_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.MP3]: \"audio/mpeg\",\n    [_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.OGG_OPUS]: \"audio/ogg\",\n    [_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.WEBM_OPUS]: \"audio/webm; codecs=opus\",\n    [_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.ALaw]: \"audio/x-wav\",\n    [_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.FLAC]: \"audio/flac\",\n};\n/**\n * Represents the speaker playback audio destination, which only works in browser.\n * Note: the SDK will try to use <a href=\"https://www.w3.org/TR/media-source/\">Media Source Extensions</a> to play audio.\n * Mp3 format has better supports on Microsoft Edge, Chrome and Safari (desktop), so, it's better to specify mp3 format for playback.\n * @class SpeakerAudioDestination\n * Updated in version 1.17.0\n */\nclass SpeakerAudioDestination {\n    constructor(audioDestinationId) {\n        this.privPlaybackStarted = false;\n        this.privAppendingToBuffer = false;\n        this.privMediaSourceOpened = false;\n        this.privBytesReceived = 0;\n        this.privId = audioDestinationId ? audioDestinationId : (0,_common_Exports__WEBPACK_IMPORTED_MODULE_1__.createNoDashGuid)();\n        this.privIsPaused = false;\n        this.privIsClosed = false;\n    }\n    id() {\n        return this.privId;\n    }\n    write(buffer, cb, err) {\n        if (this.privAudioBuffer !== undefined) {\n            this.privAudioBuffer.push(buffer);\n            this.updateSourceBuffer().then(() => {\n                if (!!cb) {\n                    cb();\n                }\n            }, (error) => {\n                if (!!err) {\n                    err(error);\n                }\n            });\n        }\n        else if (this.privAudioOutputStream !== undefined) {\n            this.privAudioOutputStream.write(buffer);\n            this.privBytesReceived += buffer.byteLength;\n        }\n    }\n    close(cb, err) {\n        this.privIsClosed = true;\n        if (this.privSourceBuffer !== undefined) {\n            this.handleSourceBufferUpdateEnd().then(() => {\n                if (!!cb) {\n                    cb();\n                }\n            }, (error) => {\n                if (!!err) {\n                    err(error);\n                }\n            });\n        }\n        else if (this.privAudioOutputStream !== undefined && typeof window !== \"undefined\") {\n            if ((this.privFormat.formatTag === _AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.PCM || this.privFormat.formatTag === _AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.MuLaw\n                || this.privFormat.formatTag === _AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.ALaw) && this.privFormat.hasHeader === false) {\n                // eslint-disable-next-line no-console\n                console.warn(\"Play back is not supported for raw PCM, mulaw or alaw format without header.\");\n                if (!!this.onAudioEnd) {\n                    this.onAudioEnd(this);\n                }\n            }\n            else {\n                let receivedAudio = new ArrayBuffer(this.privBytesReceived);\n                this.privAudioOutputStream.read(receivedAudio).then(() => {\n                    receivedAudio = _common_speech_Exports__WEBPACK_IMPORTED_MODULE_2__.SynthesisAdapterBase.addHeader(receivedAudio, this.privFormat);\n                    const audioBlob = new Blob([receivedAudio], { type: AudioFormatToMimeType[this.privFormat.formatTag] });\n                    this.privAudio.src = window.URL.createObjectURL(audioBlob);\n                    this.notifyPlayback().then(() => {\n                        if (!!cb) {\n                            cb();\n                        }\n                    }, (error) => {\n                        if (!!err) {\n                            err(error);\n                        }\n                    });\n                }, (error) => {\n                    if (!!err) {\n                        err(error);\n                    }\n                });\n            }\n        }\n        else {\n            // unsupported format, call onAudioEnd directly.\n            if (!!this.onAudioEnd) {\n                this.onAudioEnd(this);\n            }\n        }\n    }\n    set format(format) {\n        // eslint-disable-next-line @typescript-eslint/no-unsafe-member-access\n        if (typeof (AudioContext) !== \"undefined\" || (typeof (window) !== \"undefined\" && typeof (window.webkitAudioContext) !== \"undefined\")) {\n            this.privFormat = format;\n            const mimeType = AudioFormatToMimeType[this.privFormat.formatTag];\n            if (mimeType === undefined) {\n                // eslint-disable-next-line no-console\n                console.warn(`Unknown mimeType for format ${_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag[this.privFormat.formatTag]}; playback is not supported.`);\n            }\n            else if (typeof (MediaSource) !== \"undefined\" && MediaSource.isTypeSupported(mimeType)) {\n                this.privAudio = new Audio();\n                this.privAudioBuffer = [];\n                this.privMediaSource = new MediaSource();\n                this.privAudio.src = URL.createObjectURL(this.privMediaSource);\n                this.privAudio.load();\n                this.privMediaSource.onsourceopen = () => {\n                    this.privMediaSourceOpened = true;\n                    this.privMediaSource.duration = MediaDurationPlaceholderSeconds;\n                    this.privSourceBuffer = this.privMediaSource.addSourceBuffer(mimeType);\n                    this.privSourceBuffer.onupdate = () => {\n                        this.updateSourceBuffer().catch((reason) => {\n                            _common_Exports__WEBPACK_IMPORTED_MODULE_3__.Events.instance.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_4__.BackgroundEvent(reason));\n                        });\n                    };\n                    this.privSourceBuffer.onupdateend = () => {\n                        this.handleSourceBufferUpdateEnd().catch((reason) => {\n                            _common_Exports__WEBPACK_IMPORTED_MODULE_3__.Events.instance.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_4__.BackgroundEvent(reason));\n                        });\n                    };\n                    this.privSourceBuffer.onupdatestart = () => {\n                        this.privAppendingToBuffer = false;\n                    };\n                };\n                this.updateSourceBuffer().catch((reason) => {\n                    _common_Exports__WEBPACK_IMPORTED_MODULE_3__.Events.instance.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_4__.BackgroundEvent(reason));\n                });\n            }\n            else {\n                // eslint-disable-next-line no-console\n                console.warn(`Format ${_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag[this.privFormat.formatTag]} could not be played by MSE, streaming playback is not enabled.`);\n                this.privAudioOutputStream = new _AudioOutputStream__WEBPACK_IMPORTED_MODULE_5__.PullAudioOutputStreamImpl();\n                this.privAudioOutputStream.format = this.privFormat;\n                this.privAudio = new Audio();\n            }\n        }\n    }\n    get volume() {\n        var _a, _b;\n        return (_b = (_a = this.privAudio) === null || _a === void 0 ? void 0 : _a.volume) !== null && _b !== void 0 ? _b : -1;\n    }\n    set volume(volume) {\n        if (!!this.privAudio) {\n            this.privAudio.volume = volume;\n        }\n    }\n    mute() {\n        if (!!this.privAudio) {\n            this.privAudio.muted = true;\n        }\n    }\n    unmute() {\n        if (!!this.privAudio) {\n            this.privAudio.muted = false;\n        }\n    }\n    get isClosed() {\n        return this.privIsClosed;\n    }\n    get currentTime() {\n        if (this.privAudio !== undefined) {\n            return this.privAudio.currentTime;\n        }\n        return -1;\n    }\n    pause() {\n        if (!this.privIsPaused && this.privAudio !== undefined) {\n            this.privAudio.pause();\n            this.privIsPaused = true;\n        }\n    }\n    resume(cb, err) {\n        if (this.privIsPaused && this.privAudio !== undefined) {\n            this.privAudio.play().then(() => {\n                if (!!cb) {\n                    cb();\n                }\n            }, (error) => {\n                if (!!err) {\n                    err(error);\n                }\n            });\n            this.privIsPaused = false;\n        }\n    }\n    get internalAudio() {\n        return this.privAudio;\n    }\n    updateSourceBuffer() {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (this.privAudioBuffer !== undefined && (this.privAudioBuffer.length > 0) && this.sourceBufferAvailable()) {\n                this.privAppendingToBuffer = true;\n                const binary = this.privAudioBuffer.shift();\n                try {\n                    this.privSourceBuffer.appendBuffer(binary);\n                }\n                catch (error) {\n                    this.privAudioBuffer.unshift(binary);\n                    // eslint-disable-next-line no-console\n                    console.log(\"buffer filled, pausing addition of binaries until space is made\");\n                    return;\n                }\n                yield this.notifyPlayback();\n            }\n            else if (this.canEndStream()) {\n                yield this.handleSourceBufferUpdateEnd();\n            }\n        });\n    }\n    handleSourceBufferUpdateEnd() {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (this.canEndStream() && this.sourceBufferAvailable()) {\n                this.privMediaSource.endOfStream();\n                yield this.notifyPlayback();\n            }\n        });\n    }\n    notifyPlayback() {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (!this.privPlaybackStarted && this.privAudio !== undefined) {\n                this.privPlaybackStarted = true;\n                if (!!this.onAudioStart) {\n                    this.onAudioStart(this);\n                }\n                this.privAudio.onended = () => {\n                    if (!!this.onAudioEnd) {\n                        this.onAudioEnd(this);\n                    }\n                };\n                if (!this.privIsPaused) {\n                    yield this.privAudio.play();\n                }\n            }\n        });\n    }\n    canEndStream() {\n        return (this.isClosed && this.privSourceBuffer !== undefined && (this.privAudioBuffer.length === 0)\n            && this.privMediaSourceOpened && !this.privAppendingToBuffer && this.privMediaSource.readyState === \"open\");\n    }\n    sourceBufferAvailable() {\n        return (this.privSourceBuffer !== undefined && !this.privSourceBuffer.updating);\n    }\n}\n\n//# sourceMappingURL=SpeakerAudioDestination.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/SpeakerAudioDestination.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationDetails.js":
  /*!***********************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationDetails.js ***!
    \***********************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"CancellationDetails\": () => (/* binding */ CancellationDetails)\n/* harmony export */ });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SimpleSpeechPhrase.js\");\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/EnumTranslation.js\");\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _CancellationDetailsBase__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./CancellationDetailsBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationDetailsBase.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationReason.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionResult.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\n/**\n * Contains detailed information about why a result was canceled.\n * @class CancellationDetails\n */\nclass CancellationDetails extends _CancellationDetailsBase__WEBPACK_IMPORTED_MODULE_0__.CancellationDetailsBase {\n    constructor(reason, errorDetails, errorCode) {\n        super(reason, errorDetails, errorCode);\n    }\n    /**\n     * Creates an instance of CancellationDetails object for the canceled RecognitionResult.\n     * @member CancellationDetails.fromResult\n     * @function\n     * @public\n     * @param {RecognitionResult | SpeechSynthesisResult} result - The result that was canceled.\n     * @returns {CancellationDetails} The cancellation details object being created.\n     */\n    static fromResult(result) {\n        let reason = _Exports__WEBPACK_IMPORTED_MODULE_1__.CancellationReason.Error;\n        let errorCode = _Exports__WEBPACK_IMPORTED_MODULE_2__.CancellationErrorCode.NoError;\n        if (result instanceof _Exports__WEBPACK_IMPORTED_MODULE_3__.RecognitionResult && !!result.json) {\n            const simpleSpeech = _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.SimpleSpeechPhrase.fromJSON(result.json);\n            reason = _common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.EnumTranslation.implTranslateCancelResult(simpleSpeech.RecognitionStatus);\n        }\n        if (!!result.properties) {\n            errorCode = _Exports__WEBPACK_IMPORTED_MODULE_2__.CancellationErrorCode[result.properties.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_6__.CancellationErrorCodePropertyName, _Exports__WEBPACK_IMPORTED_MODULE_2__.CancellationErrorCode[_Exports__WEBPACK_IMPORTED_MODULE_2__.CancellationErrorCode.NoError])];\n        }\n        return new CancellationDetails(reason, result.errorDetails || _common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.EnumTranslation.implTranslateErrorDetails(errorCode), errorCode);\n    }\n}\n\n//# sourceMappingURL=CancellationDetails.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationDetails.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationDetailsBase.js":
  /*!***************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationDetailsBase.js ***!
    \***************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"CancellationDetailsBase\": () => (/* binding */ CancellationDetailsBase)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Contains detailed information about why a result was canceled.\n * @class CancellationDetailsBase\n */\nclass CancellationDetailsBase {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {CancellationReason} reason - The cancellation reason.\n     * @param {string} errorDetails - The error details, if provided.\n     */\n    constructor(reason, errorDetails, errorCode) {\n        this.privReason = reason;\n        this.privErrorDetails = errorDetails;\n        this.privErrorCode = errorCode;\n    }\n    /**\n     * The reason the recognition was canceled.\n     * @member CancellationDetailsBase.prototype.reason\n     * @function\n     * @public\n     * @returns {CancellationReason} Specifies the reason canceled.\n     */\n    get reason() {\n        return this.privReason;\n    }\n    /**\n     * In case of an unsuccessful recognition, provides details of the occurred error.\n     * @member CancellationDetailsBase.prototype.errorDetails\n     * @function\n     * @public\n     * @returns {string} A String that represents the error details.\n     */\n    get errorDetails() {\n        return this.privErrorDetails;\n    }\n    /**\n     * The error code in case of an unsuccessful recognition.\n     * Added in version 1.1.0.\n     * @return An error code that represents the error reason.\n     */\n    get ErrorCode() {\n        return this.privErrorCode;\n    }\n}\n\n//# sourceMappingURL=CancellationDetailsBase.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationDetailsBase.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js":
  /*!**************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js ***!
    \**************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"CancellationErrorCode\": () => (/* binding */ CancellationErrorCode)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines error code in case that CancellationReason is Error.\n * Added in version 1.1.0.\n */\nvar CancellationErrorCode;\n(function (CancellationErrorCode) {\n    /**\n     * Indicates that no error occurred during speech recognition.\n     */\n    CancellationErrorCode[CancellationErrorCode[\"NoError\"] = 0] = \"NoError\";\n    /**\n     * Indicates an authentication error.\n     */\n    CancellationErrorCode[CancellationErrorCode[\"AuthenticationFailure\"] = 1] = \"AuthenticationFailure\";\n    /**\n     * Indicates that one or more recognition parameters are invalid.\n     */\n    CancellationErrorCode[CancellationErrorCode[\"BadRequestParameters\"] = 2] = \"BadRequestParameters\";\n    /**\n     * Indicates that the number of parallel requests exceeded the number of allowed\n     * concurrent transcriptions for the subscription.\n     */\n    CancellationErrorCode[CancellationErrorCode[\"TooManyRequests\"] = 3] = \"TooManyRequests\";\n    /**\n     * Indicates a connection error.\n     */\n    CancellationErrorCode[CancellationErrorCode[\"ConnectionFailure\"] = 4] = \"ConnectionFailure\";\n    /**\n     * Indicates a time-out error when waiting for response from service.\n     */\n    CancellationErrorCode[CancellationErrorCode[\"ServiceTimeout\"] = 5] = \"ServiceTimeout\";\n    /**\n     * Indicates that an error is returned by the service.\n     */\n    CancellationErrorCode[CancellationErrorCode[\"ServiceError\"] = 6] = \"ServiceError\";\n    /**\n     * Indicates an unexpected runtime error.\n     */\n    CancellationErrorCode[CancellationErrorCode[\"RuntimeError\"] = 7] = \"RuntimeError\";\n    /**\n     * Indicates an quota overrun on existing key.\n     */\n    CancellationErrorCode[CancellationErrorCode[\"Forbidden\"] = 8] = \"Forbidden\";\n})(CancellationErrorCode || (CancellationErrorCode = {}));\n\n//# sourceMappingURL=CancellationErrorCodes.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationEventArgsBase.js":
  /*!*****************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationEventArgsBase.js ***!
    \*****************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"CancellationEventArgsBase\": () => (/* binding */ CancellationEventArgsBase)\n/* harmony export */ });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionEventArgs.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Defines content of a CancellationEvent.\n * @class CancellationEventArgsBase\n */\nclass CancellationEventArgsBase extends _Exports__WEBPACK_IMPORTED_MODULE_0__.RecognitionEventArgs {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {CancellationReason} reason - The cancellation reason.\n     * @param {string} errorDetails - Error details, if provided.\n     * @param {number} offset - The offset.\n     * @param {string} sessionId - The session id.\n     */\n    constructor(reason, errorDetails, errorCode, offset, sessionId) {\n        super(offset, sessionId);\n        this.privReason = reason;\n        this.privErrorDetails = errorDetails;\n        this.privErrorCode = errorCode;\n    }\n    /**\n     * The reason the recognition was canceled.\n     * @member CancellationEventArgsBase.prototype.reason\n     * @function\n     * @public\n     * @returns {CancellationReason} Specifies the reason canceled.\n     */\n    get reason() {\n        return this.privReason;\n    }\n    /**\n     * The error code in case of an unsuccessful operation.\n     * @return An error code that represents the error reason.\n     */\n    get errorCode() {\n        return this.privErrorCode;\n    }\n    /**\n     * In case of an unsuccessful operation, provides details of the occurred error.\n     * @member CancellationEventArgsBase.prototype.errorDetails\n     * @function\n     * @public\n     * @returns {string} A String that represents the error details.\n     */\n    get errorDetails() {\n        return this.privErrorDetails;\n    }\n}\n\n//# sourceMappingURL=CancellationEventArgsBase.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationEventArgsBase.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationReason.js":
  /*!**********************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationReason.js ***!
    \**********************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"CancellationReason\": () => (/* binding */ CancellationReason)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines the possible reasons a recognition result might be canceled.\n * @class CancellationReason\n */\nvar CancellationReason;\n(function (CancellationReason) {\n    /**\n     * Indicates that an error occurred during speech recognition.\n     * @member CancellationReason.Error\n     */\n    CancellationReason[CancellationReason[\"Error\"] = 0] = \"Error\";\n    /**\n     * Indicates that the end of the audio stream was reached.\n     * @member CancellationReason.EndOfStream\n     */\n    CancellationReason[CancellationReason[\"EndOfStream\"] = 1] = \"EndOfStream\";\n})(CancellationReason || (CancellationReason = {}));\n\n//# sourceMappingURL=CancellationReason.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationReason.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Connection.js":
  /*!**************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Connection.js ***!
    \**************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Connection\": () => (/* binding */ Connection)\n/* harmony export */ });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisAdapterBase.js\");\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceRecognizerBase.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js\");\n/* harmony import */ var _ConnectionMessage__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./ConnectionMessage */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionMessage.js\");\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionEventArgs.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionMessageEventArgs.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ServiceEventArgs.js\");\n//\n// Copyright (c) Microsoft. All rights reserved.\n// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.\n//\n\n\n\n\n\n/**\n * Connection is a proxy class for managing connection to the speech service of the specified Recognizer.\n * By default, a Recognizer autonomously manages connection to service when needed.\n * The Connection class provides additional methods for users to explicitly open or close a connection and\n * to subscribe to connection status changes.\n * The use of Connection is optional, and mainly for scenarios where fine tuning of application\n * behavior based on connection status is needed. Users can optionally call Open() to manually set up a connection\n * in advance before starting recognition on the Recognizer associated with this Connection.\n * If the Recognizer needs to connect or disconnect to service, it will\n * setup or shutdown the connection independently. In this case the Connection will be notified by change of connection\n * status via Connected/Disconnected events.\n * Added in version 1.2.1.\n */\nclass Connection {\n    /**\n     * Gets the Connection instance from the specified recognizer.\n     * @param recognizer The recognizer associated with the connection.\n     * @return The Connection instance of the recognizer.\n     */\n    static fromRecognizer(recognizer) {\n        const recoBase = recognizer.internalData;\n        const ret = new Connection();\n        ret.privInternalData = recoBase;\n        ret.setupEvents();\n        return ret;\n    }\n    /**\n     * Gets the Connection instance from the specified synthesizer.\n     * @param synthesizer The synthesizer associated with the connection.\n     * @return The Connection instance of the synthesizer.\n     */\n    static fromSynthesizer(synthesizer) {\n        const synthBase = synthesizer.internalData;\n        const ret = new Connection();\n        ret.privInternalData = synthBase;\n        ret.setupEvents();\n        return ret;\n    }\n    /**\n     * Starts to set up connection to the service.\n     * Users can optionally call openConnection() to manually set up a connection in advance before starting recognition on the\n     * Recognizer associated with this Connection. After starting recognition, calling Open() will have no effect\n     *\n     * Note: On return, the connection might not be ready yet. Please subscribe to the Connected event to\n     * be notified when the connection is established.\n     */\n    openConnection(cb, err) {\n        (0,_common_Exports__WEBPACK_IMPORTED_MODULE_0__.marshalPromiseToCallbacks)(this.privInternalData.connect(), cb, err);\n    }\n    /**\n     * Closes the connection the service.\n     * Users can optionally call closeConnection() to manually shutdown the connection of the associated Recognizer.\n     *\n     * If closeConnection() is called during recognition, recognition will fail and cancel with an error.\n     */\n    closeConnection(cb, err) {\n        if (this.privInternalData instanceof _common_speech_Exports__WEBPACK_IMPORTED_MODULE_1__.SynthesisAdapterBase) {\n            throw new Error(\"Disconnecting a synthesizer's connection is currently not supported\");\n        }\n        else {\n            (0,_common_Exports__WEBPACK_IMPORTED_MODULE_0__.marshalPromiseToCallbacks)(this.privInternalData.disconnect(), cb, err);\n        }\n    }\n    /**\n     * Appends a parameter in a message to service.\n     * Added in version 1.12.1.\n     * @param path The path of the network message.\n     * @param propertyName Name of the property\n     * @param propertyValue Value of the property. This is a json string.\n     */\n    setMessageProperty(path, propertyName, propertyValue) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__.Contracts.throwIfNullOrWhitespace(propertyName, \"propertyName\");\n        if (this.privInternalData instanceof _common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__.ServiceRecognizerBase) {\n            if (path.toLowerCase() !== \"speech.context\") {\n                throw new Error(\"Only speech.context message property sets are currently supported for recognizer\");\n            }\n            else {\n                this.privInternalData.speechContext.setSection(propertyName, propertyValue);\n            }\n        }\n        else if (this.privInternalData instanceof _common_speech_Exports__WEBPACK_IMPORTED_MODULE_1__.SynthesisAdapterBase) {\n            if (path.toLowerCase() !== \"synthesis.context\") {\n                throw new Error(\"Only synthesis.context message property sets are currently supported for synthesizer\");\n            }\n            else {\n                this.privInternalData.synthesisContext.setSection(propertyName, propertyValue);\n            }\n        }\n    }\n    /**\n     * Sends a message to the speech service.\n     * Added in version 1.13.0.\n     * @param path The WebSocket path of the message\n     * @param payload The payload of the message. This is a json string or a ArrayBuffer.\n     * @param success A callback to indicate success.\n     * @param error A callback to indicate an error.\n     */\n    sendMessageAsync(path, payload, success, error) {\n        (0,_common_Exports__WEBPACK_IMPORTED_MODULE_0__.marshalPromiseToCallbacks)(this.privInternalData.sendNetworkMessage(path, payload), success, error);\n    }\n    /**\n     * Dispose of associated resources.\n     */\n    close() {\n        /* eslint-disable no-empty */\n    }\n    setupEvents() {\n        this.privEventListener = this.privInternalData.connectionEvents.attach((connectionEvent) => {\n            if (connectionEvent.name === \"ConnectionEstablishedEvent\") {\n                if (!!this.connected) {\n                    this.connected(new _Exports__WEBPACK_IMPORTED_MODULE_4__.ConnectionEventArgs(connectionEvent.connectionId));\n                }\n            }\n            else if (connectionEvent.name === \"ConnectionClosedEvent\") {\n                if (!!this.disconnected) {\n                    this.disconnected(new _Exports__WEBPACK_IMPORTED_MODULE_4__.ConnectionEventArgs(connectionEvent.connectionId));\n                }\n            }\n            else if (connectionEvent.name === \"ConnectionMessageSentEvent\") {\n                if (!!this.messageSent) {\n                    this.messageSent(new _Exports__WEBPACK_IMPORTED_MODULE_5__.ConnectionMessageEventArgs(new _ConnectionMessage__WEBPACK_IMPORTED_MODULE_6__.ConnectionMessageImpl(connectionEvent.message)));\n                }\n            }\n            else if (connectionEvent.name === \"ConnectionMessageReceivedEvent\") {\n                if (!!this.messageReceived) {\n                    this.messageReceived(new _Exports__WEBPACK_IMPORTED_MODULE_5__.ConnectionMessageEventArgs(new _ConnectionMessage__WEBPACK_IMPORTED_MODULE_6__.ConnectionMessageImpl(connectionEvent.message)));\n                }\n            }\n        });\n        this.privServiceEventListener = this.privInternalData.serviceEvents.attach((e) => {\n            if (!!this.receivedServiceMessage) {\n                this.receivedServiceMessage(new _Exports__WEBPACK_IMPORTED_MODULE_7__.ServiceEventArgs(e.jsonString, e.name));\n            }\n        });\n    }\n}\n\n//# sourceMappingURL=Connection.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Connection.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionEventArgs.js":
  /*!***********************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionEventArgs.js ***!
    \***********************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConnectionEventArgs\": () => (/* binding */ ConnectionEventArgs)\n/* harmony export */ });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SessionEventArgs.js\");\n//\n// Copyright (c) Microsoft. All rights reserved.\n// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.\n//\n\n/**\n * Defines payload for connection events like Connected/Disconnected.\n * Added in version 1.2.0\n */\nclass ConnectionEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__.SessionEventArgs {\n}\n\n//# sourceMappingURL=ConnectionEventArgs.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionEventArgs.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionMessage.js":
  /*!*********************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionMessage.js ***!
    \*********************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConnectionMessage\": () => (/* binding */ ConnectionMessage),\n/* harmony export */   \"ConnectionMessageImpl\": () => (/* binding */ ConnectionMessageImpl)\n/* harmony export */ });\n/* harmony import */ var _common_speech_HeaderNames__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common.speech/HeaderNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js\");\n/* harmony import */ var _PropertyCollection__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./PropertyCollection */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js\");\n/* harmony import */ var _PropertyId__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./PropertyId */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n//\n// Copyright (c) Microsoft. All rights reserved.\n// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.\n//\n// eslint-disable-next-line max-classes-per-file\n\n\n\n\n/**\n * ConnectionMessage represents implementation specific messages sent to and received from\n * the speech service. These messages are provided for debugging purposes and should not\n * be used for production use cases with the Azure Cognitive Services Speech Service.\n * Messages sent to and received from the Speech Service are subject to change without\n * notice. This includes message contents, headers, payloads, ordering, etc.\n * Added in version 1.11.0.\n */\nclass ConnectionMessage {\n}\nclass ConnectionMessageImpl {\n    constructor(message) {\n        this.privConnectionMessage = message;\n        this.privProperties = new _PropertyCollection__WEBPACK_IMPORTED_MODULE_0__.PropertyCollection();\n        if (!!this.privConnectionMessage.headers[_common_speech_HeaderNames__WEBPACK_IMPORTED_MODULE_1__.HeaderNames.ConnectionId]) {\n            this.privProperties.setProperty(_PropertyId__WEBPACK_IMPORTED_MODULE_2__.PropertyId.Speech_SessionId, this.privConnectionMessage.headers[_common_speech_HeaderNames__WEBPACK_IMPORTED_MODULE_1__.HeaderNames.ConnectionId]);\n        }\n        Object.keys(this.privConnectionMessage.headers).forEach((header) => {\n            this.privProperties.setProperty(header, this.privConnectionMessage.headers[header]);\n        });\n    }\n    /**\n     * The message path.\n     */\n    get path() {\n        return this.privConnectionMessage.headers[Object.keys(this.privConnectionMessage.headers).find((key) => key.toLowerCase() === \"path\".toLowerCase())];\n    }\n    /**\n     * Checks to see if the ConnectionMessage is a text message.\n     * See also IsBinaryMessage().\n     */\n    get isTextMessage() {\n        return this.privConnectionMessage.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_3__.MessageType.Text;\n    }\n    /**\n     * Checks to see if the ConnectionMessage is a binary message.\n     * See also GetBinaryMessage().\n     */\n    get isBinaryMessage() {\n        return this.privConnectionMessage.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_3__.MessageType.Binary;\n    }\n    /**\n     * Gets the text message payload. Typically the text message content-type is\n     * application/json. To determine other content-types use\n     * Properties.GetProperty(\"Content-Type\").\n     */\n    get TextMessage() {\n        return this.privConnectionMessage.textBody;\n    }\n    /**\n     * Gets the binary message payload.\n     */\n    get binaryMessage() {\n        return this.privConnectionMessage.binaryBody;\n    }\n    /**\n     * A collection of properties and their values defined for this <see cref=\"ConnectionMessage\"/>.\n     * Message headers can be accessed via this collection (e.g. \"Content-Type\").\n     */\n    get properties() {\n        return this.privProperties;\n    }\n    /**\n     * Returns a string that represents the connection message.\n     */\n    toString() {\n        return \"\";\n    }\n}\n\n//# sourceMappingURL=ConnectionMessage.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionMessage.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionMessageEventArgs.js":
  /*!******************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionMessageEventArgs.js ***!
    \******************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConnectionMessageEventArgs\": () => (/* binding */ ConnectionMessageEventArgs)\n/* harmony export */ });\n//\n// Copyright (c) Microsoft. All rights reserved.\n// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.\n//\nclass ConnectionMessageEventArgs {\n    constructor(message) {\n        this.privConnectionMessage = message;\n    }\n    /**\n     * Gets the <see cref=\"ConnectionMessage\"/> associated with this <see cref=\"ConnectionMessageEventArgs\"/>.\n     */\n    get message() {\n        return this.privConnectionMessage;\n    }\n    /**\n     * Returns a string that represents the connection message event.\n     */\n    toString() {\n        return \"Message: \" + this.privConnectionMessage.toString();\n    }\n}\n\n//# sourceMappingURL=ConnectionMessageEventArgs.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionMessageEventArgs.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js":
  /*!*************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js ***!
    \*************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Contracts\": () => (/* binding */ Contracts)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * @class Contracts\n * @private\n */\nclass Contracts {\n    static throwIfNullOrUndefined(param, name) {\n        if (param === undefined || param === null) {\n            throw new Error(\"throwIfNullOrUndefined:\" + name);\n        }\n    }\n    static throwIfNull(param, name) {\n        if (param === null) {\n            throw new Error(\"throwIfNull:\" + name);\n        }\n    }\n    static throwIfNullOrWhitespace(param, name) {\n        Contracts.throwIfNullOrUndefined(param, name);\n        if ((\"\" + param).trim().length < 1) {\n            throw new Error(\"throwIfNullOrWhitespace:\" + name);\n        }\n    }\n    static throwIfDisposed(isDisposed) {\n        if (isDisposed) {\n            throw new Error(\"the object is already disposed\");\n        }\n    }\n    static throwIfArrayEmptyOrWhitespace(array, name) {\n        Contracts.throwIfNullOrUndefined(array, name);\n        if (array.length === 0) {\n            throw new Error(\"throwIfArrayEmptyOrWhitespace:\" + name);\n        }\n        for (const item of array) {\n            Contracts.throwIfNullOrWhitespace(item, name);\n        }\n    }\n    static throwIfFileDoesNotExist(param, name) {\n        Contracts.throwIfNullOrWhitespace(param, name);\n        // TODO check for file existence.\n    }\n    static throwIfNotUndefined(param, name) {\n        if (param !== undefined) {\n            throw new Error(\"throwIfNotUndefined:\" + name);\n        }\n    }\n}\n\n//# sourceMappingURL=Contracts.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConversationTranscriptionCanceledEventArgs.js":
  /*!**********************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConversationTranscriptionCanceledEventArgs.js ***!
    \**********************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConversationTranscriptionCanceledEventArgs\": () => (/* binding */ ConversationTranscriptionCanceledEventArgs)\n/* harmony export */ });\n/* harmony import */ var _CancellationEventArgsBase__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./CancellationEventArgsBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationEventArgsBase.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Defines content of a RecognitionErrorEvent.\n * @class ConversationTranscriptionCanceledEventArgs\n */\nclass ConversationTranscriptionCanceledEventArgs extends _CancellationEventArgsBase__WEBPACK_IMPORTED_MODULE_0__.CancellationEventArgsBase {\n}\n\n//# sourceMappingURL=ConversationTranscriptionCanceledEventArgs.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConversationTranscriptionCanceledEventArgs.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/DialogServiceConfig.js":
  /*!***********************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/DialogServiceConfig.js ***!
    \***********************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"DialogServiceConfig\": () => (/* binding */ DialogServiceConfig),\n/* harmony export */   \"DialogServiceConfigImpl\": () => (/* binding */ DialogServiceConfigImpl)\n/* harmony export */ });\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechConfig.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/* eslint-disable max-classes-per-file */\n\n\n/**\n * Class that defines base configurations for dialog service connector\n * @class DialogServiceConfig\n */\nclass DialogServiceConfig {\n    /**\n     * Creates an instance of DialogService config.\n     * @constructor\n     */\n    constructor() {\n        return;\n    }\n    /**\n     * Sets the corresponding backend application identifier.\n     * @member DialogServiceConfig.prototype.Conversation_ApplicationId\n     * @function\n     * @public\n     * @param {string} value - The application identifier to set.\n     */\n    // eslint-disable-next-line @typescript-eslint/no-empty-function\n    set applicationId(value) { }\n    static get DialogTypes() {\n        return {\n            BotFramework: \"bot_framework\",\n            CustomCommands: \"custom_commands\"\n        };\n    }\n}\n/**\n * Dialog Service configuration.\n * @class DialogServiceConfigImpl\n */\nclass DialogServiceConfigImpl extends DialogServiceConfig {\n    /**\n     * Creates an instance of dialogService config.\n     */\n    constructor() {\n        super();\n        this.privSpeechConfig = new _Exports__WEBPACK_IMPORTED_MODULE_0__.SpeechConfigImpl();\n    }\n    /**\n     * Provides access to custom properties.\n     * @member DialogServiceConfigImpl.prototype.properties\n     * @function\n     * @public\n     * @returns {PropertyCollection} The properties.\n     */\n    get properties() {\n        return this.privSpeechConfig.properties;\n    }\n    /**\n     * Gets the speech recognition language.\n     * @member DialogServiceConfigImpl.prototype.speechRecognitionLanguage\n     * @function\n     * @public\n     */\n    get speechRecognitionLanguage() {\n        return this.privSpeechConfig.speechRecognitionLanguage;\n    }\n    /**\n     * Sets the speech recognition language.\n     * @member DialogServiceConfigImpl.prototype.speechRecognitionLanguage\n     * @function\n     * @public\n     * @param {string} value - The language to set.\n     */\n    set speechRecognitionLanguage(value) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(value, \"value\");\n        this.privSpeechConfig.speechRecognitionLanguage = value;\n    }\n    get outputFormat() {\n        return this.privSpeechConfig.outputFormat;\n    }\n    set outputFormat(value) {\n        this.privSpeechConfig.outputFormat = value;\n    }\n    /**\n     * Sets a named property as value\n     * @member DialogServiceConfigImpl.prototype.setProperty\n     * @function\n     * @public\n     * @param {PropertyId | string} name - The property to set.\n     * @param {string} value - The value.\n     */\n    setProperty(name, value) {\n        this.privSpeechConfig.setProperty(name, value);\n    }\n    /**\n     * Sets a named property as value\n     * @member DialogServiceConfigImpl.prototype.getProperty\n     * @function\n     * @public\n     * @param {PropertyId | string} name - The property to get.\n     * @param {string} def - The default value to return in case the property is not known.\n     * @returns {string} The current value, or provided default, of the given property.\n     */\n    getProperty(name, def) {\n        void def;\n        return this.privSpeechConfig.getProperty(name);\n    }\n    /**\n     * Sets the proxy configuration.\n     * Only relevant in Node.js environments.\n     * Added in version 1.4.0.\n     * @param proxyHostName The host name of the proxy server, without the protocol scheme (http://)\n     * @param proxyPort The port number of the proxy server.\n     * @param proxyUserName The user name of the proxy server.\n     * @param proxyPassword The password of the proxy server.\n     */\n    setProxy(proxyHostName, proxyPort, proxyUserName, proxyPassword) {\n        this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_ProxyHostName, proxyHostName);\n        this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_ProxyPort, `${proxyPort}`);\n        if (proxyUserName) {\n            this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_ProxyUserName, proxyUserName);\n        }\n        if (proxyPassword) {\n            this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_ProxyPassword, proxyPassword);\n        }\n    }\n    setServiceProperty(name, value, channel) {\n        void channel;\n        this.privSpeechConfig.setServiceProperty(name, value);\n    }\n    /**\n     * Dispose of associated resources.\n     * @member DialogServiceConfigImpl.prototype.close\n     * @function\n     * @public\n     */\n    close() {\n        return;\n    }\n}\n\n//# sourceMappingURL=DialogServiceConfig.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/DialogServiceConfig.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionCanceledEventArgs.js":
  /*!**************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionCanceledEventArgs.js ***!
    \**************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"IntentRecognitionCanceledEventArgs\": () => (/* binding */ IntentRecognitionCanceledEventArgs)\n/* harmony export */ });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionEventArgs.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Define payload of intent recognition canceled result events.\n * @class IntentRecognitionCanceledEventArgs\n */\nclass IntentRecognitionCanceledEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__.IntentRecognitionEventArgs {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {CancellationReason} result - The result of the intent recognition.\n     * @param {string} offset - The offset.\n     * @param {IntentRecognitionResult} sessionId - The session id.\n     */\n    constructor(reason, errorDetails, errorCode, result, offset, sessionId) {\n        super(result, offset, sessionId);\n        this.privReason = reason;\n        this.privErrorDetails = errorDetails;\n        this.privErrorCode = errorCode;\n    }\n    /**\n     * The reason the recognition was canceled.\n     * @member IntentRecognitionCanceledEventArgs.prototype.reason\n     * @function\n     * @public\n     * @returns {CancellationReason} Specifies the reason canceled.\n     */\n    get reason() {\n        return this.privReason;\n    }\n    /**\n     * The error code in case of an unsuccessful recognition.\n     * Added in version 1.1.0.\n     * @return An error code that represents the error reason.\n     */\n    get errorCode() {\n        return this.privErrorCode;\n    }\n    /**\n     * In case of an unsuccessful recognition, provides details of the occurred error.\n     * @member IntentRecognitionCanceledEventArgs.prototype.errorDetails\n     * @function\n     * @public\n     * @returns {string} A String that represents the error details.\n     */\n    get errorDetails() {\n        return this.privErrorDetails;\n    }\n}\n\n//# sourceMappingURL=IntentRecognitionCanceledEventArgs.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionCanceledEventArgs.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionEventArgs.js":
  /*!******************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionEventArgs.js ***!
    \******************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"IntentRecognitionEventArgs\": () => (/* binding */ IntentRecognitionEventArgs)\n/* harmony export */ });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionEventArgs.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Intent recognition result event arguments.\n * @class\n */\nclass IntentRecognitionEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__.RecognitionEventArgs {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param result - The result of the intent recognition.\n     * @param offset - The offset.\n     * @param sessionId - The session id.\n     */\n    constructor(result, offset, sessionId) {\n        super(offset, sessionId);\n        this.privResult = result;\n    }\n    /**\n     * Represents the intent recognition result.\n     * @member IntentRecognitionEventArgs.prototype.result\n     * @function\n     * @public\n     * @returns {IntentRecognitionResult} Represents the intent recognition result.\n     */\n    get result() {\n        return this.privResult;\n    }\n}\n\n//# sourceMappingURL=IntentRecognitionEventArgs.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionEventArgs.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionResult.js":
  /*!***************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionResult.js ***!
    \***************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"IntentRecognitionResult\": () => (/* binding */ IntentRecognitionResult)\n/* harmony export */ });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionResult.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Intent recognition result.\n * @class\n */\nclass IntentRecognitionResult extends _Exports__WEBPACK_IMPORTED_MODULE_0__.SpeechRecognitionResult {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param intentId - The intent id.\n     * @param resultId - The result id.\n     * @param reason - The reason.\n     * @param text - The recognized text.\n     * @param duration - The duration.\n     * @param offset - The offset into the stream.\n     * @param language - Primary Language detected, if provided.\n     * @param languageDetectionConfidence - Primary Language confidence (\"Unknown,\" \"Low,\" \"Medium,\" \"High\"...), if provided.\n     * @param errorDetails - Error details, if provided.\n     * @param json - Additional Json, if provided.\n     * @param properties - Additional properties, if provided.\n     */\n    constructor(intentId, resultId, reason, text, duration, offset, language, languageDetectionConfidence, errorDetails, json, properties) {\n        super(resultId, reason, text, duration, offset, language, languageDetectionConfidence, undefined, errorDetails, json, properties);\n        this.privIntentId = intentId;\n    }\n    /**\n     * A String that represents the intent identifier being recognized.\n     * @member IntentRecognitionResult.prototype.intentId\n     * @function\n     * @public\n     * @returns {string} A String that represents the intent identifier being recognized.\n     */\n    get intentId() {\n        return this.privIntentId;\n    }\n}\n\n//# sourceMappingURL=IntentRecognitionResult.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionResult.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/NoMatchDetails.js":
  /*!******************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/NoMatchDetails.js ***!
    \******************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"NoMatchDetails\": () => (/* binding */ NoMatchDetails)\n/* harmony export */ });\n/* harmony import */ var _src_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../src/common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SimpleSpeechPhrase.js\");\n/* harmony import */ var _src_common_speech_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../src/common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/Enums.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/NoMatchReason.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n/**\n * Contains detailed information for NoMatch recognition results.\n * @class NoMatchDetails\n */\nclass NoMatchDetails {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {NoMatchReason} reason - The no-match reason.\n     */\n    constructor(reason) {\n        this.privReason = reason;\n    }\n    /**\n     * Creates an instance of NoMatchDetails object for the NoMatch SpeechRecognitionResults.\n     * @member NoMatchDetails.fromResult\n     * @function\n     * @public\n     * @param {SpeechRecognitionResult | IntentRecognitionResult | TranslationRecognitionResult}\n     * result - The recognition result that was not recognized.\n     * @returns {NoMatchDetails} The no match details object being created.\n     */\n    static fromResult(result) {\n        const simpleSpeech = _src_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__.SimpleSpeechPhrase.fromJSON(result.json);\n        let reason = _Exports__WEBPACK_IMPORTED_MODULE_1__.NoMatchReason.NotRecognized;\n        switch (simpleSpeech.RecognitionStatus) {\n            case _src_common_speech_Exports__WEBPACK_IMPORTED_MODULE_2__.RecognitionStatus.BabbleTimeout:\n                reason = _Exports__WEBPACK_IMPORTED_MODULE_1__.NoMatchReason.InitialBabbleTimeout;\n                break;\n            case _src_common_speech_Exports__WEBPACK_IMPORTED_MODULE_2__.RecognitionStatus.InitialSilenceTimeout:\n                reason = _Exports__WEBPACK_IMPORTED_MODULE_1__.NoMatchReason.InitialSilenceTimeout;\n                break;\n            default:\n                reason = _Exports__WEBPACK_IMPORTED_MODULE_1__.NoMatchReason.NotRecognized;\n                break;\n        }\n        return new NoMatchDetails(reason);\n    }\n    /**\n     * The reason the recognition was canceled.\n     * @member NoMatchDetails.prototype.reason\n     * @function\n     * @public\n     * @returns {NoMatchReason} Specifies the reason canceled.\n     */\n    get reason() {\n        return this.privReason;\n    }\n}\n\n//# sourceMappingURL=NoMatchDetails.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/NoMatchDetails.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/NoMatchReason.js":
  /*!*****************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/NoMatchReason.js ***!
    \*****************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"NoMatchReason\": () => (/* binding */ NoMatchReason)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines the possible reasons a recognition result might not be recognized.\n * @class NoMatchReason\n */\nvar NoMatchReason;\n(function (NoMatchReason) {\n    /**\n     * Indicates that speech was detected, but not recognized.\n     * @member NoMatchReason.NotRecognized\n     */\n    NoMatchReason[NoMatchReason[\"NotRecognized\"] = 0] = \"NotRecognized\";\n    /**\n     * Indicates that the start of the audio stream contained only silence,\n     * and the service timed out waiting for speech.\n     * @member NoMatchReason.InitialSilenceTimeout\n     */\n    NoMatchReason[NoMatchReason[\"InitialSilenceTimeout\"] = 1] = \"InitialSilenceTimeout\";\n    /**\n     * Indicates that the start of the audio stream contained only noise,\n     * and the service timed out waiting for speech.\n     * @member NoMatchReason.InitialBabbleTimeout\n     */\n    NoMatchReason[NoMatchReason[\"InitialBabbleTimeout\"] = 2] = \"InitialBabbleTimeout\";\n})(NoMatchReason || (NoMatchReason = {}));\n\n//# sourceMappingURL=NoMatchReason.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/NoMatchReason.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/OutputFormat.js":
  /*!****************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/OutputFormat.js ***!
    \****************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"OutputFormat\": () => (/* binding */ OutputFormat)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Define Speech Recognizer output formats.\n * @class OutputFormat\n */\nvar OutputFormat;\n(function (OutputFormat) {\n    /**\n     * @member OutputFormat.Simple\n     */\n    OutputFormat[OutputFormat[\"Simple\"] = 0] = \"Simple\";\n    /**\n     * @member OutputFormat.Detailed\n     */\n    OutputFormat[OutputFormat[\"Detailed\"] = 1] = \"Detailed\";\n})(OutputFormat || (OutputFormat = {}));\n\n//# sourceMappingURL=OutputFormat.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/OutputFormat.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ProfanityOption.js":
  /*!*******************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ProfanityOption.js ***!
    \*******************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ProfanityOption\": () => (/* binding */ ProfanityOption)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation.\n// Licensed under the MIT license.\n/**\n * Profanity option.\n * Added in version 1.7.0.\n */\nvar ProfanityOption;\n(function (ProfanityOption) {\n    ProfanityOption[ProfanityOption[\"Masked\"] = 0] = \"Masked\";\n    ProfanityOption[ProfanityOption[\"Removed\"] = 1] = \"Removed\";\n    ProfanityOption[ProfanityOption[\"Raw\"] = 2] = \"Raw\";\n})(ProfanityOption || (ProfanityOption = {}));\n\n//# sourceMappingURL=ProfanityOption.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ProfanityOption.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentResult.js":
  /*!*********************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentResult.js ***!
    \*********************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"PronunciationAssessmentResult\": () => (/* binding */ PronunciationAssessmentResult)\n/* harmony export */ });\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n/**\n * Pronunciation assessment results.\n * @class PronunciationAssessmentResult\n * Added in version 1.15.0.\n */\nclass PronunciationAssessmentResult {\n    constructor(jsonString) {\n        const j = JSON.parse(jsonString);\n        _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(j.NBest[0], \"NBest\");\n        this.privPronJson = j.NBest[0];\n    }\n    /**\n     * @member PronunciationAssessmentResult.fromResult\n     * @function\n     * @public\n     * @param {RecognitionResult} result The recognition result.\n     * @return {PronunciationAssessmentConfig} Instance of PronunciationAssessmentConfig\n     * @summary Creates an instance of the PronunciationAssessmentResult from recognition result.\n     */\n    static fromResult(result) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(result, \"result\");\n        const json = result.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceResponse_JsonResult);\n        _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(json, \"json\");\n        return new PronunciationAssessmentResult(json);\n    }\n    /**\n     * Gets the detail result of pronunciation assessment.\n     * @member PronunciationAssessmentConfig.prototype.detailResult\n     * @function\n     * @public\n     * @returns {DetailResult} detail result.\n     */\n    get detailResult() {\n        return this.privPronJson;\n    }\n    /**\n     * The score indicating the pronunciation accuracy of the given speech, which indicates\n     * how closely the phonemes match a native speaker's pronunciation.\n     * @member PronunciationAssessmentResult.prototype.accuracyScore\n     * @function\n     * @public\n     * @returns {number} Accuracy score.\n     */\n    get accuracyScore() {\n        return this.detailResult.PronunciationAssessment.AccuracyScore;\n    }\n    /**\n     * The overall score indicating the pronunciation quality of the given speech.\n     * This is calculated from AccuracyScore, FluencyScore and CompletenessScore with weight.\n     * @member PronunciationAssessmentResult.prototype.pronunciationScore\n     * @function\n     * @public\n     * @returns {number} Pronunciation score.\n     */\n    get pronunciationScore() {\n        return this.detailResult.PronunciationAssessment.PronScore;\n    }\n    /**\n     * The score indicating the completeness of the given speech by calculating the ratio of pronounced words towards entire input.\n     * @member PronunciationAssessmentResult.prototype.completenessScore\n     * @function\n     * @public\n     * @returns {number} Completeness score.\n     */\n    get completenessScore() {\n        return this.detailResult.PronunciationAssessment.CompletenessScore;\n    }\n    /**\n     * The score indicating the fluency of the given speech.\n     * @member PronunciationAssessmentResult.prototype.fluencyScore\n     * @function\n     * @public\n     * @returns {number} Fluency score.\n     */\n    get fluencyScore() {\n        return this.detailResult.PronunciationAssessment.FluencyScore;\n    }\n}\n\n//# sourceMappingURL=PronunciationAssessmentResult.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentResult.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js":
  /*!**********************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js ***!
    \**********************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"PropertyCollection\": () => (/* binding */ PropertyCollection)\n/* harmony export */ });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Represents collection of properties and their values.\n * @class PropertyCollection\n */\nclass PropertyCollection {\n    constructor() {\n        this.privKeys = [];\n        this.privValues = [];\n    }\n    /**\n     * Returns the property value in type String.\n     * Currently only String, int and bool are allowed.\n     * If the name is not available, the specified defaultValue is returned.\n     * @member PropertyCollection.prototype.getProperty\n     * @function\n     * @public\n     * @param {string} key - The parameter name.\n     * @param {string | number | boolean} def - The default value which is returned if the parameter\n     * is not available in the collection.\n     * @returns {string} value of the parameter.\n     */\n    getProperty(key, def) {\n        let keyToUse;\n        if (typeof key === \"string\") {\n            keyToUse = key;\n        }\n        else {\n            keyToUse = _Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId[key];\n        }\n        for (let n = 0; n < this.privKeys.length; n++) {\n            if (this.privKeys[n] === keyToUse) {\n                return this.privValues[n];\n            }\n        }\n        if (def === undefined) {\n            return undefined;\n        }\n        return String(def);\n    }\n    /**\n     * Sets the String value of the parameter specified by name.\n     * @member PropertyCollection.prototype.setProperty\n     * @function\n     * @public\n     * @param {string} key - The parameter name.\n     * @param {string} value - The value of the parameter.\n     */\n    setProperty(key, value) {\n        let keyToUse;\n        if (typeof key === \"string\") {\n            keyToUse = key;\n        }\n        else {\n            keyToUse = _Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId[key];\n        }\n        for (let n = 0; n < this.privKeys.length; n++) {\n            if (this.privKeys[n] === keyToUse) {\n                this.privValues[n] = value;\n                return;\n            }\n        }\n        this.privKeys.push(keyToUse);\n        this.privValues.push(value);\n    }\n    /**\n     * Clones the collection.\n     * @member PropertyCollection.prototype.clone\n     * @function\n     * @public\n     * @returns {PropertyCollection} A copy of the collection.\n     */\n    clone() {\n        const clonedMap = new PropertyCollection();\n        for (let n = 0; n < this.privKeys.length; n++) {\n            clonedMap.privKeys.push(this.privKeys[n]);\n            clonedMap.privValues.push(this.privValues[n]);\n        }\n        return clonedMap;\n    }\n    /**\n     * Merges this set of properties into another, no overwrites.\n     * @member PropertyCollection.prototype.mergeTo\n     * @function\n     * @public\n     * @param {PropertyCollection}  destinationCollection - The collection to merge into.\n     */\n    mergeTo(destinationCollection) {\n        this.privKeys.forEach((key) => {\n            if (destinationCollection.getProperty(key, undefined) === undefined) {\n                const value = this.getProperty(key);\n                destinationCollection.setProperty(key, value);\n            }\n        });\n    }\n    /**\n     * Get the keys in Property Collection.\n     * @member PropertyCollection.prototype.keys\n     * @function\n     * @public\n     * @returns {string []} Keys in the collection.\n     */\n    get keys() {\n        return this.privKeys;\n    }\n}\n\n//# sourceMappingURL=PropertyCollection.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js":
  /*!**************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js ***!
    \**************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"PropertyId\": () => (/* binding */ PropertyId)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines speech property ids.\n * @class PropertyId\n */\nvar PropertyId;\n(function (PropertyId) {\n    /**\n     * The Cognitive Services Speech Service subscription Key. If you are using an intent recognizer, you need to\n     * specify the LUIS endpoint key for your particular LUIS app. Under normal circumstances, you shouldn't\n     * have to use this property directly.\n     * Instead, use [[SpeechConfig.fromSubscription]].\n     * @member PropertyId.SpeechServiceConnection_Key\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_Key\"] = 0] = \"SpeechServiceConnection_Key\";\n    /**\n     * The Cognitive Services Speech Service endpoint (url). Under normal circumstances, you shouldn't\n     * have to use this property directly.\n     * Instead, use [[SpeechConfig.fromEndpoint]].\n     * NOTE: This endpoint is not the same as the endpoint used to obtain an access token.\n     * @member PropertyId.SpeechServiceConnection_Endpoint\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_Endpoint\"] = 1] = \"SpeechServiceConnection_Endpoint\";\n    /**\n     * The Cognitive Services Speech Service region. Under normal circumstances, you shouldn't have to\n     * use this property directly.\n     * Instead, use [[SpeechConfig.fromSubscription]], [[SpeechConfig.fromEndpoint]], [[SpeechConfig.fromAuthorizationToken]].\n     * @member PropertyId.SpeechServiceConnection_Region\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_Region\"] = 2] = \"SpeechServiceConnection_Region\";\n    /**\n     * The Cognitive Services Speech Service authorization token (aka access token). Under normal circumstances,\n     * you shouldn't have to use this property directly.\n     * Instead, use [[SpeechConfig.fromAuthorizationToken]], [[SpeechRecognizer.authorizationToken]],\n     * [[IntentRecognizer.authorizationToken]], [[TranslationRecognizer.authorizationToken]], [[SpeakerRecognizer.authorizationToken]].\n     * @member PropertyId.SpeechServiceAuthorization_Token\n     */\n    PropertyId[PropertyId[\"SpeechServiceAuthorization_Token\"] = 3] = \"SpeechServiceAuthorization_Token\";\n    /**\n     * The Cognitive Services Speech Service authorization type. Currently unused.\n     * @member PropertyId.SpeechServiceAuthorization_Type\n     */\n    PropertyId[PropertyId[\"SpeechServiceAuthorization_Type\"] = 4] = \"SpeechServiceAuthorization_Type\";\n    /**\n     * The Cognitive Services Speech Service endpoint id. Under normal circumstances, you shouldn't\n     * have to use this property directly.\n     * Instead, use [[SpeechConfig.endpointId]].\n     * NOTE: The endpoint id is available in the Speech Portal, listed under Endpoint Details.\n     * @member PropertyId.SpeechServiceConnection_EndpointId\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_EndpointId\"] = 5] = \"SpeechServiceConnection_EndpointId\";\n    /**\n     * The list of comma separated languages (BCP-47 format) used as target translation languages. Under normal circumstances,\n     * you shouldn't have to use this property directly.\n     * Instead use [[SpeechTranslationConfig.addTargetLanguage]],\n     * [[SpeechTranslationConfig.targetLanguages]], [[TranslationRecognizer.targetLanguages]].\n     * @member PropertyId.SpeechServiceConnection_TranslationToLanguages\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_TranslationToLanguages\"] = 6] = \"SpeechServiceConnection_TranslationToLanguages\";\n    /**\n     * The name of the Cognitive Service Text to Speech Service Voice. Under normal circumstances, you shouldn't have to use this\n     * property directly.\n     * Instead, use [[SpeechTranslationConfig.voiceName]].\n     * NOTE: Valid voice names can be found <a href=\"https://aka.ms/csspeech/voicenames\">here</a>.\n     * @member PropertyId.SpeechServiceConnection_TranslationVoice\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_TranslationVoice\"] = 7] = \"SpeechServiceConnection_TranslationVoice\";\n    /**\n     * Translation features.\n     * @member PropertyId.SpeechServiceConnection_TranslationFeatures\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_TranslationFeatures\"] = 8] = \"SpeechServiceConnection_TranslationFeatures\";\n    /**\n     * The Language Understanding Service Region. Under normal circumstances, you shouldn't have to use this property directly.\n     * Instead, use [[LanguageUnderstandingModel]].\n     * @member PropertyId.SpeechServiceConnection_IntentRegion\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_IntentRegion\"] = 9] = \"SpeechServiceConnection_IntentRegion\";\n    /**\n     * The host name of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.\n     * You shouldn't have to use this property directly.\n     * Instead use <see cref=\"SpeechConfig.SetProxy(string,int,string,string)\"/>.\n     * Added in version 1.4.0.\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_ProxyHostName\"] = 10] = \"SpeechServiceConnection_ProxyHostName\";\n    /**\n     * The port of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.\n     * You shouldn't have to use this property directly.\n     * Instead use <see cref=\"SpeechConfig.SetProxy(string,int,string,string)\"/>.\n     * Added in version 1.4.0.\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_ProxyPort\"] = 11] = \"SpeechServiceConnection_ProxyPort\";\n    /**\n     * The user name of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.\n     * You shouldn't have to use this property directly.\n     * Instead use <see cref=\"SpeechConfig.SetProxy(string,int,string,string)\"/>.\n     * Added in version 1.4.0.\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_ProxyUserName\"] = 12] = \"SpeechServiceConnection_ProxyUserName\";\n    /**\n     * The password of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.\n     * You shouldn't have to use this property directly.\n     * Instead use <see cref=\"SpeechConfig.SetProxy(string,int,string,string)\"/>.\n     * Added in version 1.4.0.\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_ProxyPassword\"] = 13] = \"SpeechServiceConnection_ProxyPassword\";\n    /**\n     * The Cognitive Services Speech Service recognition Mode. Can be \"INTERACTIVE\", \"CONVERSATION\", \"DICTATION\".\n     * This property is intended to be read-only. The SDK is using it internally.\n     * @member PropertyId.SpeechServiceConnection_RecoMode\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_RecoMode\"] = 14] = \"SpeechServiceConnection_RecoMode\";\n    /**\n     * The spoken language to be recognized (in BCP-47 format). Under normal circumstances, you shouldn't have to use this property\n     * directly.\n     * Instead, use [[SpeechConfig.speechRecognitionLanguage]].\n     * @member PropertyId.SpeechServiceConnection_RecoLanguage\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_RecoLanguage\"] = 15] = \"SpeechServiceConnection_RecoLanguage\";\n    /**\n     * The session id. This id is a universally unique identifier (aka UUID) representing a specific binding of an audio input stream\n     * and the underlying speech recognition instance to which it is bound. Under normal circumstances, you shouldn't have to use this\n     * property directly.\n     * Instead use [[SessionEventArgs.sessionId]].\n     * @member PropertyId.Speech_SessionId\n     */\n    PropertyId[PropertyId[\"Speech_SessionId\"] = 16] = \"Speech_SessionId\";\n    /**\n     * The spoken language to be synthesized (e.g. en-US)\n     * @member PropertyId.SpeechServiceConnection_SynthLanguage\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_SynthLanguage\"] = 17] = \"SpeechServiceConnection_SynthLanguage\";\n    /**\n     * The name of the TTS voice to be used for speech synthesis\n     * @member PropertyId.SpeechServiceConnection_SynthVoice\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_SynthVoice\"] = 18] = \"SpeechServiceConnection_SynthVoice\";\n    /**\n     * The string to specify TTS output audio format\n     * @member PropertyId.SpeechServiceConnection_SynthOutputFormat\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_SynthOutputFormat\"] = 19] = \"SpeechServiceConnection_SynthOutputFormat\";\n    /**\n     * The list of comma separated languages used as possible source languages\n     * Added in version 1.13.0\n     * @member PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_AutoDetectSourceLanguages\"] = 20] = \"SpeechServiceConnection_AutoDetectSourceLanguages\";\n    /**\n     * The requested Cognitive Services Speech Service response output format (simple or detailed). Under normal circumstances, you shouldn't have\n     * to use this property directly.\n     * Instead use [[SpeechConfig.outputFormat]].\n     * @member PropertyId.SpeechServiceResponse_RequestDetailedResultTrueFalse\n     */\n    PropertyId[PropertyId[\"SpeechServiceResponse_RequestDetailedResultTrueFalse\"] = 21] = \"SpeechServiceResponse_RequestDetailedResultTrueFalse\";\n    /**\n     * The requested Cognitive Services Speech Service response output profanity level. Currently unused.\n     * @member PropertyId.SpeechServiceResponse_RequestProfanityFilterTrueFalse\n     */\n    PropertyId[PropertyId[\"SpeechServiceResponse_RequestProfanityFilterTrueFalse\"] = 22] = \"SpeechServiceResponse_RequestProfanityFilterTrueFalse\";\n    /**\n     * The Cognitive Services Speech Service response output (in JSON format). This property is available on recognition result objects only.\n     * @member PropertyId.SpeechServiceResponse_JsonResult\n     */\n    PropertyId[PropertyId[\"SpeechServiceResponse_JsonResult\"] = 23] = \"SpeechServiceResponse_JsonResult\";\n    /**\n     * The Cognitive Services Speech Service error details (in JSON format). Under normal circumstances, you shouldn't have to\n     * use this property directly. Instead use [[CancellationDetails.errorDetails]].\n     * @member PropertyId.SpeechServiceResponse_JsonErrorDetails\n     */\n    PropertyId[PropertyId[\"SpeechServiceResponse_JsonErrorDetails\"] = 24] = \"SpeechServiceResponse_JsonErrorDetails\";\n    /**\n     * The cancellation reason. Currently unused.\n     * @member PropertyId.CancellationDetails_Reason\n     */\n    PropertyId[PropertyId[\"CancellationDetails_Reason\"] = 25] = \"CancellationDetails_Reason\";\n    /**\n     * The cancellation text. Currently unused.\n     * @member PropertyId.CancellationDetails_ReasonText\n     */\n    PropertyId[PropertyId[\"CancellationDetails_ReasonText\"] = 26] = \"CancellationDetails_ReasonText\";\n    /**\n     * The Cancellation detailed text. Currently unused.\n     * @member PropertyId.CancellationDetails_ReasonDetailedText\n     */\n    PropertyId[PropertyId[\"CancellationDetails_ReasonDetailedText\"] = 27] = \"CancellationDetails_ReasonDetailedText\";\n    /**\n     * The Language Understanding Service response output (in JSON format). Available via [[IntentRecognitionResult]]\n     * @member PropertyId.LanguageUnderstandingServiceResponse_JsonResult\n     */\n    PropertyId[PropertyId[\"LanguageUnderstandingServiceResponse_JsonResult\"] = 28] = \"LanguageUnderstandingServiceResponse_JsonResult\";\n    /**\n     * The URL string built from speech configuration.\n     * This property is intended to be read-only. The SDK is using it internally.\n     * NOTE: Added in version 1.7.0.\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_Url\"] = 29] = \"SpeechServiceConnection_Url\";\n    /**\n     * The initial silence timeout value (in milliseconds) used by the service.\n     * Added in version 1.7.0\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_InitialSilenceTimeoutMs\"] = 30] = \"SpeechServiceConnection_InitialSilenceTimeoutMs\";\n    /**\n     * The end silence timeout value (in milliseconds) used by the service.\n     * Added in version 1.7.0\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_EndSilenceTimeoutMs\"] = 31] = \"SpeechServiceConnection_EndSilenceTimeoutMs\";\n    /**\n     * A duration of detected silence, measured in milliseconds, after which speech-to-text will determine a spoken\n     * phrase has ended and generate a final Recognized result. Configuring this timeout may be helpful in situations\n     * where spoken input is significantly faster or slower than usual and default segmentation behavior consistently\n     * yields results that are too long or too short. Segmentation timeout values that are inappropriately high or low\n     * can negatively affect speech-to-text accuracy; this property should be carefully configured and the resulting\n     * behavior should be thoroughly validated as intended.\n     *\n     * For more information about timeout configuration that includes discussion of default behaviors, please visit\n     * https://aka.ms/csspeech/timeouts.\n     *\n     * Added in version 1.21.0.\n     */\n    PropertyId[PropertyId[\"Speech_SegmentationSilenceTimeoutMs\"] = 32] = \"Speech_SegmentationSilenceTimeoutMs\";\n    /**\n     * A boolean value specifying whether audio logging is enabled in the service or not.\n     * Added in version 1.7.0\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_EnableAudioLogging\"] = 33] = \"SpeechServiceConnection_EnableAudioLogging\";\n    /**\n     * The speech service connection language identifier mode.\n     * Can be \"AtStart\" (the default), or \"Continuous\". See Language\n     * Identification document https://aka.ms/speech/lid?pivots=programming-language-javascript\n     * for more details.\n     * Added in 1.25.0\n     **/\n    PropertyId[PropertyId[\"SpeechServiceConnection_LanguageIdMode\"] = 34] = \"SpeechServiceConnection_LanguageIdMode\";\n    /**\n     * A string value representing the desired endpoint version to target for Speech Recognition.\n     * Added in version 1.21.0\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_RecognitionEndpointVersion\"] = 35] = \"SpeechServiceConnection_RecognitionEndpointVersion\";\n    /**\n     * The requested Cognitive Services Speech Service response output profanity setting.\n     * Allowed values are \"masked\", \"removed\", and \"raw\".\n     * Added in version 1.7.0.\n     */\n    PropertyId[PropertyId[\"SpeechServiceResponse_ProfanityOption\"] = 36] = \"SpeechServiceResponse_ProfanityOption\";\n    /**\n     * A string value specifying which post processing option should be used by service.\n     * Allowed values are \"TrueText\".\n     * Added in version 1.7.0\n     */\n    PropertyId[PropertyId[\"SpeechServiceResponse_PostProcessingOption\"] = 37] = \"SpeechServiceResponse_PostProcessingOption\";\n    /**\n     * A boolean value specifying whether to include word-level timestamps in the response result.\n     * Added in version 1.7.0\n     */\n    PropertyId[PropertyId[\"SpeechServiceResponse_RequestWordLevelTimestamps\"] = 38] = \"SpeechServiceResponse_RequestWordLevelTimestamps\";\n    /**\n     * The number of times a word has to be in partial results to be returned.\n     * Added in version 1.7.0\n     */\n    PropertyId[PropertyId[\"SpeechServiceResponse_StablePartialResultThreshold\"] = 39] = \"SpeechServiceResponse_StablePartialResultThreshold\";\n    /**\n     * A string value specifying the output format option in the response result. Internal use only.\n     * Added in version 1.7.0.\n     */\n    PropertyId[PropertyId[\"SpeechServiceResponse_OutputFormatOption\"] = 40] = \"SpeechServiceResponse_OutputFormatOption\";\n    /**\n     * A boolean value to request for stabilizing translation partial results by omitting words in the end.\n     * Added in version 1.7.0.\n     */\n    PropertyId[PropertyId[\"SpeechServiceResponse_TranslationRequestStablePartialResult\"] = 41] = \"SpeechServiceResponse_TranslationRequestStablePartialResult\";\n    /**\n     * A boolean value specifying whether to request WordBoundary events.\n     * @member PropertyId.SpeechServiceResponse_RequestWordBoundary\n     * Added in version 1.21.0.\n     */\n    PropertyId[PropertyId[\"SpeechServiceResponse_RequestWordBoundary\"] = 42] = \"SpeechServiceResponse_RequestWordBoundary\";\n    /**\n     * A boolean value specifying whether to request punctuation boundary in WordBoundary Events. Default is true.\n     * @member PropertyId.SpeechServiceResponse_RequestPunctuationBoundary\n     * Added in version 1.21.0.\n     */\n    PropertyId[PropertyId[\"SpeechServiceResponse_RequestPunctuationBoundary\"] = 43] = \"SpeechServiceResponse_RequestPunctuationBoundary\";\n    /**\n     * A boolean value specifying whether to request sentence boundary in WordBoundary Events. Default is false.\n     * @member PropertyId.SpeechServiceResponse_RequestSentenceBoundary\n     * Added in version 1.21.0.\n     */\n    PropertyId[PropertyId[\"SpeechServiceResponse_RequestSentenceBoundary\"] = 44] = \"SpeechServiceResponse_RequestSentenceBoundary\";\n    /**\n     * Identifier used to connect to the backend service.\n     * @member PropertyId.Conversation_ApplicationId\n     */\n    PropertyId[PropertyId[\"Conversation_ApplicationId\"] = 45] = \"Conversation_ApplicationId\";\n    /**\n     * Type of dialog backend to connect to.\n     * @member PropertyId.Conversation_DialogType\n     */\n    PropertyId[PropertyId[\"Conversation_DialogType\"] = 46] = \"Conversation_DialogType\";\n    /**\n     * Silence timeout for listening\n     * @member PropertyId.Conversation_Initial_Silence_Timeout\n     */\n    PropertyId[PropertyId[\"Conversation_Initial_Silence_Timeout\"] = 47] = \"Conversation_Initial_Silence_Timeout\";\n    /**\n     * From Id to add to speech recognition activities.\n     * @member PropertyId.Conversation_From_Id\n     */\n    PropertyId[PropertyId[\"Conversation_From_Id\"] = 48] = \"Conversation_From_Id\";\n    /**\n     * ConversationId for the session.\n     * @member PropertyId.Conversation_Conversation_Id\n     */\n    PropertyId[PropertyId[\"Conversation_Conversation_Id\"] = 49] = \"Conversation_Conversation_Id\";\n    /**\n     * Comma separated list of custom voice deployment ids.\n     * @member PropertyId.Conversation_Custom_Voice_Deployment_Ids\n     */\n    PropertyId[PropertyId[\"Conversation_Custom_Voice_Deployment_Ids\"] = 50] = \"Conversation_Custom_Voice_Deployment_Ids\";\n    /**\n     * Speech activity template, stamp properties from the template on the activity generated by the service for speech.\n     * @member PropertyId.Conversation_Speech_Activity_Template\n     * Added in version 1.10.0.\n     */\n    PropertyId[PropertyId[\"Conversation_Speech_Activity_Template\"] = 51] = \"Conversation_Speech_Activity_Template\";\n    /**\n     * Enables or disables the receipt of turn status messages as obtained on the turnStatusReceived event.\n     * @member PropertyId.Conversation_Request_Bot_Status_Messages\n     * Added in version 1.15.0.\n     */\n    PropertyId[PropertyId[\"Conversation_Request_Bot_Status_Messages\"] = 52] = \"Conversation_Request_Bot_Status_Messages\";\n    /**\n     * Specifies the connection ID to be provided in the Agent configuration message, e.g. a Direct Line token for\n     * channel authentication.\n     * Added in version 1.15.1.\n     */\n    PropertyId[PropertyId[\"Conversation_Agent_Connection_Id\"] = 53] = \"Conversation_Agent_Connection_Id\";\n    /**\n     * The Cognitive Services Speech Service host (url). Under normal circumstances, you shouldn't have to use this property directly.\n     * Instead, use [[SpeechConfig.fromHost]].\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_Host\"] = 54] = \"SpeechServiceConnection_Host\";\n    /**\n     * Set the host for service calls to the Conversation Translator REST management and websocket calls.\n     */\n    PropertyId[PropertyId[\"ConversationTranslator_Host\"] = 55] = \"ConversationTranslator_Host\";\n    /**\n     * Optionally set the the host's display name.\n     * Used when joining a conversation.\n     */\n    PropertyId[PropertyId[\"ConversationTranslator_Name\"] = 56] = \"ConversationTranslator_Name\";\n    /**\n     * Optionally set a value for the X-CorrelationId request header.\n     * Used for troubleshooting errors in the server logs. It should be a valid guid.\n     */\n    PropertyId[PropertyId[\"ConversationTranslator_CorrelationId\"] = 57] = \"ConversationTranslator_CorrelationId\";\n    /**\n     * Set the conversation token to be sent to the speech service. This enables the\n     * service to service call from the speech service to the Conversation Translator service for relaying\n     * recognitions. For internal use.\n     */\n    PropertyId[PropertyId[\"ConversationTranslator_Token\"] = 58] = \"ConversationTranslator_Token\";\n    /**\n     * The reference text of the audio for pronunciation evaluation.\n     * For this and the following pronunciation assessment parameters, see\n     * https://docs.microsoft.com/azure/cognitive-services/speech-service/rest-speech-to-text#pronunciation-assessment-parameters for details.\n     * Under normal circumstances, you shouldn't have to use this property directly.\n     * Added in version 1.15.0\n     */\n    PropertyId[PropertyId[\"PronunciationAssessment_ReferenceText\"] = 59] = \"PronunciationAssessment_ReferenceText\";\n    /**\n     * The point system for pronunciation score calibration (FivePoint or HundredMark).\n     * Under normal circumstances, you shouldn't have to use this property directly.\n     * Added in version 1.15.0\n     */\n    PropertyId[PropertyId[\"PronunciationAssessment_GradingSystem\"] = 60] = \"PronunciationAssessment_GradingSystem\";\n    /**\n     * The pronunciation evaluation granularity (Phoneme, Word, or FullText).\n     * Under normal circumstances, you shouldn't have to use this property directly.\n     * Added in version 1.15.0\n     */\n    PropertyId[PropertyId[\"PronunciationAssessment_Granularity\"] = 61] = \"PronunciationAssessment_Granularity\";\n    /**\n     * Defines if enable miscue calculation.\n     * With this enabled, the pronounced words will be compared to the reference text,\n     * and will be marked with omission/insertion based on the comparison. The default setting is False.\n     * Under normal circumstances, you shouldn't have to use this property directly.\n     * Added in version 1.15.0\n     */\n    PropertyId[PropertyId[\"PronunciationAssessment_EnableMiscue\"] = 62] = \"PronunciationAssessment_EnableMiscue\";\n    /**\n     * The json string of pronunciation assessment parameters\n     * Under normal circumstances, you shouldn't have to use this property directly.\n     * Added in version 1.15.0\n     */\n    PropertyId[PropertyId[\"PronunciationAssessment_Json\"] = 63] = \"PronunciationAssessment_Json\";\n    /**\n     * Pronunciation assessment parameters.\n     * This property is intended to be read-only. The SDK is using it internally.\n     * Added in version 1.15.0\n     */\n    PropertyId[PropertyId[\"PronunciationAssessment_Params\"] = 64] = \"PronunciationAssessment_Params\";\n    /**\n     * Version of Speaker Recognition API to use.\n     * Added in version 1.18.0\n     */\n    PropertyId[PropertyId[\"SpeakerRecognition_Api_Version\"] = 65] = \"SpeakerRecognition_Api_Version\";\n})(PropertyId || (PropertyId = {}));\n\n//# sourceMappingURL=PropertyId.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionEventArgs.js":
  /*!************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionEventArgs.js ***!
    \************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"RecognitionEventArgs\": () => (/* binding */ RecognitionEventArgs)\n/* harmony export */ });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SessionEventArgs.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Defines payload for session events like Speech Start/End Detected\n * @class\n */\nclass RecognitionEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__.SessionEventArgs {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {number} offset - The offset.\n     * @param {string} sessionId - The session id.\n     */\n    constructor(offset, sessionId) {\n        super(sessionId);\n        this.privOffset = offset;\n    }\n    /**\n     * Represents the message offset\n     * @member RecognitionEventArgs.prototype.offset\n     * @function\n     * @public\n     */\n    get offset() {\n        return this.privOffset;\n    }\n}\n\n//# sourceMappingURL=RecognitionEventArgs.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionEventArgs.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionResult.js":
  /*!*********************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionResult.js ***!
    \*********************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"RecognitionResult\": () => (/* binding */ RecognitionResult)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines result of speech recognition.\n * @class RecognitionResult\n */\nclass RecognitionResult {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {string} resultId - The result id.\n     * @param {ResultReason} reason - The reason.\n     * @param {string} text - The recognized text.\n     * @param {number} duration - The duration.\n     * @param {number} offset - The offset into the stream.\n     * @param {string} language - Primary Language detected, if provided.\n     * @param {string} languageDetectionConfidence - Primary Language confidence (\"Unknown,\" \"Low,\" \"Medium,\" \"High\"...), if provided.\n     * @param {string} errorDetails - Error details, if provided.\n     * @param {string} json - Additional Json, if provided.\n     * @param {PropertyCollection} properties - Additional properties, if provided.\n     */\n    constructor(resultId, reason, text, duration, offset, language, languageDetectionConfidence, errorDetails, json, properties) {\n        this.privResultId = resultId;\n        this.privReason = reason;\n        this.privText = text;\n        this.privDuration = duration;\n        this.privOffset = offset;\n        this.privLanguage = language;\n        this.privLanguageDetectionConfidence = languageDetectionConfidence;\n        this.privErrorDetails = errorDetails;\n        this.privJson = json;\n        this.privProperties = properties;\n    }\n    /**\n     * Specifies the result identifier.\n     * @member RecognitionResult.prototype.resultId\n     * @function\n     * @public\n     * @returns {string} Specifies the result identifier.\n     */\n    get resultId() {\n        return this.privResultId;\n    }\n    /**\n     * Specifies status of the result.\n     * @member RecognitionResult.prototype.reason\n     * @function\n     * @public\n     * @returns {ResultReason} Specifies status of the result.\n     */\n    get reason() {\n        return this.privReason;\n    }\n    /**\n     * Presents the recognized text in the result.\n     * @member RecognitionResult.prototype.text\n     * @function\n     * @public\n     * @returns {string} Presents the recognized text in the result.\n     */\n    get text() {\n        return this.privText;\n    }\n    /**\n     * Duration of recognized speech in 100 nano second increments.\n     * @member RecognitionResult.prototype.duration\n     * @function\n     * @public\n     * @returns {number} Duration of recognized speech in 100 nano second increments.\n     */\n    get duration() {\n        return this.privDuration;\n    }\n    /**\n     * Offset of recognized speech in 100 nano second increments.\n     * @member RecognitionResult.prototype.offset\n     * @function\n     * @public\n     * @returns {number} Offset of recognized speech in 100 nano second increments.\n     */\n    get offset() {\n        return this.privOffset;\n    }\n    /**\n     * Primary Language detected.\n     * @member RecognitionResult.prototype.language\n     * @function\n     * @public\n     * @returns {string} language detected.\n     */\n    get language() {\n        return this.privLanguage;\n    }\n    /**\n     * Primary Language detection confidence (Unknown, Low, Medium, High).\n     * @member RecognitionResult.prototype.languageDetectionConfidence\n     * @function\n     * @public\n     * @returns {string} detection confidence strength.\n     */\n    get languageDetectionConfidence() {\n        return this.privLanguageDetectionConfidence;\n    }\n    /**\n     * In case of an unsuccessful recognition, provides details of the occurred error.\n     * @member RecognitionResult.prototype.errorDetails\n     * @function\n     * @public\n     * @returns {string} a brief description of an error.\n     */\n    get errorDetails() {\n        return this.privErrorDetails;\n    }\n    /**\n     * A string containing Json serialized recognition result as it was received from the service.\n     * @member RecognitionResult.prototype.json\n     * @function\n     * @private\n     * @returns {string} Json serialized representation of the result.\n     */\n    get json() {\n        return this.privJson;\n    }\n    /**\n     * The set of properties exposed in the result.\n     * @member RecognitionResult.prototype.properties\n     * @function\n     * @public\n     * @returns {PropertyCollection} The set of properties exposed in the result.\n     */\n    get properties() {\n        return this.privProperties;\n    }\n}\n\n//# sourceMappingURL=RecognitionResult.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionResult.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Recognizer.js":
  /*!**************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Recognizer.js ***!
    \**************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Recognizer\": () => (/* binding */ Recognizer)\n/* harmony export */ });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceRecognizerBase.js\");\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js\");\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/CognitiveSubscriptionKeyAuthentication.js\");\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/CognitiveTokenAuthentication.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js\");\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioConfig.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\n\n/**\n * Defines the base class Recognizer which mainly contains common event handlers.\n * @class Recognizer\n */\nclass Recognizer {\n    /**\n     * Creates and initializes an instance of a Recognizer\n     * @constructor\n     * @param {AudioConfig} audioInput - An optional audio input stream associated with the recognizer\n     */\n    constructor(audioConfig, properties, connectionFactory) {\n        this.audioConfig = (audioConfig !== undefined) ? audioConfig : _Exports__WEBPACK_IMPORTED_MODULE_0__.AudioConfig.fromDefaultMicrophoneInput();\n        this.privDisposed = false;\n        this.privProperties = properties.clone();\n        this.privConnectionFactory = connectionFactory;\n        this.implCommonRecognizerSetup();\n    }\n    /**\n     * Dispose of associated resources.\n     * @member Recognizer.prototype.close\n     * @function\n     * @public\n     */\n    close(cb, errorCb) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposed);\n        (0,_common_Exports__WEBPACK_IMPORTED_MODULE_2__.marshalPromiseToCallbacks)(this.dispose(true), cb, errorCb);\n    }\n    /**\n     * @Internal\n     * Internal data member to support fromRecognizer* pattern methods on other classes.\n     * Do not use externally, object returned will change without warning or notice.\n     */\n    get internalData() {\n        return this.privReco;\n    }\n    /**\n     * This method performs cleanup of resources.\n     * The Boolean parameter disposing indicates whether the method is called\n     * from Dispose (if disposing is true) or from the finalizer (if disposing is false).\n     * Derived classes should override this method to dispose resource if needed.\n     * @member Recognizer.prototype.dispose\n     * @function\n     * @public\n     * @param {boolean} disposing - Flag to request disposal.\n     */\n    dispose(disposing) {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (this.privDisposed) {\n                return;\n            }\n            this.privDisposed = true;\n            if (disposing) {\n                if (this.privReco) {\n                    yield this.privReco.audioSource.turnOff();\n                    yield this.privReco.dispose();\n                }\n            }\n        });\n    }\n    /**\n     * This method returns the current state of the telemetry setting.\n     * @member Recognizer.prototype.telemetryEnabled\n     * @function\n     * @public\n     * @returns true if the telemetry is enabled, false otherwise.\n     */\n    static get telemetryEnabled() {\n        return _common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__.ServiceRecognizerBase.telemetryDataEnabled;\n    }\n    /**\n     * This method globally enables or disables telemetry.\n     * @member Recognizer.prototype.enableTelemetry\n     * @function\n     * @public\n     * @param enabled - Global setting for telemetry collection.\n     * If set to true, telemetry information like microphone errors,\n     * recognition errors are collected and sent to Microsoft.\n     * If set to false, no telemetry is sent to Microsoft.\n     */\n    static enableTelemetry(enabled) {\n        _common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__.ServiceRecognizerBase.telemetryDataEnabled = enabled;\n    }\n    // Does the generic recognizer setup that is common across all recognizer types.\n    implCommonRecognizerSetup() {\n        let osPlatform = (typeof window !== \"undefined\") ? \"Browser\" : \"Node\";\n        let osName = \"unknown\";\n        let osVersion = \"unknown\";\n        if (typeof navigator !== \"undefined\") {\n            osPlatform = osPlatform + \"/\" + navigator.platform;\n            osName = navigator.userAgent;\n            osVersion = navigator.appVersion;\n        }\n        const recognizerConfig = this.createRecognizerConfig(new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.SpeechServiceConfig(new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.Context(new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.OS(osPlatform, osName, osVersion))));\n        this.privReco = this.createServiceRecognizer(Recognizer.getAuthFromProperties(this.privProperties), this.privConnectionFactory, this.audioConfig, recognizerConfig);\n    }\n    recognizeOnceAsyncImpl(recognitionMode) {\n        return __awaiter(this, void 0, void 0, function* () {\n            _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposed);\n            const ret = new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.Deferred();\n            yield this.implRecognizerStop();\n            yield this.privReco.recognize(recognitionMode, ret.resolve, ret.reject);\n            const result = yield ret.promise;\n            yield this.implRecognizerStop();\n            return result;\n        });\n    }\n    startContinuousRecognitionAsyncImpl(recognitionMode) {\n        return __awaiter(this, void 0, void 0, function* () {\n            _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposed);\n            yield this.implRecognizerStop();\n            yield this.privReco.recognize(recognitionMode, undefined, undefined);\n        });\n    }\n    stopContinuousRecognitionAsyncImpl() {\n        return __awaiter(this, void 0, void 0, function* () {\n            _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposed);\n            yield this.implRecognizerStop();\n        });\n    }\n    implRecognizerStop() {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (this.privReco) {\n                yield this.privReco.stopRecognizing();\n            }\n            return;\n        });\n    }\n    static getAuthFromProperties(properties) {\n        const subscriptionKey = properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_5__.PropertyId.SpeechServiceConnection_Key, undefined);\n        const authentication = (subscriptionKey && subscriptionKey !== \"\") ?\n            new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_6__.CognitiveSubscriptionKeyAuthentication(subscriptionKey) :\n            new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_7__.CognitiveTokenAuthentication(() => {\n                const authorizationToken = properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_5__.PropertyId.SpeechServiceAuthorization_Token, undefined);\n                return Promise.resolve(authorizationToken);\n            }, () => {\n                const authorizationToken = properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_5__.PropertyId.SpeechServiceAuthorization_Token, undefined);\n                return Promise.resolve(authorizationToken);\n            });\n        return authentication;\n    }\n}\n\n//# sourceMappingURL=Recognizer.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Recognizer.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js":
  /*!****************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js ***!
    \****************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ResultReason\": () => (/* binding */ ResultReason)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines the possible reasons a recognition result might be generated.\n * @class ResultReason\n */\nvar ResultReason;\n(function (ResultReason) {\n    /**\n     * Indicates speech could not be recognized. More details\n     * can be found in the NoMatchDetails object.\n     * @member ResultReason.NoMatch\n     */\n    ResultReason[ResultReason[\"NoMatch\"] = 0] = \"NoMatch\";\n    /**\n     * Indicates that the recognition was canceled. More details\n     * can be found using the CancellationDetails object.\n     * @member ResultReason.Canceled\n     */\n    ResultReason[ResultReason[\"Canceled\"] = 1] = \"Canceled\";\n    /**\n     * Indicates the speech result contains hypothesis text.\n     * @member ResultReason.RecognizedSpeech\n     */\n    ResultReason[ResultReason[\"RecognizingSpeech\"] = 2] = \"RecognizingSpeech\";\n    /**\n     * Indicates the speech result contains final text that has been recognized.\n     * Speech Recognition is now complete for this phrase.\n     * @member ResultReason.RecognizedSpeech\n     */\n    ResultReason[ResultReason[\"RecognizedSpeech\"] = 3] = \"RecognizedSpeech\";\n    /**\n     * Indicates the speech result contains a finalized acceptance of a provided keyword.\n     * Speech recognition will continue unless otherwise configured.\n     * @member ResultReason.RecognizedKeyword\n     */\n    ResultReason[ResultReason[\"RecognizedKeyword\"] = 4] = \"RecognizedKeyword\";\n    /**\n     * Indicates the intent result contains hypothesis text and intent.\n     * @member ResultReason.RecognizingIntent\n     */\n    ResultReason[ResultReason[\"RecognizingIntent\"] = 5] = \"RecognizingIntent\";\n    /**\n     * Indicates the intent result contains final text and intent.\n     * Speech Recognition and Intent determination are now complete for this phrase.\n     * @member ResultReason.RecognizedIntent\n     */\n    ResultReason[ResultReason[\"RecognizedIntent\"] = 6] = \"RecognizedIntent\";\n    /**\n     * Indicates the translation result contains hypothesis text and its translation(s).\n     * @member ResultReason.TranslatingSpeech\n     */\n    ResultReason[ResultReason[\"TranslatingSpeech\"] = 7] = \"TranslatingSpeech\";\n    /**\n     * Indicates the translation result contains final text and corresponding translation(s).\n     * Speech Recognition and Translation are now complete for this phrase.\n     * @member ResultReason.TranslatedSpeech\n     */\n    ResultReason[ResultReason[\"TranslatedSpeech\"] = 8] = \"TranslatedSpeech\";\n    /**\n     * Indicates the synthesized audio result contains a non-zero amount of audio data\n     * @member ResultReason.SynthesizingAudio\n     */\n    ResultReason[ResultReason[\"SynthesizingAudio\"] = 9] = \"SynthesizingAudio\";\n    /**\n     * Indicates the synthesized audio is now complete for this phrase.\n     * @member ResultReason.SynthesizingAudioCompleted\n     */\n    ResultReason[ResultReason[\"SynthesizingAudioCompleted\"] = 10] = \"SynthesizingAudioCompleted\";\n    /**\n     * Indicates the speech synthesis is now started\n     * @member ResultReason.SynthesizingAudioStarted\n     */\n    ResultReason[ResultReason[\"SynthesizingAudioStarted\"] = 11] = \"SynthesizingAudioStarted\";\n    /**\n     * Indicates the voice profile is being enrolled and customers need to send more audio to create a voice profile.\n     * @member ResultReason.EnrollingVoiceProfile\n     */\n    ResultReason[ResultReason[\"EnrollingVoiceProfile\"] = 12] = \"EnrollingVoiceProfile\";\n    /**\n     * Indicates the voice profile has been enrolled.\n     * @member ResultReason.EnrolledVoiceProfile\n     */\n    ResultReason[ResultReason[\"EnrolledVoiceProfile\"] = 13] = \"EnrolledVoiceProfile\";\n    /**\n     * Indicates successful identification of some speakers.\n     * @member ResultReason.RecognizedSpeakers\n     */\n    ResultReason[ResultReason[\"RecognizedSpeakers\"] = 14] = \"RecognizedSpeakers\";\n    /**\n     * Indicates successfully verified one speaker.\n     * @member ResultReason.RecognizedSpeaker\n     */\n    ResultReason[ResultReason[\"RecognizedSpeaker\"] = 15] = \"RecognizedSpeaker\";\n    /**\n     * Indicates a voice profile has been reset successfully.\n     * @member ResultReason.ResetVoiceProfile\n     */\n    ResultReason[ResultReason[\"ResetVoiceProfile\"] = 16] = \"ResetVoiceProfile\";\n    /**\n     * Indicates a voice profile has been deleted successfully.\n     * @member ResultReason.DeletedVoiceProfile\n     */\n    ResultReason[ResultReason[\"DeletedVoiceProfile\"] = 17] = \"DeletedVoiceProfile\";\n    /**\n     * Indicates synthesis voices list has been successfully retrieved.\n     * @member ResultReason.VoicesListRetrieved\n     */\n    ResultReason[ResultReason[\"VoicesListRetrieved\"] = 18] = \"VoicesListRetrieved\";\n})(ResultReason || (ResultReason = {}));\n\n//# sourceMappingURL=ResultReason.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ServiceEventArgs.js":
  /*!********************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ServiceEventArgs.js ***!
    \********************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ServiceEventArgs\": () => (/* binding */ ServiceEventArgs)\n/* harmony export */ });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SessionEventArgs.js\");\n//\n// Copyright (c) Microsoft. All rights reserved.\n// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.\n//\n\n/**\n * Defines payload for any Service message event\n * Added in version 1.9.0\n */\nclass ServiceEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__.SessionEventArgs {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {string} json - json payload of the USP message.\n     */\n    constructor(json, name, sessionId) {\n        super(sessionId);\n        this.privJsonResult = json;\n        this.privEventName = name;\n    }\n    get jsonString() {\n        return this.privJsonResult;\n    }\n    get eventName() {\n        return this.privEventName;\n    }\n}\n\n//# sourceMappingURL=ServiceEventArgs.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ServiceEventArgs.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SessionEventArgs.js":
  /*!********************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SessionEventArgs.js ***!
    \********************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SessionEventArgs\": () => (/* binding */ SessionEventArgs)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines content for session events like SessionStarted/Stopped, SoundStarted/Stopped.\n * @class SessionEventArgs\n */\nclass SessionEventArgs {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {string} sessionId - The session id.\n     */\n    constructor(sessionId) {\n        this.privSessionId = sessionId;\n    }\n    /**\n     * Represents the session identifier.\n     * @member SessionEventArgs.prototype.sessionId\n     * @function\n     * @public\n     * @returns {string} Represents the session identifier.\n     */\n    get sessionId() {\n        return this.privSessionId;\n    }\n}\n\n//# sourceMappingURL=SessionEventArgs.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SessionEventArgs.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechConfig.js":
  /*!****************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechConfig.js ***!
    \****************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SpeechConfig\": () => (/* binding */ SpeechConfig),\n/* harmony export */   \"SpeechConfigImpl\": () => (/* binding */ SpeechConfigImpl)\n/* harmony export */ });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/OutputFormat.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ProfanityOption.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisOutputFormat.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/* eslint-disable max-classes-per-file */\n\n\n\n/**\n * Speech configuration.\n * @class SpeechConfig\n */\nclass SpeechConfig {\n    /**\n     * Creates and initializes an instance.\n     * @constructor\n     */\n    constructor() {\n        return;\n    }\n    /**\n     * Static instance of SpeechConfig returned by passing subscriptionKey and service region.\n     * Note: Please use your LanguageUnderstanding subscription key in case you want to use the Intent recognizer.\n     * @member SpeechConfig.fromSubscription\n     * @function\n     * @public\n     * @param {string} subscriptionKey - The subscription key.\n     * @param {string} region - The region name (see the <a href=\"https://aka.ms/csspeech/region\">region page</a>).\n     * @returns {SpeechConfig} The speech factory\n     */\n    static fromSubscription(subscriptionKey, region) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(subscriptionKey, \"subscriptionKey\");\n        _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(region, \"region\");\n        const speechImpl = new SpeechConfigImpl();\n        speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Region, region);\n        speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_IntentRegion, region);\n        speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Key, subscriptionKey);\n        return speechImpl;\n    }\n    /**\n     * Creates an instance of the speech config with specified endpoint and subscription key.\n     * This method is intended only for users who use a non-standard service endpoint or parameters.\n     * Note: Please use your LanguageUnderstanding subscription key in case you want to use the Intent recognizer.\n     * Note: The query parameters specified in the endpoint URL are not changed, even if they are set by any other APIs.\n     * For example, if language is defined in the uri as query parameter \"language=de-DE\", and also set by\n     * SpeechConfig.speechRecognitionLanguage = \"en-US\", the language setting in uri takes precedence,\n     * and the effective language is \"de-DE\". Only the parameters that are not specified in the\n     * endpoint URL can be set by other APIs.\n     * Note: To use authorization token with fromEndpoint, pass an empty string to the subscriptionKey in the\n     * fromEndpoint method, and then set authorizationToken=\"token\" on the created SpeechConfig instance to\n     * use the authorization token.\n     * @member SpeechConfig.fromEndpoint\n     * @function\n     * @public\n     * @param {URL} endpoint - The service endpoint to connect to.\n     * @param {string} subscriptionKey - The subscription key. If a subscription key is not specified, an authorization token must be set.\n     * @returns {SpeechConfig} A speech factory instance.\n     */\n    static fromEndpoint(endpoint, subscriptionKey) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNull(endpoint, \"endpoint\");\n        const speechImpl = new SpeechConfigImpl();\n        speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Endpoint, endpoint.href);\n        if (undefined !== subscriptionKey) {\n            speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Key, subscriptionKey);\n        }\n        return speechImpl;\n    }\n    /**\n     * Creates an instance of the speech config with specified host and subscription key.\n     * This method is intended only for users who use a non-default service host. Standard resource path will be assumed.\n     * For services with a non-standard resource path or no path at all, use fromEndpoint instead.\n     * Note: Query parameters are not allowed in the host URI and must be set by other APIs.\n     * Note: To use an authorization token with fromHost, use fromHost(URL),\n     * and then set the AuthorizationToken property on the created SpeechConfig instance.\n     * Note: Added in version 1.9.0.\n     * @member SpeechConfig.fromHost\n     * @function\n     * @public\n     * @param {URL} host - The service endpoint to connect to. Format is \"protocol://host:port\" where \":port\" is optional.\n     * @param {string} subscriptionKey - The subscription key. If a subscription key is not specified, an authorization token must be set.\n     * @returns {SpeechConfig} A speech factory instance.\n     */\n    static fromHost(hostName, subscriptionKey) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNull(hostName, \"hostName\");\n        const speechImpl = new SpeechConfigImpl();\n        speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Host, hostName.protocol + \"//\" + hostName.hostname + (hostName.port === \"\" ? \"\" : \":\" + hostName.port));\n        if (undefined !== subscriptionKey) {\n            speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Key, subscriptionKey);\n        }\n        return speechImpl;\n    }\n    /**\n     * Creates an instance of the speech factory with specified initial authorization token and region.\n     * Note: The caller needs to ensure that the authorization token is valid. Before the authorization token\n     * expires, the caller needs to refresh it by calling this setter with a new valid token.\n     * Note: Please use a token derived from your LanguageUnderstanding subscription key in case you want\n     * to use the Intent recognizer. As configuration values are copied when creating a new recognizer,\n     * the new token value will not apply to recognizers that have already been created. For recognizers\n     * that have been created before, you need to set authorization token of the corresponding recognizer\n     * to refresh the token. Otherwise, the recognizers will encounter errors during recognition.\n     * @member SpeechConfig.fromAuthorizationToken\n     * @function\n     * @public\n     * @param {string} authorizationToken - The initial authorization token.\n     * @param {string} region - The region name (see the <a href=\"https://aka.ms/csspeech/region\">region page</a>).\n     * @returns {SpeechConfig} A speech factory instance.\n     */\n    static fromAuthorizationToken(authorizationToken, region) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNull(authorizationToken, \"authorizationToken\");\n        _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(region, \"region\");\n        const speechImpl = new SpeechConfigImpl();\n        speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Region, region);\n        speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_IntentRegion, region);\n        speechImpl.authorizationToken = authorizationToken;\n        return speechImpl;\n    }\n    /**\n     * Closes the configuration.\n     * @member SpeechConfig.prototype.close\n     * @function\n     * @public\n     */\n    // eslint-disable-next-line @typescript-eslint/no-empty-function\n    close() { }\n}\n/**\n * @public\n * @class SpeechConfigImpl\n */\nclass SpeechConfigImpl extends SpeechConfig {\n    constructor() {\n        super();\n        this.privProperties = new _Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyCollection();\n        this.speechRecognitionLanguage = \"en-US\"; // Should we have a default?\n        this.outputFormat = _Exports__WEBPACK_IMPORTED_MODULE_3__.OutputFormat.Simple;\n    }\n    get properties() {\n        return this.privProperties;\n    }\n    get endPoint() {\n        return new URL(this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Endpoint));\n    }\n    get subscriptionKey() {\n        return this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Key);\n    }\n    get region() {\n        return this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Region);\n    }\n    get authorizationToken() {\n        return this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceAuthorization_Token);\n    }\n    set authorizationToken(value) {\n        this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceAuthorization_Token, value);\n    }\n    get speechRecognitionLanguage() {\n        return this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_RecoLanguage);\n    }\n    set speechRecognitionLanguage(value) {\n        this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_RecoLanguage, value);\n    }\n    get autoDetectSourceLanguages() {\n        return this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages);\n    }\n    set autoDetectSourceLanguages(value) {\n        this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages, value);\n    }\n    get outputFormat() {\n        return _Exports__WEBPACK_IMPORTED_MODULE_3__.OutputFormat[this.privProperties.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.OutputFormatPropertyName, undefined)];\n    }\n    set outputFormat(value) {\n        this.privProperties.setProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.OutputFormatPropertyName, _Exports__WEBPACK_IMPORTED_MODULE_3__.OutputFormat[value]);\n    }\n    get endpointId() {\n        return this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_EndpointId);\n    }\n    set endpointId(value) {\n        this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_EndpointId, value);\n    }\n    setProperty(name, value) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNull(value, \"value\");\n        this.privProperties.setProperty(name, value);\n    }\n    getProperty(name, def) {\n        return this.privProperties.getProperty(name, def);\n    }\n    setProxy(proxyHostName, proxyPort, proxyUserName, proxyPassword) {\n        this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_ProxyHostName], proxyHostName);\n        this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_ProxyPort], proxyPort);\n        this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_ProxyUserName], proxyUserName);\n        this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_ProxyPassword], proxyPassword);\n    }\n    setServiceProperty(name, value) {\n        const currentProperties = JSON.parse(this.privProperties.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ServicePropertiesPropertyName, \"{}\"));\n        currentProperties[name] = value;\n        this.privProperties.setProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ServicePropertiesPropertyName, JSON.stringify(currentProperties));\n    }\n    setProfanity(profanity) {\n        this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceResponse_ProfanityOption, _Exports__WEBPACK_IMPORTED_MODULE_5__.ProfanityOption[profanity]);\n    }\n    enableAudioLogging() {\n        this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_EnableAudioLogging, \"true\");\n    }\n    requestWordLevelTimestamps() {\n        this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceResponse_RequestWordLevelTimestamps, \"true\");\n    }\n    enableDictation() {\n        this.privProperties.setProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ForceDictationPropertyName, \"true\");\n    }\n    clone() {\n        const ret = new SpeechConfigImpl();\n        ret.privProperties = this.privProperties.clone();\n        return ret;\n    }\n    get speechSynthesisLanguage() {\n        return this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_SynthLanguage);\n    }\n    set speechSynthesisLanguage(language) {\n        this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_SynthLanguage, language);\n    }\n    get speechSynthesisVoiceName() {\n        return this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_SynthVoice);\n    }\n    set speechSynthesisVoiceName(voice) {\n        this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_SynthVoice, voice);\n    }\n    get speechSynthesisOutputFormat() {\n        return _Exports__WEBPACK_IMPORTED_MODULE_6__.SpeechSynthesisOutputFormat[this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_SynthOutputFormat, undefined)];\n    }\n    set speechSynthesisOutputFormat(format) {\n        this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_SynthOutputFormat, _Exports__WEBPACK_IMPORTED_MODULE_6__.SpeechSynthesisOutputFormat[format]);\n    }\n}\n\n//# sourceMappingURL=SpeechConfig.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechConfig.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionCanceledEventArgs.js":
  /*!**************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionCanceledEventArgs.js ***!
    \**************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SpeechRecognitionCanceledEventArgs\": () => (/* binding */ SpeechRecognitionCanceledEventArgs)\n/* harmony export */ });\n/* harmony import */ var _CancellationEventArgsBase__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./CancellationEventArgsBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationEventArgsBase.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nclass SpeechRecognitionCanceledEventArgs extends _CancellationEventArgsBase__WEBPACK_IMPORTED_MODULE_0__.CancellationEventArgsBase {\n}\n\n//# sourceMappingURL=SpeechRecognitionCanceledEventArgs.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionCanceledEventArgs.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionEventArgs.js":
  /*!******************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionEventArgs.js ***!
    \******************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConversationTranscriptionEventArgs\": () => (/* binding */ ConversationTranscriptionEventArgs),\n/* harmony export */   \"SpeechRecognitionEventArgs\": () => (/* binding */ SpeechRecognitionEventArgs)\n/* harmony export */ });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionEventArgs.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/* eslint-disable max-classes-per-file */\n\n/**\n * Defines contents of speech recognizing/recognized event.\n * @class SpeechRecognitionEventArgs\n */\nclass SpeechRecognitionEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__.RecognitionEventArgs {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {SpeechRecognitionResult} result - The speech recognition result.\n     * @param {number} offset - The offset.\n     * @param {string} sessionId - The session id.\n     */\n    constructor(result, offset, sessionId) {\n        super(offset, sessionId);\n        this.privResult = result;\n    }\n    /**\n     * Specifies the recognition result.\n     * @member SpeechRecognitionEventArgs.prototype.result\n     * @function\n     * @public\n     * @returns {SpeechRecognitionResult} the recognition result.\n     */\n    get result() {\n        return this.privResult;\n    }\n}\n/**\n * Defines contents of conversation transcribed/transcribing event.\n * @class ConversationTranscriptionEventArgs\n */\nclass ConversationTranscriptionEventArgs extends SpeechRecognitionEventArgs {\n}\n\n//# sourceMappingURL=SpeechRecognitionEventArgs.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionEventArgs.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionResult.js":
  /*!***************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionResult.js ***!
    \***************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SpeechRecognitionResult\": () => (/* binding */ SpeechRecognitionResult)\n/* harmony export */ });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionResult.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Defines result of speech recognition.\n * @class SpeechRecognitionResult\n */\nclass SpeechRecognitionResult extends _Exports__WEBPACK_IMPORTED_MODULE_0__.RecognitionResult {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @public\n     * @param {string} resultId - The result id.\n     * @param {ResultReason} reason - The reason.\n     * @param {string} text - The recognized text.\n     * @param {number} duration - The duration.\n     * @param {number} offset - The offset into the stream.\n     * @param {string} language - Primary Language detected, if provided.\n     * @param {string} languageDetectionConfidence - Primary Language confidence (\"Unknown,\" \"Low,\" \"Medium,\" \"High\"...), if provided.\n     * @param {string} speakerId - speaker id for conversation transcription, if provided.\n     * @param {string} errorDetails - Error details, if provided.\n     * @param {string} json - Additional Json, if provided.\n     * @param {PropertyCollection} properties - Additional properties, if provided.\n     */\n    constructor(resultId, reason, text, duration, offset, language, languageDetectionConfidence, speakerId, errorDetails, json, properties) {\n        super(resultId, reason, text, duration, offset, language, languageDetectionConfidence, errorDetails, json, properties);\n        this.privSpeakerId = speakerId;\n    }\n    /**\n     * speaker id from conversation transcription/id scenarios\n     * @member SpeechRecognitionResult.prototype.speakerId\n     * @function\n     * @public\n     * @returns {string} id of speaker in given result\n     */\n    get speakerId() {\n        return this.privSpeakerId;\n    }\n}\n\n//# sourceMappingURL=SpeechRecognitionResult.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionResult.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognizer.js":
  /*!********************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognizer.js ***!
    \********************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SpeechRecognizer\": () => (/* binding */ SpeechRecognizer)\n/* harmony export */ });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionFactory.js\");\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js\");\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechServiceRecognizer.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js\");\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Recognizer.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/OutputFormat.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\n\n/**\n * Performs speech recognition from microphone, file, or other audio input streams, and gets transcribed text as result.\n * @class SpeechRecognizer\n */\nclass SpeechRecognizer extends _Exports__WEBPACK_IMPORTED_MODULE_0__.Recognizer {\n    /**\n     * SpeechRecognizer constructor.\n     * @constructor\n     * @param {SpeechConfig} speechConfig - an set of initial properties for this recognizer\n     * @param {AudioConfig} audioConfig - An optional audio configuration associated with the recognizer\n     */\n    constructor(speechConfig, audioConfig) {\n        const speechConfigImpl = speechConfig;\n        _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNull(speechConfigImpl, \"speechConfig\");\n        _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(speechConfigImpl.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_RecoLanguage), _Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_RecoLanguage]);\n        super(audioConfig, speechConfigImpl.properties, new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__.SpeechConnectionFactory());\n        this.privDisposedRecognizer = false;\n    }\n    /**\n     * SpeechRecognizer constructor.\n     * @constructor\n     * @param {SpeechConfig} speechConfig - an set of initial properties for this recognizer\n     * @param {AutoDetectSourceLanguageConfig} autoDetectSourceLanguageConfig - An source language detection configuration associated with the recognizer\n     * @param {AudioConfig} audioConfig - An optional audio configuration associated with the recognizer\n     */\n    static FromConfig(speechConfig, autoDetectSourceLanguageConfig, audioConfig) {\n        const speechConfigImpl = speechConfig;\n        autoDetectSourceLanguageConfig.properties.mergeTo(speechConfigImpl.properties);\n        const recognizer = new SpeechRecognizer(speechConfig, audioConfig);\n        return recognizer;\n    }\n    /**\n     * Gets the endpoint id of a customized speech model that is used for speech recognition.\n     * @member SpeechRecognizer.prototype.endpointId\n     * @function\n     * @public\n     * @returns {string} the endpoint id of a customized speech model that is used for speech recognition.\n     */\n    get endpointId() {\n        _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposedRecognizer);\n        return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_EndpointId, \"00000000-0000-0000-0000-000000000000\");\n    }\n    /**\n     * Gets the authorization token used to communicate with the service.\n     * @member SpeechRecognizer.prototype.authorizationToken\n     * @function\n     * @public\n     * @returns {string} Authorization token.\n     */\n    get authorizationToken() {\n        return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceAuthorization_Token);\n    }\n    /**\n     * Gets/Sets the authorization token used to communicate with the service.\n     * @member SpeechRecognizer.prototype.authorizationToken\n     * @function\n     * @public\n     * @param {string} token - Authorization token.\n     */\n    set authorizationToken(token) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(token, \"token\");\n        this.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceAuthorization_Token, token);\n    }\n    /**\n     * Gets the spoken language of recognition.\n     * @member SpeechRecognizer.prototype.speechRecognitionLanguage\n     * @function\n     * @public\n     * @returns {string} The spoken language of recognition.\n     */\n    get speechRecognitionLanguage() {\n        _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposedRecognizer);\n        return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_RecoLanguage);\n    }\n    /**\n     * Gets the output format of recognition.\n     * @member SpeechRecognizer.prototype.outputFormat\n     * @function\n     * @public\n     * @returns {OutputFormat} The output format of recognition.\n     */\n    get outputFormat() {\n        _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposedRecognizer);\n        if (this.properties.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.OutputFormatPropertyName, _Exports__WEBPACK_IMPORTED_MODULE_5__.OutputFormat[_Exports__WEBPACK_IMPORTED_MODULE_5__.OutputFormat.Simple]) === _Exports__WEBPACK_IMPORTED_MODULE_5__.OutputFormat[_Exports__WEBPACK_IMPORTED_MODULE_5__.OutputFormat.Simple]) {\n            return _Exports__WEBPACK_IMPORTED_MODULE_5__.OutputFormat.Simple;\n        }\n        else {\n            return _Exports__WEBPACK_IMPORTED_MODULE_5__.OutputFormat.Detailed;\n        }\n    }\n    /**\n     * The collection of properties and their values defined for this SpeechRecognizer.\n     * @member SpeechRecognizer.prototype.properties\n     * @function\n     * @public\n     * @returns {PropertyCollection} The collection of properties and their values defined for this SpeechRecognizer.\n     */\n    get properties() {\n        return this.privProperties;\n    }\n    /**\n     * Starts speech recognition, and stops after the first utterance is recognized.\n     * The task returns the recognition text as result.\n     * Note: RecognizeOnceAsync() returns when the first utterance has been recognized,\n     * so it is suitable only for single shot recognition\n     * like command or query. For long-running recognition, use StartContinuousRecognitionAsync() instead.\n     * @member SpeechRecognizer.prototype.recognizeOnceAsync\n     * @function\n     * @public\n     * @param cb - Callback that received the SpeechRecognitionResult.\n     * @param err - Callback invoked in case of an error.\n     */\n    recognizeOnceAsync(cb, err) {\n        (0,_common_Exports__WEBPACK_IMPORTED_MODULE_6__.marshalPromiseToCallbacks)(this.recognizeOnceAsyncImpl(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_7__.RecognitionMode.Interactive), cb, err);\n    }\n    /**\n     * Starts speech recognition, until stopContinuousRecognitionAsync() is called.\n     * User must subscribe to events to receive recognition results.\n     * @member SpeechRecognizer.prototype.startContinuousRecognitionAsync\n     * @function\n     * @public\n     * @param cb - Callback invoked once the recognition has started.\n     * @param err - Callback invoked in case of an error.\n     */\n    startContinuousRecognitionAsync(cb, err) {\n        (0,_common_Exports__WEBPACK_IMPORTED_MODULE_6__.marshalPromiseToCallbacks)(this.startContinuousRecognitionAsyncImpl(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_7__.RecognitionMode.Conversation), cb, err);\n    }\n    /**\n     * Stops continuous speech recognition.\n     * @member SpeechRecognizer.prototype.stopContinuousRecognitionAsync\n     * @function\n     * @public\n     * @param cb - Callback invoked once the recognition has stopped.\n     * @param err - Callback invoked in case of an error.\n     */\n    stopContinuousRecognitionAsync(cb, err) {\n        (0,_common_Exports__WEBPACK_IMPORTED_MODULE_6__.marshalPromiseToCallbacks)(this.stopContinuousRecognitionAsyncImpl(), cb, err);\n    }\n    /**\n     * Starts speech recognition with keyword spotting, until\n     * stopKeywordRecognitionAsync() is called.\n     * User must subscribe to events to receive recognition results.\n     * Note: Key word spotting functionality is only available on the\n     * Speech Devices SDK. This functionality is currently not included in the SDK itself.\n     * @member SpeechRecognizer.prototype.startKeywordRecognitionAsync\n     * @function\n     * @public\n     * @param {KeywordRecognitionModel} model The keyword recognition model that\n     * specifies the keyword to be recognized.\n     * @param cb - Callback invoked once the recognition has started.\n     * @param err - Callback invoked in case of an error.\n     */\n    startKeywordRecognitionAsync(model, cb, err) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNull(model, \"model\");\n        if (!!err) {\n            err(\"Not yet implemented.\");\n        }\n    }\n    /**\n     * Stops continuous speech recognition.\n     * Note: Key word spotting functionality is only available on the\n     * Speech Devices SDK. This functionality is currently not included in the SDK itself.\n     * @member SpeechRecognizer.prototype.stopKeywordRecognitionAsync\n     * @function\n     * @public\n     * @param cb - Callback invoked once the recognition has stopped.\n     * @param err - Callback invoked in case of an error.\n     */\n    stopKeywordRecognitionAsync(cb) {\n        if (!!cb) {\n            cb();\n        }\n    }\n    /**\n     * closes all external resources held by an instance of this class.\n     * @member SpeechRecognizer.prototype.close\n     * @function\n     * @public\n     */\n    close(cb, errorCb) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposedRecognizer);\n        (0,_common_Exports__WEBPACK_IMPORTED_MODULE_6__.marshalPromiseToCallbacks)(this.dispose(true), cb, errorCb);\n    }\n    /**\n     * Disposes any resources held by the object.\n     * @member SpeechRecognizer.prototype.dispose\n     * @function\n     * @public\n     * @param {boolean} disposing - true if disposing the object.\n     */\n    dispose(disposing) {\n        const _super = Object.create(null, {\n            dispose: { get: () => super.dispose }\n        });\n        return __awaiter(this, void 0, void 0, function* () {\n            if (this.privDisposedRecognizer) {\n                return;\n            }\n            if (disposing) {\n                this.privDisposedRecognizer = true;\n                yield this.implRecognizerStop();\n            }\n            yield _super.dispose.call(this, disposing);\n        });\n    }\n    createRecognizerConfig(speechConfig) {\n        return new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_7__.RecognizerConfig(speechConfig, this.properties);\n    }\n    createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {\n        const configImpl = audioConfig;\n        return new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_8__.SpeechServiceRecognizer(authentication, connectionFactory, configImpl, recognizerConfig, this);\n    }\n}\n\n//# sourceMappingURL=SpeechRecognizer.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognizer.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisBookmarkEventArgs.js":
  /*!************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisBookmarkEventArgs.js ***!
    \************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SpeechSynthesisBookmarkEventArgs\": () => (/* binding */ SpeechSynthesisBookmarkEventArgs)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines contents of speech synthesis bookmark event.\n * @class SpeechSynthesisBookmarkEventArgs\n * Added in version 1.16.0\n */\nclass SpeechSynthesisBookmarkEventArgs {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {number} audioOffset - The audio offset.\n     * @param {string} text - The bookmark text.\n     */\n    constructor(audioOffset, text) {\n        this.privAudioOffset = audioOffset;\n        this.privText = text;\n    }\n    /**\n     * Specifies the audio offset.\n     * @member SpeechSynthesisBookmarkEventArgs.prototype.audioOffset\n     * @function\n     * @public\n     * @returns {number} the audio offset.\n     */\n    get audioOffset() {\n        return this.privAudioOffset;\n    }\n    /**\n     * Specifies the bookmark.\n     * @member SpeechSynthesisBookmarkEventArgs.prototype.text\n     * @function\n     * @public\n     * @returns {string} the bookmark text.\n     */\n    get text() {\n        return this.privText;\n    }\n}\n\n//# sourceMappingURL=SpeechSynthesisBookmarkEventArgs.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisBookmarkEventArgs.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisEventArgs.js":
  /*!****************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisEventArgs.js ***!
    \****************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SpeechSynthesisEventArgs\": () => (/* binding */ SpeechSynthesisEventArgs)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines contents of speech synthesis events.\n * @class SpeechSynthesisEventArgs\n * Added in version 1.11.0\n */\nclass SpeechSynthesisEventArgs {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {SpeechSynthesisResult} result - The speech synthesis result.\n     */\n    constructor(result) {\n        this.privResult = result;\n    }\n    /**\n     * Specifies the synthesis result.\n     * @member SpeechSynthesisEventArgs.prototype.result\n     * @function\n     * @public\n     * @returns {SpeechSynthesisResult} the synthesis result.\n     */\n    get result() {\n        return this.privResult;\n    }\n}\n\n//# sourceMappingURL=SpeechSynthesisEventArgs.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisEventArgs.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisOutputFormat.js":
  /*!*******************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisOutputFormat.js ***!
    \*******************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SpeechSynthesisOutputFormat\": () => (/* binding */ SpeechSynthesisOutputFormat)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Define speech synthesis audio output formats.\n * @enum SpeechSynthesisOutputFormat\n * Updated in version 1.17.0\n */\nvar SpeechSynthesisOutputFormat;\n(function (SpeechSynthesisOutputFormat) {\n    /**\n     * raw-8khz-8bit-mono-mulaw\n     * @member SpeechSynthesisOutputFormat.Raw8Khz8BitMonoMULaw,\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Raw8Khz8BitMonoMULaw\"] = 0] = \"Raw8Khz8BitMonoMULaw\";\n    /**\n     * riff-16khz-16kbps-mono-siren\n     * @note Unsupported by the service. Do not use this value.\n     * @member SpeechSynthesisOutputFormat.Riff16Khz16KbpsMonoSiren\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Riff16Khz16KbpsMonoSiren\"] = 1] = \"Riff16Khz16KbpsMonoSiren\";\n    /**\n     * audio-16khz-16kbps-mono-siren\n     * @note Unsupported by the service. Do not use this value.\n     * @member SpeechSynthesisOutputFormat.Audio16Khz16KbpsMonoSiren\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Audio16Khz16KbpsMonoSiren\"] = 2] = \"Audio16Khz16KbpsMonoSiren\";\n    /**\n     * audio-16khz-32kbitrate-mono-mp3\n     * @member SpeechSynthesisOutputFormat.Audio16Khz32KBitRateMonoMp3\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Audio16Khz32KBitRateMonoMp3\"] = 3] = \"Audio16Khz32KBitRateMonoMp3\";\n    /**\n     * audio-16khz-128kbitrate-mono-mp3\n     * @member SpeechSynthesisOutputFormat.Audio16Khz128KBitRateMonoMp3\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Audio16Khz128KBitRateMonoMp3\"] = 4] = \"Audio16Khz128KBitRateMonoMp3\";\n    /**\n     * audio-16khz-64kbitrate-mono-mp3\n     * @member SpeechSynthesisOutputFormat.Audio16Khz64KBitRateMonoMp3\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Audio16Khz64KBitRateMonoMp3\"] = 5] = \"Audio16Khz64KBitRateMonoMp3\";\n    /**\n     * audio-24khz-48kbitrate-mono-mp3\n     * @member SpeechSynthesisOutputFormat.Audio24Khz48KBitRateMonoMp3\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Audio24Khz48KBitRateMonoMp3\"] = 6] = \"Audio24Khz48KBitRateMonoMp3\";\n    /**\n     * audio-24khz-96kbitrate-mono-mp3\n     * @member SpeechSynthesisOutputFormat.Audio24Khz96KBitRateMonoMp3\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Audio24Khz96KBitRateMonoMp3\"] = 7] = \"Audio24Khz96KBitRateMonoMp3\";\n    /**\n     * audio-24khz-160kbitrate-mono-mp3\n     * @member SpeechSynthesisOutputFormat.Audio24Khz160KBitRateMonoMp3\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Audio24Khz160KBitRateMonoMp3\"] = 8] = \"Audio24Khz160KBitRateMonoMp3\";\n    /**\n     * raw-16khz-16bit-mono-truesilk\n     * @member SpeechSynthesisOutputFormat.Raw16Khz16BitMonoTrueSilk\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Raw16Khz16BitMonoTrueSilk\"] = 9] = \"Raw16Khz16BitMonoTrueSilk\";\n    /**\n     * riff-16khz-16bit-mono-pcm\n     * @member SpeechSynthesisOutputFormat.Riff16Khz16BitMonoPcm\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Riff16Khz16BitMonoPcm\"] = 10] = \"Riff16Khz16BitMonoPcm\";\n    /**\n     * riff-8khz-16bit-mono-pcm\n     * @member SpeechSynthesisOutputFormat.Riff8Khz16BitMonoPcm\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Riff8Khz16BitMonoPcm\"] = 11] = \"Riff8Khz16BitMonoPcm\";\n    /**\n     * riff-24khz-16bit-mono-pcm\n     * @member SpeechSynthesisOutputFormat.Riff24Khz16BitMonoPcm\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Riff24Khz16BitMonoPcm\"] = 12] = \"Riff24Khz16BitMonoPcm\";\n    /**\n     * riff-8khz-8bit-mono-mulaw\n     * @member SpeechSynthesisOutputFormat.Riff8Khz8BitMonoMULaw\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Riff8Khz8BitMonoMULaw\"] = 13] = \"Riff8Khz8BitMonoMULaw\";\n    /**\n     * raw-16khz-16bit-mono-pcm\n     * @member SpeechSynthesisOutputFormat.Raw16Khz16BitMonoPcm\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Raw16Khz16BitMonoPcm\"] = 14] = \"Raw16Khz16BitMonoPcm\";\n    /**\n     * raw-24khz-16bit-mono-pcm\n     * @member SpeechSynthesisOutputFormat.Raw24Khz16BitMonoPcm\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Raw24Khz16BitMonoPcm\"] = 15] = \"Raw24Khz16BitMonoPcm\";\n    /**\n     * raw-8khz-16bit-mono-pcm\n     * @member SpeechSynthesisOutputFormat.Raw8Khz16BitMonoPcm\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Raw8Khz16BitMonoPcm\"] = 16] = \"Raw8Khz16BitMonoPcm\";\n    /**\n     * ogg-16khz-16bit-mono-opus\n     * @member SpeechSynthesisOutputFormat.Ogg16Khz16BitMonoOpus\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Ogg16Khz16BitMonoOpus\"] = 17] = \"Ogg16Khz16BitMonoOpus\";\n    /**\n     * ogg-24khz-16bit-mono-opus\n     * @member SpeechSynthesisOutputFormat.Ogg24Khz16BitMonoOpus\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Ogg24Khz16BitMonoOpus\"] = 18] = \"Ogg24Khz16BitMonoOpus\";\n    /**\n     * raw-48khz-16bit-mono-pcm\n     * @member SpeechSynthesisOutputFormat.Raw48Khz16BitMonoPcm\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Raw48Khz16BitMonoPcm\"] = 19] = \"Raw48Khz16BitMonoPcm\";\n    /**\n     * riff-48khz-16bit-mono-pcm\n     * @member SpeechSynthesisOutputFormat.Riff48Khz16BitMonoPcm\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Riff48Khz16BitMonoPcm\"] = 20] = \"Riff48Khz16BitMonoPcm\";\n    /**\n     * audio-48khz-96kbitrate-mono-mp3\n     * @member SpeechSynthesisOutputFormat.Audio48Khz96KBitRateMonoMp3\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Audio48Khz96KBitRateMonoMp3\"] = 21] = \"Audio48Khz96KBitRateMonoMp3\";\n    /**\n     * audio-48khz-192kbitrate-mono-mp3\n     * @member SpeechSynthesisOutputFormat.Audio48Khz192KBitRateMonoMp3\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Audio48Khz192KBitRateMonoMp3\"] = 22] = \"Audio48Khz192KBitRateMonoMp3\";\n    /**\n     * ogg-48khz-16bit-mono-opus\n     * Added in version 1.16.0\n     * @member SpeechSynthesisOutputFormat.Ogg48Khz16BitMonoOpus\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Ogg48Khz16BitMonoOpus\"] = 23] = \"Ogg48Khz16BitMonoOpus\";\n    /**\n     * webm-16khz-16bit-mono-opus\n     * Added in version 1.16.0\n     * @member SpeechSynthesisOutputFormat.Webm16Khz16BitMonoOpus\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Webm16Khz16BitMonoOpus\"] = 24] = \"Webm16Khz16BitMonoOpus\";\n    /**\n     * webm-24khz-16bit-mono-opus\n     * Added in version 1.16.0\n     * @member SpeechSynthesisOutputFormat.Webm24Khz16BitMonoOpus\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Webm24Khz16BitMonoOpus\"] = 25] = \"Webm24Khz16BitMonoOpus\";\n    /**\n     * raw-24khz-16bit-mono-truesilk\n     * Added in version 1.17.0\n     * @member SpeechSynthesisOutputFormat.Raw24Khz16BitMonoTrueSilk\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Raw24Khz16BitMonoTrueSilk\"] = 26] = \"Raw24Khz16BitMonoTrueSilk\";\n    /**\n     * raw-8khz-8bit-mono-alaw\n     * Added in version 1.17.0\n     * @member SpeechSynthesisOutputFormat.Raw8Khz8BitMonoALaw\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Raw8Khz8BitMonoALaw\"] = 27] = \"Raw8Khz8BitMonoALaw\";\n    /**\n     * riff-8khz-8bit-mono-alaw\n     * Added in version 1.17.0\n     * @member SpeechSynthesisOutputFormat.Riff8Khz8BitMonoALaw\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Riff8Khz8BitMonoALaw\"] = 28] = \"Riff8Khz8BitMonoALaw\";\n    /**\n     * webm-24khz-16bit-24kbps-mono-opus\n     * Audio compressed by OPUS codec in a webm container, with bitrate of 24kbps, optimized for IoT scenario.\n     * Added in version 1.19.0\n     * @member SpeechSynthesisOutputFormat.Webm24Khz16Bit24KbpsMonoOpus\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Webm24Khz16Bit24KbpsMonoOpus\"] = 29] = \"Webm24Khz16Bit24KbpsMonoOpus\";\n    /**\n     * audio-16khz-16bit-32kbps-mono-opus\n     * Audio compressed by OPUS codec without container, with bitrate of 32kbps.\n     * Added in version 1.20.0\n     * @member SpeechSynthesisOutputFormat.Audio16Khz16Bit32KbpsMonoOpus\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Audio16Khz16Bit32KbpsMonoOpus\"] = 30] = \"Audio16Khz16Bit32KbpsMonoOpus\";\n    /**\n     * audio-24khz-16bit-48kbps-mono-opus\n     * Audio compressed by OPUS codec without container, with bitrate of 48kbps.\n     * Added in version 1.20.0\n     * @member SpeechSynthesisOutputFormat.Audio24Khz16Bit48KbpsMonoOpus\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Audio24Khz16Bit48KbpsMonoOpus\"] = 31] = \"Audio24Khz16Bit48KbpsMonoOpus\";\n    /**\n     * audio-24khz-16bit-24kbps-mono-opus\n     * Audio compressed by OPUS codec without container, with bitrate of 24kbps.\n     * Added in version 1.20.0\n     * @member SpeechSynthesisOutputFormat.Audio24Khz16Bit24KbpsMonoOpus\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Audio24Khz16Bit24KbpsMonoOpus\"] = 32] = \"Audio24Khz16Bit24KbpsMonoOpus\";\n    /**\n     * raw-22050hz-16bit-mono-pcm\n     * Raw PCM audio at 22050Hz sampling rate and 16-bit depth.\n     * Added in version 1.22.0\n     * @member SpeechSynthesisOutputFormat.Raw22050Hz16BitMonoPcm\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Raw22050Hz16BitMonoPcm\"] = 33] = \"Raw22050Hz16BitMonoPcm\";\n    /**\n     * riff-22050hz-16bit-mono-pcm\n     * PCM audio at 22050Hz sampling rate and 16-bit depth, with RIFF header.\n     * Added in version 1.22.0\n     * @member SpeechSynthesisOutputFormat.Riff22050Hz16BitMonoPcm\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Riff22050Hz16BitMonoPcm\"] = 34] = \"Riff22050Hz16BitMonoPcm\";\n    /**\n     * raw-44100hz-16bit-mono-pcm\n     * Raw PCM audio at 44100Hz sampling rate and 16-bit depth.\n     * Added in version 1.22.0\n     * @member SpeechSynthesisOutputFormat.Raw44100Hz16BitMonoPcm\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Raw44100Hz16BitMonoPcm\"] = 35] = \"Raw44100Hz16BitMonoPcm\";\n    /**\n     * riff-44100hz-16bit-mono-pcm\n     * PCM audio at 44100Hz sampling rate and 16-bit depth, with RIFF header.\n     * Added in version 1.22.0\n     * @member SpeechSynthesisOutputFormat.Riff44100Hz16BitMonoPcm\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Riff44100Hz16BitMonoPcm\"] = 36] = \"Riff44100Hz16BitMonoPcm\";\n})(SpeechSynthesisOutputFormat || (SpeechSynthesisOutputFormat = {}));\n\n//# sourceMappingURL=SpeechSynthesisOutputFormat.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisOutputFormat.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisResult.js":
  /*!*************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisResult.js ***!
    \*************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SpeechSynthesisResult\": () => (/* binding */ SpeechSynthesisResult)\n/* harmony export */ });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SynthesisResult.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Defines result of speech synthesis.\n * @class SpeechSynthesisResult\n * Added in version 1.11.0\n */\nclass SpeechSynthesisResult extends _Exports__WEBPACK_IMPORTED_MODULE_0__.SynthesisResult {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {string} resultId - The result id.\n     * @param {ResultReason} reason - The reason.\n     * @param {ArrayBuffer} audioData - The synthesized audio binary.\n     * @param {string} errorDetails - Error details, if provided.\n     * @param {PropertyCollection} properties - Additional properties, if provided.\n     * @param {number} audioDuration - The audio duration.\n     */\n    constructor(resultId, reason, audioData, errorDetails, properties, audioDuration) {\n        super(resultId, reason, errorDetails, properties);\n        this.privAudioData = audioData;\n        this.privAudioDuration = audioDuration;\n    }\n    /**\n     * The synthesized audio data\n     * @member SpeechSynthesisResult.prototype.audioData\n     * @function\n     * @public\n     * @returns {ArrayBuffer} The synthesized audio data.\n     */\n    get audioData() {\n        return this.privAudioData;\n    }\n    /**\n     * The time duration of synthesized audio, in ticks (100 nanoseconds).\n     * @member SpeechSynthesisResult.prototype.audioDuration\n     * @function\n     * @public\n     * @returns {number} The time duration of synthesized audio.\n     */\n    get audioDuration() {\n        return this.privAudioDuration;\n    }\n}\n\n//# sourceMappingURL=SpeechSynthesisResult.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisResult.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisVisemeEventArgs.js":
  /*!**********************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisVisemeEventArgs.js ***!
    \**********************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SpeechSynthesisVisemeEventArgs\": () => (/* binding */ SpeechSynthesisVisemeEventArgs)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines contents of speech synthesis viseme event.\n * @class SpeechSynthesisVisemeEventArgs\n * Added in version 1.16.0\n */\nclass SpeechSynthesisVisemeEventArgs {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {number} audioOffset - The audio offset.\n     * @param {number} visemeId - The viseme ID.\n     * @param {string} animation - The animation, could be in svg or other format.\n     */\n    constructor(audioOffset, visemeId, animation) {\n        this.privAudioOffset = audioOffset;\n        this.privVisemeId = visemeId;\n        this.privAnimation = animation;\n    }\n    /**\n     * Specifies the audio offset.\n     * @member SpeechSynthesisVisemeEventArgs.prototype.audioOffset\n     * @function\n     * @public\n     * @returns {number} the audio offset.\n     */\n    get audioOffset() {\n        return this.privAudioOffset;\n    }\n    /**\n     * Specifies the viseme ID.\n     * @member SpeechSynthesisVisemeEventArgs.prototype.visemeId\n     * @function\n     * @public\n     * @returns {number} the viseme ID.\n     */\n    get visemeId() {\n        return this.privVisemeId;\n    }\n    /**\n     * Specifies the animation.\n     * @member SpeechSynthesisVisemeEventArgs.prototype.animation\n     * @function\n     * @public\n     * @returns {string} the animation, could be in svg or other format.\n     */\n    get animation() {\n        return this.privAnimation;\n    }\n}\n\n//# sourceMappingURL=SpeechSynthesisVisemeEventArgs.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisVisemeEventArgs.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisWordBoundaryEventArgs.js":
  /*!****************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisWordBoundaryEventArgs.js ***!
    \****************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SpeechSynthesisWordBoundaryEventArgs\": () => (/* binding */ SpeechSynthesisWordBoundaryEventArgs)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines contents of speech synthesis word boundary event.\n * @class SpeechSynthesisWordBoundaryEventArgs\n * Added in version 1.11.0\n */\nclass SpeechSynthesisWordBoundaryEventArgs {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {number} audioOffset - The audio offset.\n     * @param {number} duration - The audio duration.\n     * @param {string} text - The text.\n     * @param {number} wordLength - The length of the word.\n     * @param {number} textOffset - The text offset.\n     * @param {SpeechSynthesisBoundaryType} boundaryType - The boundary type\n     */\n    constructor(audioOffset, duration, text, wordLength, textOffset, boundaryType) {\n        this.privAudioOffset = audioOffset;\n        this.privDuration = duration;\n        this.privText = text;\n        this.privWordLength = wordLength;\n        this.privTextOffset = textOffset;\n        this.privBoundaryType = boundaryType;\n    }\n    /**\n     * Specifies the audio offset.\n     * @member SpeechSynthesisWordBoundaryEventArgs.prototype.audioOffset\n     * @function\n     * @public\n     * @returns {number} the audio offset.\n     */\n    get audioOffset() {\n        return this.privAudioOffset;\n    }\n    /**\n     * Specifies the duration, in ticks (100 nanoseconds).\n     * @member SpeechSynthesisWordBoundaryEventArgs.prototype.duration\n     * @function\n     * @public\n     * @returns {number} Duration in 100 nanosecond increments.\n     */\n    get duration() {\n        return this.privDuration;\n    }\n    /**\n     * Specifies the text of the word boundary event.\n     * @member SpeechSynthesisWordBoundaryEventArgs.prototype.text\n     * @function\n     * @public\n     * @returns {string} the text.\n     */\n    get text() {\n        return this.privText;\n    }\n    /**\n     * Specifies the word length\n     * @member SpeechSynthesisWordBoundaryEventArgs.prototype.wordLength\n     * @function\n     * @public\n     * @returns {number} the word length\n     */\n    get wordLength() {\n        return this.privWordLength;\n    }\n    /**\n     * Specifies the text offset.\n     * @member SpeechSynthesisWordBoundaryEventArgs.prototype.textOffset\n     * @function\n     * @public\n     * @returns {number} the text offset.\n     */\n    get textOffset() {\n        return this.privTextOffset;\n    }\n    /**\n     * Specifies the boundary type.\n     * @member SpeechSynthesisWordBoundaryEventArgs.prototype.boundaryType\n     * @function\n     * @public\n     * @returns {SpeechSynthesisBoundaryType} the boundary type.\n     */\n    get boundaryType() {\n        return this.privBoundaryType;\n    }\n}\n\n//# sourceMappingURL=SpeechSynthesisWordBoundaryEventArgs.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisWordBoundaryEventArgs.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SynthesisResult.js":
  /*!*******************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SynthesisResult.js ***!
    \*******************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SynthesisResult\": () => (/* binding */ SynthesisResult)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Base class for synthesis results\n * @class SynthesisResult\n * Added in version 1.20.0\n */\nclass SynthesisResult {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {string} resultId - The result id.\n     * @param {ResultReason} reason - The reason.\n     * @param {string} errorDetails - Error details, if provided.\n     * @param {PropertyCollection} properties - Additional properties, if provided.\n     */\n    constructor(resultId, reason, errorDetails, properties) {\n        this.privResultId = resultId;\n        this.privReason = reason;\n        this.privErrorDetails = errorDetails;\n        this.privProperties = properties;\n    }\n    /**\n     * Specifies the result identifier.\n     * @member SynthesisResult.prototype.resultId\n     * @function\n     * @public\n     * @returns {string} Specifies the result identifier.\n     */\n    get resultId() {\n        return this.privResultId;\n    }\n    /**\n     * Specifies status of the result.\n     * @member SynthesisResult.prototype.reason\n     * @function\n     * @public\n     * @returns {ResultReason} Specifies status of the result.\n     */\n    get reason() {\n        return this.privReason;\n    }\n    /**\n     * In case of an unsuccessful synthesis, provides details of the occurred error.\n     * @member SynthesisResult.prototype.errorDetails\n     * @function\n     * @public\n     * @returns {string} a brief description of an error.\n     */\n    get errorDetails() {\n        return this.privErrorDetails;\n    }\n    /**\n     * The set of properties exposed in the result.\n     * @member SynthesisResult.prototype.properties\n     * @function\n     * @public\n     * @returns {PropertyCollection} The set of properties exposed in the result.\n     */\n    get properties() {\n        return this.privProperties;\n    }\n}\n\n//# sourceMappingURL=SynthesisResult.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SynthesisResult.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationExpirationEventArgs.js":
  /*!*************************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationExpirationEventArgs.js ***!
    \*************************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConversationExpirationEventArgs\": () => (/* binding */ ConversationExpirationEventArgs)\n/* harmony export */ });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SessionEventArgs.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n// Multi-device Conversation is a Preview feature.\n\nclass ConversationExpirationEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__.SessionEventArgs {\n    constructor(expirationTime, sessionId) {\n        super(sessionId);\n        this.privExpirationTime = expirationTime;\n    }\n    /** How much longer until the conversation expires (in minutes). */\n    get expirationTime() {\n        return this.privExpirationTime;\n    }\n}\n\n//# sourceMappingURL=ConversationExpirationEventArgs.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationExpirationEventArgs.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationCanceledEventArgs.js":
  /*!**********************************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationCanceledEventArgs.js ***!
    \**********************************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConversationTranslationCanceledEventArgs\": () => (/* binding */ ConversationTranslationCanceledEventArgs)\n/* harmony export */ });\n/* harmony import */ var _CancellationEventArgsBase__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../CancellationEventArgsBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationEventArgsBase.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n// Multi-device Conversation is a Preview feature.\n\nclass ConversationTranslationCanceledEventArgs extends _CancellationEventArgsBase__WEBPACK_IMPORTED_MODULE_0__.CancellationEventArgsBase {\n}\n\n//# sourceMappingURL=ConversationTranslationCanceledEventArgs.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationCanceledEventArgs.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationResult.js":
  /*!***********************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationResult.js ***!
    \***********************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConversationTranslationResult\": () => (/* binding */ ConversationTranslationResult)\n/* harmony export */ });\n/* harmony import */ var _TranslationRecognitionResult__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../TranslationRecognitionResult */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionResult.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n// Multi-device Conversation is a Preview feature.\n\nclass ConversationTranslationResult extends _TranslationRecognitionResult__WEBPACK_IMPORTED_MODULE_0__.TranslationRecognitionResult {\n    constructor(participantId, translations, originalLanguage, resultId, reason, text, duration, offset, errorDetails, json, properties) {\n        super(translations, resultId, reason, text, duration, offset, errorDetails, json, properties);\n        this.privId = participantId;\n        this.privOrigLang = originalLanguage;\n    }\n    /**\n     * The unique identifier for the participant this result is for.\n     */\n    get participantId() {\n        return this.privId;\n    }\n    /**\n     * The original language this result was in.\n     */\n    get originalLang() {\n        return this.privOrigLang;\n    }\n}\n\n//# sourceMappingURL=ConversationTranslationResult.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationResult.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionCanceledEventArgs.js":
  /*!*******************************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionCanceledEventArgs.js ***!
    \*******************************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"TranslationRecognitionCanceledEventArgs\": () => (/* binding */ TranslationRecognitionCanceledEventArgs)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Define payload of speech recognition canceled result events.\n * @class TranslationRecognitionCanceledEventArgs\n */\nclass TranslationRecognitionCanceledEventArgs {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {string} sessionid - The session id.\n     * @param {CancellationReason} cancellationReason - The cancellation reason.\n     * @param {string} errorDetails - Error details, if provided.\n     * @param {TranslationRecognitionResult} result - The result.\n     */\n    constructor(sessionid, cancellationReason, errorDetails, errorCode, result) {\n        this.privCancelReason = cancellationReason;\n        this.privErrorDetails = errorDetails;\n        this.privResult = result;\n        this.privSessionId = sessionid;\n        this.privErrorCode = errorCode;\n    }\n    /**\n     * Specifies the recognition result.\n     * @member TranslationRecognitionCanceledEventArgs.prototype.result\n     * @function\n     * @public\n     * @returns {TranslationRecognitionResult} the recognition result.\n     */\n    get result() {\n        return this.privResult;\n    }\n    /**\n     * Specifies the session identifier.\n     * @member TranslationRecognitionCanceledEventArgs.prototype.sessionId\n     * @function\n     * @public\n     * @returns {string} the session identifier.\n     */\n    get sessionId() {\n        return this.privSessionId;\n    }\n    /**\n     * The reason the recognition was canceled.\n     * @member TranslationRecognitionCanceledEventArgs.prototype.reason\n     * @function\n     * @public\n     * @returns {CancellationReason} Specifies the reason canceled.\n     */\n    get reason() {\n        return this.privCancelReason;\n    }\n    /**\n     * The error code in case of an unsuccessful recognition.\n     * Added in version 1.1.0.\n     * @return An error code that represents the error reason.\n     */\n    get errorCode() {\n        return this.privErrorCode;\n    }\n    /**\n     * In case of an unsuccessful recognition, provides details of the occurred error.\n     * @member TranslationRecognitionCanceledEventArgs.prototype.errorDetails\n     * @function\n     * @public\n     * @returns {string} A String that represents the error details.\n     */\n    get errorDetails() {\n        return this.privErrorDetails;\n    }\n}\n\n//# sourceMappingURL=TranslationRecognitionCanceledEventArgs.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionCanceledEventArgs.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionEventArgs.js":
  /*!***********************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionEventArgs.js ***!
    \***********************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"TranslationRecognitionEventArgs\": () => (/* binding */ TranslationRecognitionEventArgs)\n/* harmony export */ });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionEventArgs.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Translation text result event arguments.\n * @class TranslationRecognitionEventArgs\n */\nclass TranslationRecognitionEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__.RecognitionEventArgs {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {TranslationRecognitionResult} result - The translation recognition result.\n     * @param {number} offset - The offset.\n     * @param {string} sessionId - The session id.\n     */\n    constructor(result, offset, sessionId) {\n        super(offset, sessionId);\n        this.privResult = result;\n    }\n    /**\n     * Specifies the recognition result.\n     * @member TranslationRecognitionEventArgs.prototype.result\n     * @function\n     * @public\n     * @returns {TranslationRecognitionResult} the recognition result.\n     */\n    get result() {\n        return this.privResult;\n    }\n}\n\n//# sourceMappingURL=TranslationRecognitionEventArgs.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionEventArgs.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionResult.js":
  /*!********************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionResult.js ***!
    \********************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"TranslationRecognitionResult\": () => (/* binding */ TranslationRecognitionResult)\n/* harmony export */ });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionResult.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Translation text result.\n * @class TranslationRecognitionResult\n */\nclass TranslationRecognitionResult extends _Exports__WEBPACK_IMPORTED_MODULE_0__.SpeechRecognitionResult {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {Translations} translations - The translations.\n     * @param {string} resultId - The result id.\n     * @param {ResultReason} reason - The reason.\n     * @param {string} text - The recognized text.\n     * @param {number} duration - The duration.\n     * @param {number} offset - The offset into the stream.\n     * @param {string} errorDetails - Error details, if provided.\n     * @param {string} json - Additional Json, if provided.\n     * @param {PropertyCollection} properties - Additional properties, if provided.\n     */\n    constructor(translations, resultId, reason, text, duration, offset, errorDetails, json, properties) {\n        super(resultId, reason, text, duration, offset, undefined, undefined, undefined, errorDetails, json, properties);\n        this.privTranslations = translations;\n    }\n    static fromSpeechRecognitionResult(result) {\n        return new TranslationRecognitionResult(undefined, result.resultId, result.reason, result.text, result.duration, result.offset, result.errorDetails, result.json, result.properties);\n    }\n    /**\n     * Presents the translation results. Each item in the dictionary represents\n     * a translation result in one of target languages, where the key is the name\n     * of the target language, in BCP-47 format, and the value is the translation\n     * text in the specified language.\n     * @member TranslationRecognitionResult.prototype.translations\n     * @function\n     * @public\n     * @returns {Translations} the current translation map that holds all translations requested.\n     */\n    get translations() {\n        return this.privTranslations;\n    }\n}\n\n//# sourceMappingURL=TranslationRecognitionResult.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionResult.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationSynthesisEventArgs.js":
  /*!*********************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationSynthesisEventArgs.js ***!
    \*********************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"TranslationSynthesisEventArgs\": () => (/* binding */ TranslationSynthesisEventArgs)\n/* harmony export */ });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SessionEventArgs.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Translation Synthesis event arguments\n * @class TranslationSynthesisEventArgs\n */\nclass TranslationSynthesisEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__.SessionEventArgs {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {TranslationSynthesisResult} result - The translation synthesis result.\n     * @param {string} sessionId - The session id.\n     */\n    constructor(result, sessionId) {\n        super(sessionId);\n        this.privResult = result;\n    }\n    /**\n     * Specifies the translation synthesis result.\n     * @member TranslationSynthesisEventArgs.prototype.result\n     * @function\n     * @public\n     * @returns {TranslationSynthesisResult} Specifies the translation synthesis result.\n     */\n    get result() {\n        return this.privResult;\n    }\n}\n\n//# sourceMappingURL=TranslationSynthesisEventArgs.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationSynthesisEventArgs.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationSynthesisResult.js":
  /*!******************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationSynthesisResult.js ***!
    \******************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"TranslationSynthesisResult\": () => (/* binding */ TranslationSynthesisResult)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines translation synthesis result, i.e. the voice output of the translated\n * text in the target language.\n * @class TranslationSynthesisResult\n */\nclass TranslationSynthesisResult {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {ResultReason} reason - The synthesis reason.\n     * @param {ArrayBuffer} audio - The audio data.\n     */\n    constructor(reason, audio) {\n        this.privReason = reason;\n        this.privAudio = audio;\n    }\n    /**\n     * Translated text in the target language.\n     * @member TranslationSynthesisResult.prototype.audio\n     * @function\n     * @public\n     * @returns {ArrayBuffer} Translated audio in the target language.\n     */\n    get audio() {\n        return this.privAudio;\n    }\n    /**\n     * The synthesis status.\n     * @member TranslationSynthesisResult.prototype.reason\n     * @function\n     * @public\n     * @returns {ResultReason} The synthesis status.\n     */\n    get reason() {\n        return this.privReason;\n    }\n}\n\n//# sourceMappingURL=TranslationSynthesisResult.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationSynthesisResult.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Translations.js":
  /*!****************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Translations.js ***!
    \****************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Translations\": () => (/* binding */ Translations)\n/* harmony export */ });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Represents collection of parameters and their values.\n * @class Translations\n */\nclass Translations {\n    constructor() {\n        // Use an PropertyCollection internally, just wrapping it to hide the | enum syntax it has.\n        this.privMap = new _Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyCollection();\n    }\n    /**\n     * Get the languages in the object in a String array.\n     * @member Translations.prototype.languages\n     * @function\n     * @public\n     * @returns {string[]} languages in translations object.\n     */\n    get languages() {\n        return this.privMap.keys;\n    }\n    /**\n     * Returns the parameter value in type String. The parameter must have the same type as String.\n     * Currently only String, int and bool are allowed.\n     * If the name is not available, the specified defaultValue is returned.\n     * @member Translations.prototype.get\n     * @function\n     * @public\n     * @param {string} key - The parameter name.\n     * @param {string} def - The default value which is returned if the parameter is not available in the collection.\n     * @returns {string} value of the parameter.\n     */\n    get(key, def) {\n        return this.privMap.getProperty(key, def);\n    }\n    /**\n     * Sets the String value of the parameter specified by name.\n     * @member Translations.prototype.set\n     * @function\n     * @public\n     * @param {string} key - The parameter name.\n     * @param {string} value - The value of the parameter.\n     */\n    set(key, value) {\n        this.privMap.setProperty(key, value);\n    }\n}\n\n//# sourceMappingURL=Translations.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Translations.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TurnStatusReceivedEventArgs.js":
  /*!*******************************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TurnStatusReceivedEventArgs.js ***!
    \*******************************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"TurnStatusReceivedEventArgs\": () => (/* binding */ TurnStatusReceivedEventArgs)\n/* harmony export */ });\n/* harmony import */ var _common_speech_ServiceMessages_TurnStatusPayload__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.speech/ServiceMessages/TurnStatusPayload */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TurnStatusPayload.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Defines contents of received message/events.\n * @class TurnStatusReceivedEventArgs\n */\nclass TurnStatusReceivedEventArgs {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {string} turnStatus - The JSON-encoded turn status message.\n     */\n    constructor(turnStatus) {\n        this.privTurnStatus = _common_speech_ServiceMessages_TurnStatusPayload__WEBPACK_IMPORTED_MODULE_0__.TurnStatusResponsePayload.fromJSON(turnStatus);\n    }\n    /**\n     * Gets the interaction identifier associated with this turn status event.\n     * @member TurnStatusReceivedEventArgs.prototype.interactionId\n     * @function\n     * @public\n     * @returns {any} the received interaction id.\n     */\n    get interactionId() {\n        return this.privTurnStatus.interactionId;\n    }\n    /**\n     * Gets the conversation identifier associated with this turn status event.\n     * @member TurnStatusReceivedEventArgs.prototype.conversationId\n     * @function\n     * @public\n     * @returns {any} the received conversation id.\n     */\n    get conversationId() {\n        return this.privTurnStatus.conversationId;\n    }\n    /**\n     * Gets the received turn status code.\n     * @member TurnStatusReceivedEventArgs.prototype.statusCode\n     * @function\n     * @public\n     * @returns {number} the received turn status.\n     */\n    get statusCode() {\n        return this.privTurnStatus.statusCode; // eslint-disable-line @typescript-eslint/no-unsafe-return\n    }\n}\n\n//# sourceMappingURL=TurnStatusReceivedEventArgs.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TurnStatusReceivedEventArgs.js?");
  
  /***/ }),
  
  /***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileType.js":
  /*!********************************************************************************************************!*\
    !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileType.js ***!
    \********************************************************************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"VoiceProfileType\": () => (/* binding */ VoiceProfileType)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Output format\n * @class VoiceProfileType\n */\nvar VoiceProfileType;\n(function (VoiceProfileType) {\n    /**\n     * Text independent speaker identification\n     * @member VoiceProfileType.TextIndependentIdentification\n     */\n    VoiceProfileType[VoiceProfileType[\"TextIndependentIdentification\"] = 0] = \"TextIndependentIdentification\";\n    /**\n     * Text dependent speaker verification\n     * @member VoiceProfileType.TextDependentVerification\n     */\n    VoiceProfileType[VoiceProfileType[\"TextDependentVerification\"] = 1] = \"TextDependentVerification\";\n    /**\n     * Text independent speaker verification\n     * @member VoiceProfileType.TextIndependentVerification\n     */\n    VoiceProfileType[VoiceProfileType[\"TextIndependentVerification\"] = 2] = \"TextIndependentVerification\";\n})(VoiceProfileType || (VoiceProfileType = {}));\n\n//# sourceMappingURL=VoiceProfileType.js.map\n\n\n//# sourceURL=webpack://speech/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileType.js?");
  
  /***/ }),
  
  /***/ "./src/assets/microphone-disabled.svg":
  /*!********************************************!*\
    !*** ./src/assets/microphone-disabled.svg ***!
    \********************************************/
  /***/ ((module) => {
  
  eval("module.exports = \"<svg viewBox=\\\"0 0 24 24\\\" fill=\\\"none\\\" xmlns=\\\"http://www.w3.org/2000/svg\\\"><path d=\\\"M9.40137 4.5C9.92008 3.6033 10.8896 3 12 3C13.6569 3 15 4.34315 15 6V10M18 12C18 12.3407 17.9716 12.6748 17.9171 13M3 3L21 21M12 18C8.68629 18 6 15.3137 6 12M12 18C12.3407 18 12.6748 17.9716 13 17.917M12 18V21M12 21H15M12 21H9\\\" stroke=\\\"#000000\\\" stroke-width=\\\"1.5\\\" stroke-linecap=\\\"round\\\" stroke-linejoin=\\\"round\\\"></path></svg>\"\n\n//# sourceURL=webpack://speech/./src/assets/microphone-disabled.svg?");
  
  /***/ }),
  
  /***/ "./src/assets/microphone.svg":
  /*!***********************************!*\
    !*** ./src/assets/microphone.svg ***!
    \***********************************/
  /***/ ((module) => {
  
  eval("module.exports = \"<svg viewBox=\\\"0 0 24 24\\\" fill=\\\"none\\\" xmlns=\\\"http://www.w3.org/2000/svg\\\"><path d=\\\"M18 12C18 15.3137 15.3137 18 12 18M12 18C8.68629 18 6 15.3137 6 12M12 18V21M12 21H15M12 21H9M15 6V12C15 13.6569 13.6569 15 12 15C10.3431 15 9 13.6569 9 12V6C9 4.34315 10.3431 3 12 3C13.6569 3 15 4.34315 15 6Z\\\" stroke=\\\"#000000\\\" stroke-width=\\\"1.5\\\" stroke-linecap=\\\"round\\\" stroke-linejoin=\\\"round\\\"></path></svg>\"\n\n//# sourceURL=webpack://speech/./src/assets/microphone.svg?");
  
  /***/ }),
  
  /***/ "./node_modules/uuid/dist/esm-browser/regex.js":
  /*!*****************************************************!*\
    !*** ./node_modules/uuid/dist/esm-browser/regex.js ***!
    \*****************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (/^(?:[0-9a-f]{8}-[0-9a-f]{4}-[1-5][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}|00000000-0000-0000-0000-000000000000)$/i);\n\n//# sourceURL=webpack://speech/./node_modules/uuid/dist/esm-browser/regex.js?");
  
  /***/ }),
  
  /***/ "./node_modules/uuid/dist/esm-browser/rng.js":
  /*!***************************************************!*\
    !*** ./node_modules/uuid/dist/esm-browser/rng.js ***!
    \***************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ rng)\n/* harmony export */ });\n// Unique ID creation requires a high quality random # generator. In the browser we therefore\n// require the crypto API and do not support built-in fallback to lower quality random number\n// generators (like Math.random()).\nvar getRandomValues;\nvar rnds8 = new Uint8Array(16);\nfunction rng() {\n  // lazy load so that environments that need to polyfill have a chance to do so\n  if (!getRandomValues) {\n    // getRandomValues needs to be invoked in a context where \"this\" is a Crypto implementation. Also,\n    // find the complete implementation of crypto (msCrypto) on IE11.\n    getRandomValues = typeof crypto !== 'undefined' && crypto.getRandomValues && crypto.getRandomValues.bind(crypto) || typeof msCrypto !== 'undefined' && typeof msCrypto.getRandomValues === 'function' && msCrypto.getRandomValues.bind(msCrypto);\n\n    if (!getRandomValues) {\n      throw new Error('crypto.getRandomValues() not supported. See https://github.com/uuidjs/uuid#getrandomvalues-not-supported');\n    }\n  }\n\n  return getRandomValues(rnds8);\n}\n\n//# sourceURL=webpack://speech/./node_modules/uuid/dist/esm-browser/rng.js?");
  
  /***/ }),
  
  /***/ "./node_modules/uuid/dist/esm-browser/stringify.js":
  /*!*********************************************************!*\
    !*** ./node_modules/uuid/dist/esm-browser/stringify.js ***!
    \*********************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _validate_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./validate.js */ \"./node_modules/uuid/dist/esm-browser/validate.js\");\n\n/**\n * Convert array of 16 byte values to UUID string format of the form:\n * XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX\n */\n\nvar byteToHex = [];\n\nfor (var i = 0; i < 256; ++i) {\n  byteToHex.push((i + 0x100).toString(16).substr(1));\n}\n\nfunction stringify(arr) {\n  var offset = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;\n  // Note: Be careful editing this code!  It's been tuned for performance\n  // and works in ways you may not expect. See https://github.com/uuidjs/uuid/pull/434\n  var uuid = (byteToHex[arr[offset + 0]] + byteToHex[arr[offset + 1]] + byteToHex[arr[offset + 2]] + byteToHex[arr[offset + 3]] + '-' + byteToHex[arr[offset + 4]] + byteToHex[arr[offset + 5]] + '-' + byteToHex[arr[offset + 6]] + byteToHex[arr[offset + 7]] + '-' + byteToHex[arr[offset + 8]] + byteToHex[arr[offset + 9]] + '-' + byteToHex[arr[offset + 10]] + byteToHex[arr[offset + 11]] + byteToHex[arr[offset + 12]] + byteToHex[arr[offset + 13]] + byteToHex[arr[offset + 14]] + byteToHex[arr[offset + 15]]).toLowerCase(); // Consistency check for valid UUID.  If this throws, it's likely due to one\n  // of the following:\n  // - One or more input array values don't map to a hex octet (leading to\n  // \"undefined\" in the uuid)\n  // - Invalid input values for the RFC `version` or `variant` fields\n\n  if (!(0,_validate_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(uuid)) {\n    throw TypeError('Stringified UUID is invalid');\n  }\n\n  return uuid;\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (stringify);\n\n//# sourceURL=webpack://speech/./node_modules/uuid/dist/esm-browser/stringify.js?");
  
  /***/ }),
  
  /***/ "./node_modules/uuid/dist/esm-browser/v4.js":
  /*!**************************************************!*\
    !*** ./node_modules/uuid/dist/esm-browser/v4.js ***!
    \**************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _rng_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./rng.js */ \"./node_modules/uuid/dist/esm-browser/rng.js\");\n/* harmony import */ var _stringify_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./stringify.js */ \"./node_modules/uuid/dist/esm-browser/stringify.js\");\n\n\n\nfunction v4(options, buf, offset) {\n  options = options || {};\n  var rnds = options.random || (options.rng || _rng_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(); // Per 4.4, set bits for version and `clock_seq_hi_and_reserved`\n\n  rnds[6] = rnds[6] & 0x0f | 0x40;\n  rnds[8] = rnds[8] & 0x3f | 0x80; // Copy bytes to buffer, if provided\n\n  if (buf) {\n    offset = offset || 0;\n\n    for (var i = 0; i < 16; ++i) {\n      buf[offset + i] = rnds[i];\n    }\n\n    return buf;\n  }\n\n  return (0,_stringify_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(rnds);\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (v4);\n\n//# sourceURL=webpack://speech/./node_modules/uuid/dist/esm-browser/v4.js?");
  
  /***/ }),
  
  /***/ "./node_modules/uuid/dist/esm-browser/validate.js":
  /*!********************************************************!*\
    !*** ./node_modules/uuid/dist/esm-browser/validate.js ***!
    \********************************************************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _regex_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./regex.js */ \"./node_modules/uuid/dist/esm-browser/regex.js\");\n\n\nfunction validate(uuid) {\n  return typeof uuid === 'string' && _regex_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].test(uuid);\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (validate);\n\n//# sourceURL=webpack://speech/./node_modules/uuid/dist/esm-browser/validate.js?");
  
  /***/ }),
  
  /***/ "./src/index.js":
  /*!**********************!*\
    !*** ./src/index.js ***!
    \**********************/
  /***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {
  
  "use strict";
  eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var microsoft_cognitiveservices_speech_sdk__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! microsoft-cognitiveservices-speech-sdk */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioConfig.js\");\n/* harmony import */ var microsoft_cognitiveservices_speech_sdk__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! microsoft-cognitiveservices-speech-sdk */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js\");\n/* harmony import */ var microsoft_cognitiveservices_speech_sdk__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! microsoft-cognitiveservices-speech-sdk */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationReason.js\");\n/* harmony import */ var microsoft_cognitiveservices_speech_sdk__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! microsoft-cognitiveservices-speech-sdk */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/NoMatchDetails.js\");\n/* harmony import */ var microsoft_cognitiveservices_speech_sdk__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! microsoft-cognitiveservices-speech-sdk */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/NoMatchReason.js\");\n/* harmony import */ var microsoft_cognitiveservices_speech_sdk__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! microsoft-cognitiveservices-speech-sdk */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationDetails.js\");\n/* harmony import */ var microsoft_cognitiveservices_speech_sdk__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! microsoft-cognitiveservices-speech-sdk */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var microsoft_cognitiveservices_speech_sdk__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! microsoft-cognitiveservices-speech-sdk */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentResult.js\");\n/* harmony import */ var microsoft_cognitiveservices_speech_sdk__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! microsoft-cognitiveservices-speech-sdk */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechConfig.js\");\n/* harmony import */ var microsoft_cognitiveservices_speech_sdk__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! microsoft-cognitiveservices-speech-sdk */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognizer.js\");\n/* harmony import */ var _assets_microphone_svg__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./assets/microphone.svg */ \"./src/assets/microphone.svg\");\n/* harmony import */ var _assets_microphone_svg__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_assets_microphone_svg__WEBPACK_IMPORTED_MODULE_0__);\n/* harmony import */ var _assets_microphone_disabled_svg__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./assets/microphone-disabled.svg */ \"./src/assets/microphone-disabled.svg\");\n/* harmony import */ var _assets_microphone_disabled_svg__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(_assets_microphone_disabled_svg__WEBPACK_IMPORTED_MODULE_1__);\n\n\n\n\n\nconst SUBSCRIPTION_KEY = \"f037ba1b409b4530a95d6e638bfe8638\";\nconst REGION = \"westeurope\";\nconst LANGUAGE = \"cs-CZ\";\n\n// TODO - implement\nconst useDetailedResults = false; // NOTE - probably shouldn't use\nconst statusDiv = document.createElement(\"div\");\nconst scenarioSelection = document.createElement(\"select\");\nscenarioSelection.value = \"speechRecognizerRecognizeOnce\";\nconst pronunciationAssessmentResults = [];\nconst thingsToDisableDuringSession = [];\nconst scenarioStartButton = document.createElement(\"button\");\nconst scenarioStopButton = document.createElement(\"button\");\nlet reco = undefined;\n// end TODO\n\nfunction main() {\n  const voiceButton = document.getElementById(\"123\");\n  const voiceButtonIcon = document.createElement(\"div\");\n  const targetInput = document.querySelector(\n    \".\" + voiceButton.getAttribute(\"data-input\")\n  );\n\n  const animateMicrophone = () => {\n    voiceButton.style.boxShadow = \"0 0 0 5px #ccc5\";\n\n    setTimeout(() => {\n      if (voiceButton?.style) {\n        voiceButton.style.boxShadow = \"none\";\n      }\n    }, [50]);\n  };\n\n  function getSpeechConfig(sdkConfigType) {\n    let speechConfig = sdkConfigType.fromSubscription(SUBSCRIPTION_KEY, REGION);\n\n    speechConfig.speechRecognitionLanguage = LANGUAGE;\n    return speechConfig;\n  }\n\n  function getAudioConfig() {\n    return microsoft_cognitiveservices_speech_sdk__WEBPACK_IMPORTED_MODULE_2__.AudioConfig.fromMicrophoneInput(\"Default Microphone\");\n    // return SpeechSDK.AudioConfig.fromDefaultMicrophoneInput();\n  }\n\n  function onRecognizing(sender, recognitionEventArgs) {\n    animateMicrophone();\n\n    var result = recognitionEventArgs.result;\n    statusDiv.innerHTML +=\n      `(recognizing) Reason: ${microsoft_cognitiveservices_speech_sdk__WEBPACK_IMPORTED_MODULE_3__.ResultReason[result.reason]}` +\n      ` Text: ${result.text}\\r\\n`;\n\n    // Update the hypothesis line in the phrase/result view (only have one)\n    targetInput.value = `${result.text} [...]\\r\\n`;\n\n    // targetInput.scrollTop = targetInput.scrollHeight;\n  }\n\n  function onRecognized(sender, recognitionEventArgs) {\n    var result = recognitionEventArgs.result;\n    onRecognizedResult(recognitionEventArgs.result);\n  }\n\n  function onCanceled(sender, cancellationEventArgs) {\n    window.console.log(cancellationEventArgs);\n\n    statusDiv.innerHTML +=\n      \"(cancel) Reason: \" +\n      microsoft_cognitiveservices_speech_sdk__WEBPACK_IMPORTED_MODULE_4__.CancellationReason[cancellationEventArgs.reason];\n    if (cancellationEventArgs.reason === microsoft_cognitiveservices_speech_sdk__WEBPACK_IMPORTED_MODULE_4__.CancellationReason.Error) {\n      statusDiv.innerHTML += \": \" + cancellationEventArgs.errorDetails;\n    }\n    statusDiv.innerHTML += \"\\r\\n\";\n  }\n\n  function onSessionStarted(sender, sessionEventArgs) {\n    indicateButtonRecording();\n\n    statusDiv.innerHTML += `(sessionStarted) SessionId: ${sessionEventArgs.sessionId}\\r\\n`;\n\n    for (const thingToDisableDuringSession of thingsToDisableDuringSession) {\n      thingToDisableDuringSession.disabled = true;\n    }\n\n    scenarioStartButton.disabled = true;\n    scenarioStopButton.disabled = false;\n  }\n\n  function onSessionStopped(sender, sessionEventArgs) {\n    indicateButtonReady();\n\n    statusDiv.innerHTML += `(sessionStopped) SessionId: ${sessionEventArgs.sessionId}\\r\\n`;\n\n    if (scenarioSelection.value == \"pronunciationAssessmentContinuous\") {\n      calculateOverallPronunciationScore();\n    }\n\n    for (const thingToDisableDuringSession of thingsToDisableDuringSession) {\n      thingToDisableDuringSession.disabled = false;\n    }\n\n    scenarioStartButton.disabled = false;\n    scenarioStopButton.disabled = true;\n  }\n\n  function applyCommonConfigurationTo(recognizer) {\n    // The 'recognizing' event signals that an intermediate recognition result is received.\n    // Intermediate results arrive while audio is being processed and represent the current \"best guess\" about\n    // what's been spoken so far.\n    recognizer.recognizing = onRecognizing;\n\n    // The 'recognized' event signals that a finalized recognition result has been received. These results are\n    // formed across complete utterance audio (with either silence or eof at the end) and will include\n    // punctuation, capitalization, and potentially other extra details.\n    //\n    // * In the case of continuous scenarios, these final results will be generated after each segment of audio\n    //   with sufficient silence at the end.\n    // * In the case of intent scenarios, only these final results will contain intent JSON data.\n    // * Single-shot scenarios can also use a continuation on recognizeOnceAsync calls to handle this without\n    //   event registration.\n    recognizer.recognized = onRecognized;\n\n    // The 'canceled' event signals that the service has stopped processing speech.\n    // https://docs.microsoft.com/javascript/api/microsoft-cognitiveservices-speech-sdk/speechrecognitioncanceledeventargs?view=azure-node-latest\n    // This can happen for two broad classes of reasons:\n    // 1. An error was encountered.\n    //    In this case, the .errorDetails property will contain a textual representation of the error.\n    // 2. No additional audio is available.\n    //    This is caused by the input stream being closed or reaching the end of an audio file.\n    recognizer.canceled = onCanceled;\n\n    // The 'sessionStarted' event signals that audio has begun flowing and an interaction with the service has\n    // started.\n    recognizer.sessionStarted = onSessionStarted;\n\n    // The 'sessionStopped' event signals that the current interaction with the speech service has ended and\n    // audio has stopped flowing.\n    recognizer.sessionStopped = onSessionStopped;\n  }\n\n  function onRecognizedResult(result) {\n    // targetInput.scrollTop = targetInput.scrollHeight;\n\n    if (\n      scenarioSelection.value === \"speechRecognizerRecognizeOnce\" ||\n      scenarioSelection.value === \"intentRecognizerRecognizeOnce\"\n    ) {\n      // Clear the final results view for single-shot scenarios\n      targetInput.innerHTML = \"\";\n    } else {\n      // Otherwise, just remove the ongoing hypothesis line\n      targetInput.innerHTML = targetInput.innerHTML.replace(\n        /(.*)(^|[\\r\\n]+).*\\[\\.\\.\\.\\][\\r\\n]+/,\n        \"$1$2\"\n      );\n    }\n\n    switch (result.reason) {\n      case microsoft_cognitiveservices_speech_sdk__WEBPACK_IMPORTED_MODULE_3__.ResultReason.NoMatch:\n        var noMatchDetail = microsoft_cognitiveservices_speech_sdk__WEBPACK_IMPORTED_MODULE_5__.NoMatchDetails.fromResult(result);\n        statusDiv.innerHTML += ` NoMatchReason: ${\n          microsoft_cognitiveservices_speech_sdk__WEBPACK_IMPORTED_MODULE_6__.NoMatchReason[noMatchDetail.reason]\n        }\\r\\n`;\n        break;\n      case microsoft_cognitiveservices_speech_sdk__WEBPACK_IMPORTED_MODULE_3__.ResultReason.Canceled:\n        var cancelDetails = microsoft_cognitiveservices_speech_sdk__WEBPACK_IMPORTED_MODULE_7__.CancellationDetails.fromResult(result);\n        statusDiv.innerHTML += ` CancellationReason: ${\n          microsoft_cognitiveservices_speech_sdk__WEBPACK_IMPORTED_MODULE_4__.CancellationReason[cancelDetails.reason]\n        }`;\n        +(cancelDetails.reason === microsoft_cognitiveservices_speech_sdk__WEBPACK_IMPORTED_MODULE_4__.CancellationReason.Error\n          ? `: ${cancelDetails.errorDetails}`\n          : ``) + `\\r\\n`;\n        break;\n      case microsoft_cognitiveservices_speech_sdk__WEBPACK_IMPORTED_MODULE_3__.ResultReason.RecognizedSpeech:\n      case microsoft_cognitiveservices_speech_sdk__WEBPACK_IMPORTED_MODULE_3__.ResultReason.TranslatedSpeech:\n      case microsoft_cognitiveservices_speech_sdk__WEBPACK_IMPORTED_MODULE_3__.ResultReason.RecognizedIntent:\n        statusDiv.innerHTML += `\\r\\n`;\n\n        if (useDetailedResults) {\n          var detailedResultJson = JSON.parse(result.json);\n\n          // Detailed result JSON includes substantial extra information:\n          //  detailedResultJson['NBest'] is an array of recognition alternates\n          //  detailedResultJson['NBest'][0] is the highest-confidence alternate\n          //  ...['Confidence'] is the raw confidence score of an alternate\n          //  ...['Lexical'] and others provide different result forms\n          var displayText = detailedResultJson[\"DisplayText\"];\n          targetInput.innerHTML +=\n            `Detailed result for \"${displayText}\":\\r\\n` +\n            `${JSON.stringify(detailedResultJson, null, 2)}\\r\\n`;\n        } else if (result.text) {\n          targetInput.value = result.text;\n        }\n\n        // NOTE - probably none of the below is being used\n        var intentJson = result.properties.getProperty(\n          microsoft_cognitiveservices_speech_sdk__WEBPACK_IMPORTED_MODULE_8__.PropertyId.LanguageUnderstandingServiceResponse_JsonResult\n        );\n\n        if (intentJson) {\n          console.info(\"unused functionality\");\n          targetInput.innerHTML += `${intentJson}\\r\\n`;\n        }\n\n        if (result.translations) {\n          console.info(\"unused functionality\");\n          var resultJson = JSON.parse(result.json);\n          resultJson[\"privTranslationPhrase\"][\"Translation\"][\n            \"Translations\"\n          ].forEach(function (translation) {\n            targetInput.innerHTML += ` [${translation.Language}] ${translation.Text}\\r\\n`;\n          });\n        }\n\n        if (scenarioSelection.value.includes(\"pronunciation\")) {\n          console.info(\"unused functionality\");\n          var pronunciationAssessmentResult =\n            microsoft_cognitiveservices_speech_sdk__WEBPACK_IMPORTED_MODULE_9__.PronunciationAssessmentResult.fromResult(result);\n          targetInput.innerHTML += `[Pronunciation result] Accuracy: ${pronunciationAssessmentResult.accuracyScore}; \n                       Fluency: ${pronunciationAssessmentResult.fluencyScore};\n                       Completeness: ${pronunciationAssessmentResult.completenessScore}.\\n`;\n          pronunciationAssessmentResults.push(pronunciationAssessmentResult);\n        }\n        break;\n    }\n  }\n\n  function doRecognizeOnceAsync() {\n    const audioConfig = getAudioConfig();\n\n    const speechConfig = getSpeechConfig(microsoft_cognitiveservices_speech_sdk__WEBPACK_IMPORTED_MODULE_10__.SpeechConfig);\n\n    if (!audioConfig || !speechConfig) return;\n\n    // Create the SpeechRecognizer and set up common event handlers and PhraseList data\n    reco = new microsoft_cognitiveservices_speech_sdk__WEBPACK_IMPORTED_MODULE_11__.SpeechRecognizer(speechConfig, audioConfig);\n    applyCommonConfigurationTo(reco);\n\n    // Note: in this scenario sample, the 'recognized' event is not being set to instead demonstrate\n    // continuation on the 'recognizeOnceAsync' call. 'recognized' can be set in much the same way as\n    // 'recognizing' if an event-driven approach is preferable.\n    reco.recognized = undefined;\n\n    // Note: this scenario sample demonstrates result handling via continuation on the recognizeOnceAsync call.\n    // The 'recognized' event handler can be used in a similar fashion.\n    reco.recognizeOnceAsync(\n      function (successfulResult) {\n        onRecognizedResult(successfulResult);\n      },\n      function (err) {\n        console.error(err);\n        targetInput.innerHTML += \"ERROR: \" + err;\n      }\n    );\n  }\n\n  // TODO\n  function enumerateMicrophones() {\n    if (\n      !navigator ||\n      !navigator.mediaDevices ||\n      !navigator.mediaDevices.enumerateDevices\n    ) {\n      console.log(\n        `Unable to query for audio input devices. Default will be used.\\r\\n`\n      );\n      return;\n    }\n\n    navigator.mediaDevices.enumerateDevices().then((devices) => {\n      microphoneSources.innerHTML = \"\";\n\n      // Not all environments will be able to enumerate mic labels and ids. All environments will be able\n      // to select a default input, assuming appropriate permissions.\n      var defaultOption = document.createElement(\"option\");\n      defaultOption.appendChild(document.createTextNode(\"Default Microphone\"));\n      microphoneSources.appendChild(defaultOption);\n\n      for (const device of devices) {\n        if (device.kind === \"audioinput\") {\n          if (!device.deviceId) {\n            window.console.log(\n              `Warning: unable to enumerate a microphone deviceId. This may be due to limitations` +\n                ` with availability in a non-HTTPS context per mediaDevices constraints.`\n            );\n          } else {\n            var opt = document.createElement(\"option\");\n            opt.value = device.deviceId;\n            opt.appendChild(document.createTextNode(device.label));\n\n            microphoneSources.appendChild(opt);\n          }\n        }\n      }\n\n      microphoneSources.disabled = microphoneSources.options.length == 1;\n    });\n  }\n\n  // const speechInit = (targetClassName) => {\n  //   const el = document.createElement(\"button\");\n\n  //   el.textContent = \"click and speak\";\n\n  //   el.onclick = () => {\n  //     doRecognizeOnceAsync();\n  //   };\n\n  //   return el;\n  // };\n\n  const indicateButtonReady = () => {\n    voiceButton.setAttribute(\"data-recording\", \"false\");\n    voiceButtonIcon.innerHTML = (_assets_microphone_disabled_svg__WEBPACK_IMPORTED_MODULE_1___default());\n  };\n\n  const indicateButtonRecording = () => {\n    voiceButton.setAttribute(\"data-recording\", \"true\");\n    voiceButtonIcon.innerHTML = (_assets_microphone_svg__WEBPACK_IMPORTED_MODULE_0___default());\n  };\n\n  const stopRecording = () => {\n    reco.close();\n    reco = undefined;\n  };\n\n  voiceButton.style = `width: 20px; height: 20px; border-radius: 20px; padding: 10px; background-color: #ccc5`;\n  voiceButton.style.transition = \"background-color 0.1s\";\n  voiceButton.append(voiceButtonIcon);\n  indicateButtonReady();\n\n  voiceButton.onclick = () => {\n    if (voiceButton.getAttribute(\"data-recording\") !== \"true\")\n      doRecognizeOnceAsync();\n    else stopRecording();\n  };\n}\n\nmain();\n\n\n//# sourceURL=webpack://speech/./src/index.js?");
  
  /***/ }),
  
  /***/ "?2454":
  /*!******************************************!*\
    !*** ../../external/ocsp/ocsp (ignored) ***!
    \******************************************/
  /***/ (() => {
  
  eval("/* (ignored) */\n\n//# sourceURL=webpack://speech/../../external/ocsp/ocsp_(ignored)?");
  
  /***/ }),
  
  /***/ "?6483":
  /*!****************************!*\
    !*** agent-base (ignored) ***!
    \****************************/
  /***/ (() => {
  
  eval("/* (ignored) */\n\n//# sourceURL=webpack://speech/agent-base_(ignored)?");
  
  /***/ }),
  
  /***/ "?bed2":
  /*!**********************************!*\
    !*** async-disk-cache (ignored) ***!
    \**********************************/
  /***/ (() => {
  
  eval("/* (ignored) */\n\n//# sourceURL=webpack://speech/async-disk-cache_(ignored)?");
  
  /***/ }),
  
  /***/ "?72ad":
  /*!***********************************!*\
    !*** https-proxy-agent (ignored) ***!
    \***********************************/
  /***/ (() => {
  
  eval("/* (ignored) */\n\n//# sourceURL=webpack://speech/https-proxy-agent_(ignored)?");
  
  /***/ }),
  
  /***/ "?a1bf":
  /*!*********************!*\
    !*** net (ignored) ***!
    \*********************/
  /***/ (() => {
  
  eval("/* (ignored) */\n\n//# sourceURL=webpack://speech/net_(ignored)?");
  
  /***/ }),
  
  /***/ "?14d6":
  /*!*********************!*\
    !*** tls (ignored) ***!
    \*********************/
  /***/ (() => {
  
  eval("/* (ignored) */\n\n//# sourceURL=webpack://speech/tls_(ignored)?");
  
  /***/ }),
  
  /***/ "?e42a":
  /*!********************!*\
    !*** ws (ignored) ***!
    \********************/
  /***/ (() => {
  
  eval("/* (ignored) */\n\n//# sourceURL=webpack://speech/ws_(ignored)?");
  
  /***/ }),
  
  /***/ "?9463":
  /*!********************!*\
    !*** fs (ignored) ***!
    \********************/
  /***/ (() => {
  
  eval("/* (ignored) */\n\n//# sourceURL=webpack://speech/fs_(ignored)?");
  
  /***/ })
  
  /******/ 	});
  /************************************************************************/
  /******/ 	// The module cache
  /******/ 	var __webpack_module_cache__ = {};
  /******/ 	
  /******/ 	// The require function
  /******/ 	function __webpack_require__(moduleId) {
  /******/ 		// Check if module is in cache
  /******/ 		var cachedModule = __webpack_module_cache__[moduleId];
  /******/ 		if (cachedModule !== undefined) {
  /******/ 			return cachedModule.exports;
  /******/ 		}
  /******/ 		// Create a new module (and put it into the cache)
  /******/ 		var module = __webpack_module_cache__[moduleId] = {
  /******/ 			// no module.id needed
  /******/ 			// no module.loaded needed
  /******/ 			exports: {}
  /******/ 		};
  /******/ 	
  /******/ 		// Execute the module function
  /******/ 		__webpack_modules__[moduleId](module, module.exports, __webpack_require__);
  /******/ 	
  /******/ 		// Return the exports of the module
  /******/ 		return module.exports;
  /******/ 	}
  /******/ 	
  /************************************************************************/
  /******/ 	/* webpack/runtime/compat get default export */
  /******/ 	(() => {
  /******/ 		// getDefaultExport function for compatibility with non-harmony modules
  /******/ 		__webpack_require__.n = (module) => {
  /******/ 			var getter = module && module.__esModule ?
  /******/ 				() => (module['default']) :
  /******/ 				() => (module);
  /******/ 			__webpack_require__.d(getter, { a: getter });
  /******/ 			return getter;
  /******/ 		};
  /******/ 	})();
  /******/ 	
  /******/ 	/* webpack/runtime/define property getters */
  /******/ 	(() => {
  /******/ 		// define getter functions for harmony exports
  /******/ 		__webpack_require__.d = (exports, definition) => {
  /******/ 			for(var key in definition) {
  /******/ 				if(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {
  /******/ 					Object.defineProperty(exports, key, { enumerable: true, get: definition[key] });
  /******/ 				}
  /******/ 			}
  /******/ 		};
  /******/ 	})();
  /******/ 	
  /******/ 	/* webpack/runtime/hasOwnProperty shorthand */
  /******/ 	(() => {
  /******/ 		__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))
  /******/ 	})();
  /******/ 	
  /******/ 	/* webpack/runtime/make namespace object */
  /******/ 	(() => {
  /******/ 		// define __esModule on exports
  /******/ 		__webpack_require__.r = (exports) => {
  /******/ 			if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
  /******/ 				Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
  /******/ 			}
  /******/ 			Object.defineProperty(exports, '__esModule', { value: true });
  /******/ 		};
  /******/ 	})();
  /******/ 	
  /************************************************************************/
  /******/ 	
  /******/ 	// startup
  /******/ 	// Load entry module and return exports
  /******/ 	// This entry module can't be inlined because the eval devtool is used.
  /******/ 	var __webpack_exports__ = __webpack_require__("./src/index.js");
  /******/ 	
  /******/ })()
  ;